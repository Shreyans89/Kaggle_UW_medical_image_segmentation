{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed38259f-eaee-4313-b701-a4ca0889f1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: shreyans (ai_in_pathology). Use `wandb login --relogin` to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a918cd0-b62f-4916-be85-c6d5fa17fa5d",
   "metadata": {},
   "source": [
    "# Image Segmentation: GI-Tract Scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818710a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pdb\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import sklearn\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import pdb\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f10719d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0adf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>stomach</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id        class segmentation\n",
       "0  case123_day20_slice_0001  large_bowel          NaN\n",
       "1  case123_day20_slice_0001  small_bowel          NaN\n",
       "2  case123_day20_slice_0001      stomach          NaN\n",
       "3  case123_day20_slice_0002  large_bowel          NaN\n",
       "4  case123_day20_slice_0002  small_bowel          NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14123615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class EventTimer():\n",
    "    def __init__(self):\n",
    "        ## if you stop an event (code block) without starting,\n",
    "        ## it will show 0 for the time elapsed\n",
    "        self.start_times=defaultdict(time.perf_counter)\n",
    "        self.elapsed={}\n",
    "        \n",
    "    def start(self,event_name:str):\n",
    "        self.start_times[event_name]=time.perf_counter()\n",
    "        \n",
    "    def stop(self, event_name:str):\n",
    "        end =time.perf_counter()\n",
    "        self.elapsed[event_name] = end - self.start_times[event_name]\n",
    "        \n",
    "timer=EventTimer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5af39679",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs=get_image_files(Path('train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb19625a-3c27-4927-832c-ee686b3802f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filepath2id(fpath):\n",
    "    _,_,caseid,_,sliceid=str(fpath).split('\\\\')\n",
    "    ## join caseid and scanid with / to get the overall img_id\n",
    "    id_lst=np.array([caseid])\n",
    "    id_lst=np.concatenate((id_lst,sliceid.split('_')[:2]))\n",
    "    return '_'.join(id_lst)\n",
    "\n",
    "all_imgs_df=pd.DataFrame({'img_path':img_path,\n",
    "                        'id':filepath2id(img_path)} for img_path in all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e99f4823-ae04-42f3-9781-d9c773dfbc70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train\\case101\\case101_day20\\scans\\slice_0001_266_266_1.50_1.50.png</td>\n",
       "      <td>case101_day20_slice_0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train\\case101\\case101_day20\\scans\\slice_0002_266_266_1.50_1.50.png</td>\n",
       "      <td>case101_day20_slice_0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train\\case101\\case101_day20\\scans\\slice_0003_266_266_1.50_1.50.png</td>\n",
       "      <td>case101_day20_slice_0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train\\case101\\case101_day20\\scans\\slice_0004_266_266_1.50_1.50.png</td>\n",
       "      <td>case101_day20_slice_0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train\\case101\\case101_day20\\scans\\slice_0005_266_266_1.50_1.50.png</td>\n",
       "      <td>case101_day20_slice_0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38491</th>\n",
       "      <td>train\\case92\\case92_day0\\scans\\slice_0140_266_266_1.50_1.50.png</td>\n",
       "      <td>case92_day0_slice_0140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38492</th>\n",
       "      <td>train\\case92\\case92_day0\\scans\\slice_0141_266_266_1.50_1.50.png</td>\n",
       "      <td>case92_day0_slice_0141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38493</th>\n",
       "      <td>train\\case92\\case92_day0\\scans\\slice_0142_266_266_1.50_1.50.png</td>\n",
       "      <td>case92_day0_slice_0142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38494</th>\n",
       "      <td>train\\case92\\case92_day0\\scans\\slice_0143_266_266_1.50_1.50.png</td>\n",
       "      <td>case92_day0_slice_0143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38495</th>\n",
       "      <td>train\\case92\\case92_day0\\scans\\slice_0144_266_266_1.50_1.50.png</td>\n",
       "      <td>case92_day0_slice_0144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38496 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 img_path  \\\n",
       "0      train\\case101\\case101_day20\\scans\\slice_0001_266_266_1.50_1.50.png   \n",
       "1      train\\case101\\case101_day20\\scans\\slice_0002_266_266_1.50_1.50.png   \n",
       "2      train\\case101\\case101_day20\\scans\\slice_0003_266_266_1.50_1.50.png   \n",
       "3      train\\case101\\case101_day20\\scans\\slice_0004_266_266_1.50_1.50.png   \n",
       "4      train\\case101\\case101_day20\\scans\\slice_0005_266_266_1.50_1.50.png   \n",
       "...                                                                   ...   \n",
       "38491     train\\case92\\case92_day0\\scans\\slice_0140_266_266_1.50_1.50.png   \n",
       "38492     train\\case92\\case92_day0\\scans\\slice_0141_266_266_1.50_1.50.png   \n",
       "38493     train\\case92\\case92_day0\\scans\\slice_0142_266_266_1.50_1.50.png   \n",
       "38494     train\\case92\\case92_day0\\scans\\slice_0143_266_266_1.50_1.50.png   \n",
       "38495     train\\case92\\case92_day0\\scans\\slice_0144_266_266_1.50_1.50.png   \n",
       "\n",
       "                             id  \n",
       "0      case101_day20_slice_0001  \n",
       "1      case101_day20_slice_0002  \n",
       "2      case101_day20_slice_0003  \n",
       "3      case101_day20_slice_0004  \n",
       "4      case101_day20_slice_0005  \n",
       "...                         ...  \n",
       "38491    case92_day0_slice_0140  \n",
       "38492    case92_day0_slice_0141  \n",
       "38493    case92_day0_slice_0142  \n",
       "38494    case92_day0_slice_0143  \n",
       "38495    case92_day0_slice_0144  \n",
       "\n",
       "[38496 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_imgs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b281d81-ab6e-4c7e-8c27-f3cd544db91c",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a8b7d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting RLE_Segmentation_Dataset_inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 'RLE_Segmentation_Dataset_inference.py'\n",
    "\n",
    "import sklearn\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import pdb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## dataset class gto nload only X (images), to generate dataloaders for inference\n",
    "class RLE_SegmentationDataset_inference(Dataset):\n",
    "    def __init__(self,img_paths_df,  transform=transforms.Resize((224,224))\n",
    "                 ):\n",
    "        \n",
    "        self.items=img_paths_df\n",
    "        self.item_transform = transform\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "   \n",
    "    def get_img_T(self,img_path):\n",
    "        img_t=TensorImage(Image.open(img_path))\n",
    "        H,W=img_t.shape\n",
    "        if self.item_transform:\n",
    "            img_t = self.item_transform(img_t.unsqueeze(0))\n",
    "            \n",
    "        return img_t.to(torch.float32) ,H,W                        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        item_data=self.items.iloc[idx]\n",
    "        img_path,img_id=item_data['img_path'],item_data['id']\n",
    "        img_t,H,W=self.get_img_T(img_path)\n",
    "        \n",
    "       ## return 3 channel image to put it through the fastai_model\n",
    "        return img_t*torch.ones((3,1,1))\n",
    "    \n",
    "    \n",
    "## dataset class to load both X and Y (for training)  - modify only __getitem__ method\n",
    "class RLE_SegmentationDataset_train(Dataset):\n",
    "    \n",
    "    def __init__(self,img_paths_df, label_df=pd.read_csv('train.csv'), item_transform=transforms.Resize((224,224)), \n",
    "                 target_transform=transforms.Resize((224,224))):\n",
    "        \n",
    "        self.items=img_paths_df\n",
    "        self.inference_ds=RLE_SegmentationDataset_inference(img_paths_df,item_transform)\n",
    "        self.img_labels_df=label_df\n",
    "        self.target_transform = target_transform\n",
    "        self.codes={'background':0,'small_bowel':3,'large_bowel':2,'stomach':1}\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    \n",
    "    def get_mask_T(self,img_id,H,W):\n",
    "        \n",
    "        label_data=self.img_labels_df[self.img_labels_df['id']==img_id]\n",
    "        label_data=label_data[label_data['segmentation'].notnull()]\n",
    "         #Incase of no segmentation rle encoding, assert that every pixel belongs to the background\n",
    "        if len(label_data)==0:\n",
    "            mask_t=torch.zeros((H,W))\n",
    "        else: \n",
    "            ## in case of overlap b/w pixels of different classes in labels,assign to\n",
    "            ## smallest class in order small_bowel<large_bowel<stomach\n",
    "            mask_t=torch.Tensor(np.stack([self.rle2mask(rle_pixels,H,W)*self.codes[pxl_cls] \n",
    "                                    for pxl_cls,rle_pixels in \n",
    "              zip(label_data['class'],label_data['segmentation'])]).max(axis=0))\n",
    "        if self.target_transform:\n",
    "            mask_t = TensorMask(self.target_transform(mask_t.unsqueeze(0)).squeeze(0).to(torch.int64))\n",
    "          \n",
    "        return mask_t   \n",
    "   \n",
    "\n",
    "\n",
    "         \n",
    "    def foreground_only(self):\n",
    "        \"\"\"Get a new dataset with images which have foreground segmentation classes\"\"\"\n",
    "        merge_img_lbls=pd.merge(left=self.items,right=self.img_labels_df,how='left')\n",
    "        nb_ids=np.unique(merge_img_lbls['id'][ merge_img_lbls['segmentation'].notnull()])\n",
    "       # nb_df=pd.DataFrame({'id': nb_ids})\n",
    "        foreground_df=self.items.set_index('id').loc[nb_ids]\n",
    "        return self.__class__(foreground_df.reset_index())\n",
    "        \n",
    "\n",
    "    def train_test_split(self,test_pct=0.2,random_seed=42):\n",
    "        train_df,test_df=sklearn.model_selection.train_test_split(self.items,test_size=test_pct,\n",
    "                                                                 random_state=random_seed)\n",
    "        \n",
    "        return self.__class__(train_df),self.__class__(test_df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    \n",
    "    def rle2mask(rle_pixels,H,W):\n",
    "        \n",
    "        rle_pixels=np.array(rle_pixels.split(sep=' '),dtype='int32')\n",
    "        \n",
    "        ## even entries are pixel start values\n",
    "        pxl_starts=rle_pixels[np.arange(start=0,stop=len(rle_pixels),step=2)]\n",
    "\n",
    "        ## Odd ones are number of pixels starting from start point in the mask\n",
    "        pxl_offsets=rle_pixels[np.arange(start=1,stop=len(rle_pixels),step=2)]\n",
    "\n",
    "        pxl_stops=pxl_starts+pxl_offsets\n",
    "\n",
    "        ## transpose so that flatten gives pixel locations as in start-stop-start-stop\n",
    "        pxl_start_locs=(np.stack([pxl_starts,pxl_stops]).T).flatten()\n",
    "\n",
    "        ## initialize flattened mask\n",
    "        flat_mask=np.arange(start=0,stop=H*W,step=1)+1\n",
    "\n",
    "        ## compute mask with pxl start locastions. an even number at each position \n",
    "        ## implies background ,odd numbers are foreground\n",
    "\n",
    "        even_odd_mask=(np.expand_dims(flat_mask,1)>=np.expand_dims(pxl_start_locs,0)).sum(axis=1)\n",
    "\n",
    "        ## odd numbers are foreground class\n",
    "        mask=even_odd_mask%2\n",
    "\n",
    "        mask=mask.reshape(H,W) \n",
    "        \n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def save_masks(self,folder_name='masks'):\n",
    "        \"\"\"create and save seh masks from RLE in \n",
    "          a folder 'masks' at the same level as train\n",
    "          (containing images)\n",
    "          each mask is identified by its corresponding \n",
    "          image file's id (taken from train.csv) \"\"\"\n",
    "        \n",
    "        save_folder=Path(folder_name)\n",
    "        save_folder.mkdir(exist_ok=True)\n",
    "        \n",
    "        for i,img_data in tqdm(enumerate(self.items)):\n",
    "            _,mask=self[i]\n",
    "            mask=PILMask.create(mask)\n",
    "            mask_path=save_folder/Path(img_data['id']+img_data['img_path'].suffix)\n",
    "            mask.save(mask_path)\n",
    "            \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        item_data=self.items.iloc[idx]\n",
    "        img_path,img_id=item_data['img_path'],item_data['id']\n",
    "        img_t,H,W=self.inference_ds.get_img_T(img_path)\n",
    "        \n",
    "        mask_t=self.get_mask_T(img_id,H,W)\n",
    "        return img_t, mask_t\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed710cc9-718b-4566-83d9-5185c5598e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting RLE_Segmentation_Dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 'RLE_Segmentation_Dataset.py'\n",
    "import sklearn\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import pdb\n",
    "\n",
    "\n",
    "class RLE_SegmentationDataset(Dataset):\n",
    "    def __init__(self,img_paths_df, label_df=pd.read_csv('train.csv'), img_dir=Path('train'), transform=transforms.Resize((224,224)), \n",
    "                 target_transform=transforms.Resize((224,224))):\n",
    "        \n",
    "        self.items=img_paths_df\n",
    "        self.img_labels_df=label_df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.codes={'background':0,'small_bowel':3,'large_bowel':2,'stomach':1}\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def foreground_only(self):\n",
    "        \"\"\"Get a new dataset with images which have foreground segmentation classes\"\"\"\n",
    "        merge_img_lbls=pd.merge(left=self.items,right=self.img_labels_df,how='left')\n",
    "        nb_ids=np.unique(merge_img_lbls['id'][ merge_img_lbls['segmentation'].notnull()])\n",
    "       # nb_df=pd.DataFrame({'id': nb_ids})\n",
    "        foreground_df=self.items.set_index('id').loc[nb_ids]\n",
    "        return RLE_SegmentationDataset(foreground_df.reset_index())\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "   \n",
    "    def train_test_split(self,test_pct=0.2,random_seed=42):\n",
    "        train_df,test_df=sklearn.model_selection.train_test_split(self.items,test_size=test_pct,\n",
    "                                                                 random_state=random_seed)\n",
    "        \n",
    "        return RLE_SegmentationDataset(train_df),RLE_SegmentationDataset(test_df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    \n",
    "    def rle2mask(rle_pixels,H,W):\n",
    "        \n",
    "        rle_pixels=np.array(rle_pixels.split(sep=' '),dtype='int32')\n",
    "        \n",
    "        ## even entries are pixel start values\n",
    "        pxl_starts=rle_pixels[np.arange(start=0,stop=len(rle_pixels),step=2)]\n",
    "\n",
    "        ## Odd ones are number of pixels starting from start point in the mask\n",
    "        pxl_offsets=rle_pixels[np.arange(start=1,stop=len(rle_pixels),step=2)]\n",
    "\n",
    "        pxl_stops=pxl_starts+pxl_offsets\n",
    "\n",
    "        ## transpose so that flatten gives pixel locations as in start-stop-start-stop\n",
    "        pxl_start_locs=(np.stack([pxl_starts,pxl_stops]).T).flatten()\n",
    "\n",
    "        ## initialize flattened mask\n",
    "        flat_mask=np.arange(start=0,stop=H*W,step=1)+1\n",
    "\n",
    "        ## compute mask with pxl start locastions. an even number at each position \n",
    "        ## implies background ,odd numbers are foreground\n",
    "\n",
    "        even_odd_mask=(np.expand_dims(flat_mask,1)>=np.expand_dims(pxl_start_locs,0)).sum(axis=1)\n",
    "\n",
    "        ## odd numbers are foreground class\n",
    "        mask=even_odd_mask%2\n",
    "\n",
    "        mask=mask.reshape(H,W) \n",
    "        \n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def save_masks(self,folder_name='masks'):\n",
    "        \"\"\"create and save seh masks from RLE in \n",
    "          a folder 'masks' at the same level as train\n",
    "          (containing images)\n",
    "          each mask is identified by its corresponding \n",
    "          image file's id (taken from train.csv) \"\"\"\n",
    "        \n",
    "        save_folder=Path(folder_name)\n",
    "        save_folder.mkdir(exist_ok=True)\n",
    "        \n",
    "        for i,img_data in tqdm(enumerate(self.items)):\n",
    "            _,mask=self[i]\n",
    "            mask=PILMask.create(mask)\n",
    "            mask_path=save_folder/Path(img_data['id']+img_data['img_path'].suffix)\n",
    "            mask.save(mask_path)\n",
    "        \n",
    "        \n",
    "\n",
    "    def get_img_T(self,img_path):\n",
    "        img_t=TensorImage(Image.open(img_path))\n",
    "        H,W=img_t.shape\n",
    "        if self.transform:\n",
    "            img_t = self.transform(img_t.unsqueeze(0))\n",
    "            \n",
    "        return img_t.to(torch.float32) ,H,W                        \n",
    "    \n",
    "    \n",
    "    def get_mask_T(self,img_id,H,W):\n",
    "        \n",
    "        label_data=self.img_labels_df[self.img_labels_df['id']==img_id]\n",
    "        label_data=label_data[label_data['segmentation'].notnull()]\n",
    "         #Incase of no segmentation rle encoding, assert that every pixel belongs to the background\n",
    "        if len(label_data)==0:\n",
    "            mask_t=torch.zeros((H,W))\n",
    "        else: \n",
    "            ## in case of overlap b/w pixels of different classes in labels,assign to\n",
    "            ## smallest class in order small_bowel<large_bowel<stomach\n",
    "            mask_t=torch.Tensor(np.stack([RLE_SegmentationDataset.rle2mask(rle_pixels,H,W)*self.codes[pxl_cls] \n",
    "                                    for pxl_cls,rle_pixels in \n",
    "              zip(label_data['class'],label_data['segmentation'])]).max(axis=0))\n",
    "        if self.target_transform:\n",
    "            mask_t = TensorMask(self.transform(mask_t.unsqueeze(0)).squeeze(0).to(torch.int64))\n",
    "          \n",
    "        return mask_t   \n",
    "        \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        item_data=self.items.iloc[idx]\n",
    "        img_path,img_id=item_data['img_path'],item_data['id']\n",
    "        img_t,H,W=self.get_img_T(img_path)\n",
    "        \n",
    "        mask_t=self.get_mask_T(img_id,H,W)\n",
    "        return img_t, mask_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9181f45-d07e-49db-a850-37d80b942194",
   "metadata": {},
   "source": [
    "## CallBacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b0ae63e-9218-4707-b3de-cb352b004533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callback.core import Callback\n",
    "\n",
    "def display_change(model,\n",
    "                   test_img_path,\n",
    "                   dls,\n",
    "                   epoch_num,\n",
    "                   batch_num,\n",
    "                   save_folder='results'):\n",
    "    \n",
    "    save_folder=Path(save_folder)\n",
    "    save_folder.mkdir(exist_ok=True)\n",
    "   \n",
    "    model_istrain=model.training\n",
    "   \n",
    "    img_t,H,W=dls.dataset.get_img_T(test_img_path)\n",
    "    img_id=filepath2id(test_img_path)\n",
    "    mask_t=dls.dataset.get_mask_T(img_id,H,W)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_t=model(img_t.unsqueeze(0).to(dls.device))\n",
    "        \n",
    "    if model_istrain:\n",
    "        model.train()\n",
    "    \n",
    "    pred_t=pred_t.argmax(dim=1)\n",
    "    out=torch.cat((pred_t.squeeze(0),mask_t.to(dls.device)),dim=1)\n",
    "    show_image(out)\n",
    "    mask_path=save_folder/Path('_'.join(['epoch',str(epoch_num),'batch',str(batch_num),test_img_path.suffix]))\n",
    "    PILMask.create(out.to('cpu')).save(mask_path)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "## a cb to do inference on test_items and save predicted masks with labels\n",
    "def save_training_progress(self,test_items=ds_fg.items.iloc[-5:],save_folder=\"inference_progress\"):\n",
    "    save_folder=Path(save_folder)\n",
    "    save_folder.mkdir(exist_ok=True)\n",
    "    \n",
    "   \n",
    "    if self.iter%200==0:\n",
    "        save_fname='iteration_{}_output.png'.format(self.iter)\n",
    "        inps,outs,lbls=get_predictions(self,test_items)\n",
    "        save_predictions(inps,outs,lbls,save_folder/Path(save_fname))\n",
    "        self.model=self.model.to('cuda')\n",
    "        if self.model.training:\n",
    "            self.model.train()\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "## save inputs,ground truth and predictions side by side\n",
    "def save_predictions(inputs,outputs,labels,fname):\n",
    "    row_list=[]\n",
    "    for img,pred_mask,lbl_mask in zip(inputs,outputs,labels):\n",
    "        \n",
    "        img=frame_image(np.transpose(img,axes=(1,2,0))/img.max())\n",
    "        pred_mask=frame_image(mask2display(pred_mask))\n",
    "        lbl_mask=frame_image(mask2display(lbl_mask))\n",
    "        row=np.concatenate((img,pred_mask,lbl_mask),axis=1)\n",
    "        row_list.append(row)\n",
    "    \n",
    "    row_array=np.concatenate(row_list,axis=0)\n",
    "    \n",
    "    plt.figure(figsize = (20,20))\n",
    "    plt.imsave(fname,row_array)\n",
    "    \n",
    "save_training_progress_cb=Callback(after_step=save_training_progress)    \n",
    " \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e84feb5-14af-4c0c-a42e-35e13960fcb7",
   "metadata": {},
   "source": [
    "### Dataset Instantiation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edf3d1e8-d81d-4552-b235-0af4324c7881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds=RLE_SegmentationDataset(all_imgs_df)\n",
    "ds_fg=ds.foreground_only()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c9c80-9734-4937-babd-fc738374a62a",
   "metadata": {},
   "source": [
    "### Dataloaders Instantiation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac14e22a-666f-4769-9800-96bbe79958eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train,ds_test=ds_fg.train_test_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72510493-9661-456c-b600-a3d75901b86b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    }
   ],
   "source": [
    "dls=SegmentationDataLoaders.from_dsets(ds_train,ds_test,bs=16,device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e96876d-0d6e-47fb-82e7-3e96f0f47865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAACmCAYAAAB5qlzZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAADBcklEQVR4nOz9+bNlSXLfB348Is4599635FJZW2/YuEowrt1d3QCIESQTCZEUfxiz+W/mx/mLRhLHjJJxhiSE7qrupjiSRqJEgAAI9FJbLm+79ywRPj94RJxzb76X+V51dSELzDDLfO/de5Y4cSI83L/+dXdRVV631+11e91ety+muT/vDrxur9vr9rr9x9ReC93X7XV73V63L7C9Frqv2+v2ur1uX2B7LXRft9ftdXvdvsD2Wui+bq/b6/a6fYHttdB93V631+11+wJbeNGXf+e3/h+v+WT/sTWR+fdCJxSZf/+c27/+vf+7vPyoz7+9ntuv2y+63TS3Xyh0/9za4SJf/i3XPIfqzcLipu+vu85n6yzwC1y/pa+HQu9lY1LOPTz+Rce+aAyv++6w/QKF8+v2uv1Faa+W0L1OICw/u43Ave64vb/F5OTzN+J64fn8wc/LlnKMHvx9m7Y8Z3nR/Pd1Qm/ZkRe1l43LXY59mYBfnnfTRvG6vW6v258DpnvTor1OE32ZwH3R5wjXCz89+O5AIN/43SxAbpYlN93zZU3yYxze/8XnXN/PX1A7fB+3Ped1e91et732+Qvdly206wTqXa/x4g5wsxAq3ynPa5XXHfuiv2/aE/TaY8ojL/8tr/u8IL9Oa14K5Rdp5X8Owm4J5Rx+/lr4vm6vW20/H7xwnQn5MpPyJjP5zjjrbbHUFwlUXfy8+d43K9NZQ83PXLTVlw3B4b5zPVx7KGyfu/lLfl533udk7h92/Dpo4rZwxOv2uv1H1n6x8MJSslwnYa77/uUX5WYt9PZOrdmcN4F7WzQD517a7xddqzz+i3xRt/385v7qDZ9fe2WuH9OXtOUDXPcwr4Xt6/a6Xdt+Pk33tpLjOufKZ9JsYV8rXUIFtzOtSxfmrsuNwqv+/rLNweW960CiirD/zIvTD/ee6/p5eMkXGQnPO/b0uftcj1Ff47y7a3vpAL5uf2Hay5g0r9tL22cXujcN9HVe7+sW4meCEm7Scg8F783dufHWtxEcIojILJZepO2pPi+MF5uPXOOYu43wve4AeamAvfbEcvfF33dYOK8F6n+c7Tru9muBe6f22YTuyyTZUtB+JvjgZU6u6865vtWu/DwOHeeQ6gHLd1O7uBY1s0w85+a/y8RcCt9r4BZxBxvYNRvac10/3BhU9wT0S4X1fPI1v3+Oi+hlAPbr9uVqrzfbn7t9NqG7XEifO553ndf+5VrsC5GOmwTuTQ6hfLwcHrfsSr6u4OzD5Op1NJ9TteKU7BopPd/Z6zal5dh+hvG9yY91e3l3HQzxGduLnGyv259vu+27uM56ve77lygOd7rnX+B2O6F7kxZ7+N1nbtdpt8/jtNfd6jkG2nWC9PDfwZ2A66EAAZwH7+x77+bzpwjjZP1UAZco0lhSQrOgFUDLtQ+x7ZukY+3cwcb2IgGs+twjX3fo7ef74YF30YIX7/NuaveXu33Z8M7b9us6pWRPDuT3fd0Ge3ifV3UsvsD2cqF700B+rm1fu7VbyLUK4WET97yZDcxCNH8uLgvOom16B00DTUC9I3WBuPHEVpg6IW4gtpBWCbziQiKESBsiqsLVbg07j4yC7yFcgd8pflCaiwm56q0/w4hMk/3uHBpjfuRbarCHkMRS+z0Q2iI3XPcFt3jx4cvN8EUHHm6aLzA7vsyL7rD/h3jOTRP2F/HctzXzft773rjwirn3GTTl0u7Sty/73Fm0P8cw4Ou02wUccDDAqszY51IDPHyhzu0J3mriNwE9OWI6aRiOHeMJTMeKrCdW3ci97pzWTUR1PGoveKs5w5M4dj1BEg7oJLEShyBcpsinaU2vgYu04nxaMaonqeOPnj0kPT4hrhLh0tE+he5pJDy+RIYRsiYsi76rqv3dhLw5zJqiTtM+NHEdRnrNxNakN8rx27fbLKwXfP8XCV64brNbthcpJC977ruMy3UC/jrL6SWW0a36/fwF8k/l+g350Eo90HLvshndtLF8mecQtxG6d6Z2vahdL2ivvSfXjO1hXxZmuzgHPkMBXUtcN0zHgf6eMDxQNg+2fOP4Y95szrnnt3QyMajnKnWIKKrChGNST5DIoIGkwlZbBCVIWvRaSeoY1ONE8STebM5JiAntN8+5fNhxz1+RcFyllifjhh+f32d6csLqI6E7i7hdxO2yEN507N5o2L4pxJOIeIUrT/tUaM+U9mzCXeygH9BxvHlxLf7eswIOxvW6Ib2Z/fCi93+4wG4hpL9si+Y6jfauENtNQu420NHy2Ot8AId/X3fMTTjs/oeHnX7u+/k04fmiti+xjG7CvPZueYO8+QsEUf2CNN0XLbzy3XKxvtyyfk7YOmdnH21IRx39aWD3UJiOFNaJk+MtD1dPOPI9J37Hqd/SSkRQJnWcp2N2qWGXGjT3Y1RPVIeq1N55MTggYZ8P6uncxNoNpBxbMiQTvkESfQp4SRz5nl4bEkIjkZPQ82v3PibcTzz7+ppPtkdsty30G4jgT0f+8oMf80vdpxy7npVM7DTws+keHw6n/NnFPXZPjln/TFh/MuKeXqBZa775NVwjXQ+k7MsVj33o55qbHBx3y/YLgal+we2ufb7OCrmL5n+TFXMomA7B/BfBHC/ucDlw8XP/s/1bH262L2ov0ID3DvscoIhXvP2ChO7LFuryuMXLPKROwZ4pLW0DXUe8t2b3RqC/D+5Rz9dOH/OguWLlRlQFEaVPDdvUsI0tz8Y1Ud/AieJQogpj8iQVnJgQjsk9p4N7l2hcIkgkuFSvfT52nNPhRRE5hEGEqMJjPSIheEk0LjImX48Jknhnc44/MoHZuGjatxvZaUMfQx25tRv46+uf8N7RH+HfVn76l0/4g+3b/PufvcnxHwvrn17B+aVpHYUlAfu/H47nLdq8dm9z/C3w3GtP+5IupJtMhRcddygMbzKXXwS6v0zLfRH09iKc6bnvlutXbjx9cfEbfr9uXrzgnb/Mqv6yWUg3tM9Z6N52gT5/3N5Y5z9cE2DVke5t2D1o2D0CfTDy1XtP+aurJwSJrN2AIjyZjvhwOGWIgaupYUyeMXqmaNqoc5phATORnMxC1DsluISXxJg8MTmcM4EYk5AkMKkSUznXmAJ9FtpOtAppVewaakJcBabkGJNHVUiYYA4u1XMBPuYYJ8o6jJz4HQCTOpwoKzfxiRs5djtO3Y7fOP5D/tav/Qn/+1e+wr/9+B3Wf3zE5s+2yLNzY03YA1/v4LnNWzxY27eD0z6jxvuqt5dtUnfRfm+j8f487KBD4XvYDrGkW2m+8pyf5WUIwHy7l8FSN/TtOkt5b1JKPuTLOdc+B6F7CwzvuePzb9dsyISAHG0Y3zzi4iuO9Gjkq/ee8Z+sP+HEb9mmlrO44ZPxmF1suJharoaWaXKgQpwcTLInAyRlbToo4hPiwPlkglUdMcEoSkpCSiUPgy76Z4JZspAsQlZEifl7VaHvPY1PphUDMTmGFEygO7ufKkR1BJeIKkzJBGsR9hdDxydyZHCFS6z8SOMiXpQgJ6z8SOdGjlzPL3ef8Ne/8RPOvrrhf/z019A/eIvjHw/I0wvDfQ+hh+ucbwcT9yb/3O01nb+g7UXUvs96rcPrfV6Qy4uuc+iI3T+xHHTteS9S1OsvS+gKvb1cLML0uQyA1/R9ec6XUPB+BqF7iM3AZ110e2PoHLJe0X/9Pmd/OfFX3v6Q317/hCCRbWo5T2v+bHiDi6njfOw461cMZx3NM8ENEDz4HUh+Z25S1IF6ITUQG/sd50gB1MEESAKJ4EZIHbhof1sHQVuLe5icCW0E1CnSJsRpfXpxSoqOfgE3aHQwONQrvpvwPuV5YptDSoJGgSi4weF764/rITUwniqsIz4kgo+s25E3u0uiCs/GDZ0beRAueRTO+b++/W/404f3+ddPv8H0fz7k5I+38OzcKGo3aVH19T2v0l53yu18qoeb8A2b8pdwsbz84e+ggPx5YNovvKfcLMOWztmi9cJtJ8ThJbh+jG4xdlUwl8t8CecQdxa6cvDzmiPusPnUFxgCPLrPp7/e8Jd+6Wf8g81/oJXEx/GIn/ZvcjatmNQzRD8L2zOh24EfwEVFBfygpEZIXkz4JlBvAtXv1ATqpOBARVBnQlqiElshdoIfFDcZLCDl/EmRCKkRprUwbYTxWEhB8VtHc2bH6QbcBDLZ86XOhLsbBDe0dl1ngj0ku77dT0EjLir9abBNoQOZBHkWIMHoYHBrnqyOWZ/0PFxfMajnPK74eDzhUXPBfX/FP3r0v/CHp2/xr7/xdY7+9zdZ/fgcvbyyDhUpWtqLJKrqdbL4OYXvZqjhOhjprlbRK9RuJVxeYYH7wpYtwYpGLaxRPwcN1fW6NH+WO/ONWuhS471pTijXz49D7fs2TrtXu/3c8MJ1QvY2n5UXKF3H7lcesv1PR/7hu/8GR+LfD29xPq04G1eAYZvnfUd/3tKcOdaX4EYTjuEq4oaIOiGuAvFYGI8BFfzOhKHfQdNnzTdIfX8u2i9uUtQL/iIhEWIrJgjFBGhshfFISC2MpwnXRZpgpvvgAxI93RNYf5JAlWnjkATDsZjmOll/y1wJV4okRVRNm/Zim4Wz+6ZGaC6hubA+uhFiJ0wr4MIxnq/58b2W1WbgqB2IwRHV89RtOPY97zZP+b997SP+jzff4d/82Te4/2+PaT48R7fb66Xki5w3N7zvlys5f0Ex3l9oW25WX+y4Ld/rXnsRs+JwN74G8z0U4vnTctLhRQ+OuY3m+4I+vqLtDkL3xbvLy4D152BEEeTkmMtfOcX9p5d85/6fcZE6PhpP+Xh3TMov6mps2Z51hEtH10NzrrTnEddHZIoWjqsKXQMr0xJjB9oo05FpiylAarJDbTIh60ZwgwnCFITkIa0c6iCu82etklpFQsR5RYHglOAjIpBU8CGRHiqX94Tmsad7ooSdmvbceNOmk2nJblIkwbQRUNOYU2Pj4gZoLpX22Uj3JA9WTEiyyZzWLeNxIHamoTdPPX2/YjgO9KuBqXVosA3qMhlH+C91H/GNX/2UH775y3z4H97g3h8c4T85Q/vhhVLzRjw3v7zbK2qHi6j8/GwOvi+8faEa6W0F0y+m3fgqDr84WMi3cbI+LxsP/Qgl+vR2z1rvc8jWeFlHXpH2c2m6L5uTN9EHRUBOjnn266cc/9oZX9884ePxhIup42pqEGA7Nuy2LXLh6S4szLZ7NuHPe3MQxSxsQ0DXHdNRAAftmeIGIa5NkIqaQEPBj9BcJVyfwEHsHOMmR6etFW0TZIeZeHOWNT4RfLLP7DJM0TjCwSVcm7VlUeJauHyjxT/xrD412GC4L6TR7l1aCsK0gfFY0UaRSQybjopMCenHOa9DHjA3RbpdYLzXkYKHAZoLIT5ruLwX6O8Ftl3DcdNzFAZ+Fu/x8XjCm805v33675h+/Q/5va//ZR7/u4ec/p+G91JCkstLScmwdbf4bKnW3gJb2J/vN02QLzHMsGyfm3PtpvNfNkafxzg+f+/bISl67eNfJ++eF7bX3NMJmm6+xvJZK5XxC90TPz9Bfiehey3bgGtekkj1XC61JMkajqxXXPylU9pfvuR+u+XD3SljckR1RBX6MTCedTTnQriA9iIRnvXIrkhPD02DdoG4CqZNRvCXIzJMdE7Q4BfKlaAZzogrz+5hYDqGaaPo0UTTTvjkSNFZn53ivTmvVGWPdjZNjpQpZeolMxqMmdB4JfhEXAsX9zu6n3nCpXXBZ3gjBWFaQwoQtoJcmCPQ9/YMqfVI45Epzf2PCYkJkuKGhCTPtDHYZPU40Z4J/VnH04cN25MG3VxyEnZEdXw43GOnDe+EZ/zu/f+Nf/+3HvIv7/9VHv6vDf6nj/dzQdwEMyy0mnrIgdNtecqL5POelvKqt5tYBi9ttxWG113zZRvVUgO+6z1uwksXn8jBH9e93Pz7Hsa7gBfq5y98x/Ys182ncg2DJZ7HcMv1Nd3y/RxOyNs5Jq431T+Hdjuhmwe73Pday3TxMCXm/1phvFpx+Vcfkv7yjuMw8vHuiJjMk19+6rOW4x8r7bMBiWr5CmIyioIqBE88bomdQyYlXE3IkL1X3mUBC+rEktm0jmlluOy0gdTpPIevPPGZDYO2pu1qEtLkGAmIU/sHiEScU1KEFB2QMrYrTNGTMnOh8Qk2PdMvefqrBn/laJ8K3ZlhvmHH7OxTw51Ln11USGp9D47UOHPerQUNQILumdI9TaRg1wjbRHOhxE8dl++u+PAtx3bdcL/d0rqJXWz49/FNPvI9X2me8Pd/9X/ln2/+Gkf/8yPa//AYLRDNtaDe4t0dLNoXwX0HU6L+/aVqL+vwjd/fVkN9XqBcf+zLfr+rQFgK7vk64g4E6It2zkPs6dAhuxDGImQBuf/cIuwlppLlPSqMJXu3Bnn5pv0iSOQu7XZYyZ3bnTXd2xxwuDjr101D/0sPGH5t4NFqy/nQ0Y8BEaNbxd7jrxzrT6A5nywvwRTna8cIXct03DJtHKgVeZs2DRw1ixvln0qljYkaZhq2Jt0kGb7qRsUPkWnj6e8LsbXIMfX53FZJTaoYrk6C2znUA0cJn2lj5YmTAsnRhchROzK0I9tNw/aoYTx1BnWAMSgclb5mTkGhaRrCNuGGiEwJH02zRRzjRgwiORtxlzvbYLxHuwACfhvZfCRc0fL4vmc6cRw3PSs/ESTxJAWeTWuOfc833/wTfvDrv8zp8IDw0yeWVOemdp1XNL/nF23E183LL4OC+9nbdRrudcLxNoNwG4F8031v0rSvO2755zWa7fL3mxgK1wneQ2bMTfc8jJw8vFZK17MqXqRIX7dJvKjddPyLvMU/B9xwa6H7nNnxInrCdSp8CExfecjZX0k82swCVxVScuhVoHtsx7pJTeNbClzviPfX7B4Epo1phm4ENwp+tJSKbjAHlqhpi4Uyq87ghTLlXFQYI+Sw47RuGDdCbKmc3eVzqXhcpFLQJJqzbQyBXcnTIIpzineJqNCPlkinayaCj6ROjGWAwRfl+OCUGB2ahP6+YzzzhEtPc+lwEfw24a9G3Jg/6yNuNxjEIiDDiIwTBE9qDWpxI6x+4rk6PubyYcf9oytELPzYu8Tl1OFd4tff/An/37/xNd4Y7yEfPrZ3tqx8Uca+4L2llYVyjfZ7OF+ugxv+YgremwSdHny31DJfdr2f5/63hSnyp4dm/iFssNRey3y4yTK6Rut9bp4sJ8KhcF/ktn7xXLlpzA8f6g6fHz7vsr1ICN+hffbKEXD7FSQCD0559muek5MLLvqWmBY46UXD+mdC7Ix54D9R5HJXX4CuW4b7Lf2pwQMu7uev9VujjQGmapbsWmKSVmJOm6g5tU3SnJjchPFw4s2ZdpSMd3uVaV0Fo5owZkDnjBnhqawDsoMtJYcmSPneafJoFMarBmkT3ieadsKJhSIHnxCgHwNT7yHm81ql3yjDVxMkcGeB1See1eMRfzmiwaFtYxiv5ucYI0yTOdtUmVYdqYX1R8p01vD4l4443ewY8bYR+IkULYvaX337Q/7gr3yFh+dr9Go7v98XYQOHmkz5erG4bpyff2Gl7oue6Tqt9ReBtdzmmjcI3Js03Gvel4igSy33Ze/0OuF1cHydLwf9qJc+ENz7ztovaD59TvjY7YXuTSr3dZ8vtSIR5GjDs7+8on20ZZws56yqhdxy3nD0EzOzhwfK6mOheZL5pCFUZ5kkxQ9C2EFzkfC9md9V6/JZQ9vDpXLXymd5shRNGBH7Dru/tAntHSQQNc3Z7yZkjHzr7EfETcvvf/XbxNbwVXWO6DyhjYSc3DyODp2chR6LgoCOjqjQrGxjcCi7vkGeNDTn8Pc++iGr//wf88//t58x3FeO7205bgacJLanDU/vbRiPGjYfe8JZb1F1GVIgKs5NhnmrItuBoz9N9G+uGDdCc6ms/iRw9vU1906uUBV2U8MqWHKgIJF3f/kTnnzyiM0fTBY+fPhuS7sOK7tGY9lbs9mauMlh8sq2z7TAllrsddrt7W9922G6/thZsD4vS+V2m+F1B0lOoUoWvOW4l2mUhx1cFhgohy5x5IN+3PwqynN+joL3Lu/9MyoQtxe6N2E6y++XP4tZ0TT0Xz1lemuikyIXE1MK8Kzh+McWKHD1roBCe54Mo+wCKGhwJnB3ir+KuClVbVadWDRbGfNaMacIXvtbXf49v1AZE8SENh4hh/4CKQphgNAr4TLirnq+/dPft4u3DWGM/Pb5v0K98L2v/Qa7B55dcKSQZqs8CW4QvvOzH+Ey6ytuIB1H/uev/A3TdIHUe/4vf/JDHvzN/wr3zj9AH0/8/V97m0/+7X/HD07/Btu+IUWHcwZDjKfKbnRs+oA/36GbjvG0YVoJklra80h4YpFnMkysfnqJe3NDf+poLxT+1PPs6xuOjnaIKJdjy+gjThIP2yt+/JcmVo9PDGa4aTIdajdpwfE5nAdlyvxFoIbdqi3N9l+EFru40w2W+fzdiwTVfN7eMbcB4FOiFmI9lAPXlbta/n0TFLG8xovOP3igQ4z3doL3cCNcav1f3Dz9+SLSbgLLF9jP9O4Dzv6S0rUT4+RpQmQYPXoROPmxEq4i598ISIL2qTCuhdi2dE+MkSATFS6QpKh3aGtCVNQw3Hp/LQJ2hgYQsWMWjABt3Nxtb061cCHI6Gmf5Si37cC3P/o+pEKpwjDmOCCq/Mb/8c/5/q/+Z8SuYXSB2EXLxRCF5kxYf6KcvvcPkZhIjWP7KPA3f/Tf8IP73wSF3/zwhxz91j+G84jEhIyK98Lxb/7XxH/3E/xO+M2Pf8j7b3zToIygTCfQjw2rqLjLHW1M8KBj+0jYveHZbI5Zfbit76X92QX+as1wP9A9TajzXLyzpt2MbNqBmBzPhjWTen7p4WN+8vW3uPeJ39d2D9ty412alkuogYNF+WXRbpftTvidHPy88aI3HHO9Znrt0nIyVwSRmTa1d94SXlv8XFYqkcN3ctM7OoQPDjHfa/DbvXv5Svq2H6Vs1t5z52smrRz8+k3BjksfFo6153WDlwnQQ8vjlgL3c8JyS7u10FVlvxLBTTDD4nc5PuLsVz3Hp5cMk7EUxskT+8D6E6G5GNk+ahCF7lPDSqc1bD5WJGuiNT4gC1wECyCYSgpDE6QkamitLl6+QQtk2MH+VgSnGC4aDUZoLhSJOffC1ci3P/yemexFYy7BCqU6RVK+89Pv8y/u/RaxE6J3qFPCpeN3v/YW/s3fxWBrhxsS648nVr/8D/knpe+/+rukizhvJI0wHntiq/zOf/Iu7RmEr/1j/r6Di//xv+X3fuWbpGDjM9xv6AC53NE+AfUd2zeFy69CbDYc/TgL3rbBP7uilSNS41h/EkmtZ6Ah+MimGZmS43JsedBdMb4d0ZMjePJsX5M9fL/XfXaTaXqoFX9Z2k1w2v5BvHjBHsINL7rO8+06Lbb+rGb+gWXp/TxH/VxUVUVmX8eyJUVSmgVe/mwvUoHF+3Myl5Na9MOYNFmgivk21Al4ydRNi6QsOU8QKIpqTVIVF5DeMMEwIdH8FZVPLjPfnwIVXutwu60GeyiIr9kYZfnLz69AfHZN93AiHqr/qxWXv3yCf9RbTtqcXnEaPO1jR3uW6O8FUgPtU9NCw07ZfGjUpdT5WZBGe+GShaA6yQK57L7M+G2eXLpcLHEeKBejZRvL4ydTQvK93QR+SDO+BFgeyHz9lDEM76HxMIz8vX//Pf5F+A1670hBWX2qhHYgrYPlh9iNMEZc401TnqJR39oGF4L1xTvUGa3N7wQ3WeSc31kYcHOpuB1oAxpyHoajQNAOpkT3SY8fWq7ecvRvgPo1Rz/uLbItC1636Zg2DZuPEiqObWhRFbowMSWHIrx1/4yLdx+wudyatntbzOo6PPDQI/2Cw1/pdj0AeteLvPQWNw3XniGxrCpdNUlvwid4aFt03RHXgfHIuOlxZfMmecBp5YOjmN9BqcmhCkNHIpZ9r3ye7CfYZ+Uadk1TlurvZa9yQNGZBNSV9TT/0+zzsH+KOJP1MrT4vqM5h+5pIpwPFhg1TkZtVH1uE98fw7vADsvvrzvu85+on5298CJ1W4TpzVOuvp6414xsxyaPk8OfebqnSmqF4UQI2WEetomwnQWijCZwjO51sEsnnYnUCjgLNihvXJ0gk+6bUFUDXkwcJ8gUkWRBFk0fDYoQMax4HK1Q5BQhToBAG+Z32gZkjDSXyXjDa7HENo1DVEmtJ4UWfzHmHTva9Zpgghab9GWiukHpnoFEzXkajEt89Pf+Ee/9//4pPzz+Js2l8u0nP+RHm79bd3pNEC4njn7s2b7pGe6DSsfxn4Fse/AeudjiWp81XuViFRhDqgEpT92a03bHR19V1h8dwcePP9PUuFGCLNW0L5vWW9vPJ4Bf5KsqcMGe0zF/IcLzZn1eg+KcCduTNbuHDbtHwnSSWB3t2LQjR2HAu2ScaiwAqWjHUR1Tsn8lGlRVGKOvSpLlmHZ7ik15Zk0Y6yaUCipyrXa+D48omq8tPuemzn6LrhnZhJGVH/Gi9Cnw8eUx49OO1ScrumeJ5ukO+tEgiGmq6QBevInfVustAnip/b5EKH8GDeLzrRxRYIX1iouve9bHW2JmKaTJw9bRPbVD+/uC642T21xaMMB40uCHhN9OhsE2/rmNyqhSVEdaSQhjWcFkhhMEu0aGAmwzVbSYZfkaBSpwU0JGw1dVhA/e+Dbf/uh72dRSK9cOs7YxTujxihQ8v/GT77MbWv7Vr3wTBC7/5T+l+91/YgI+AUEgCXhP2rSkxmVzS4yFEfP9t6CD1EgzSeb0k9YRtvAPfv0twvmI/urv8jveFt+/+OFPcL2xF9wkrJ5aFN7wUDkPHSd/pKYleI+7GpneWOFGZf2RcBUa0tFksE+08kX33zzn8qunHD9r97Xd5aI/3HRfBDUdfv9lUHFvVCgOMMj5hFtd9lbQ4HIRLzVa57IAzp85yaHwLcOjFVfvCOnhyP2jLcdNj5e0J2pMqFoFkym5WqoqqVjQz+LJnJj1l1QMofATmgXyPklJbD1lIa5pMTSlcEDWYkm2LrV0KN8zufy7JkbxbHNfN2HgUXvB11ePmR56Pv36ET8+v0f8ZEP3KayeTPirEXY9DCPkitm3E743fX4d1LA85vOZu589OOK6LzOmtPv6PeJbI06FfteSBo/bWSny5irR33NIhOZKCVem9aTOEwrfVgwDMvUYCiarZmPZrWJCkLlUeT6nhGtXgUw+H/uuCGU3WnUHzVSzIryNwyszPlWA/GkyqCENdTFIP0HrkUnpHo+0D2ySffDgm/y9cq8CTeQd2e0m1Dek1lVNnixg3Xa0ZzhqaghzcQLe++Y/JFxOc04G8cROGE8CchxozickJvyV0jYNKTsb1TtoGzMHN7ZxqIfu6QQSuPy6R9rElKtcPGi3/NEvbTj6yTF88tSefVnWHp7XXpefHc6L6wTyl0Hw7rWy4A7N1huOvuERb4aGD74oikHFZL2FwGfBq96hXWA4DezeEMaHkePjHa2PeEnsYmOCVEGZBaqgJEyTLaWnVMmc+SwklcoKuM5cVxU0lVBcqIJo+QjLSKSCL5S/4+L3ch2BpI7olDFDt0ECT9hw4To2buDt9oyvPXrC8Ebg4+GEPz27j360ZvPhivbpgFzsoO9tnR1YUnebbtcJ4EPt9+ebvz+/prsUuCLogxO2bwtNY7zVNHhcL7RPYfU0MW5sQnVPleZyor9vzIXmYs6Li8is0Up+MVFNYxT7vUIFh7CDk72IqQpBkDfkAlkAFcx3DibTDEy7lsp7ZZqqZl05wOX6+d7TUYMbE7/1px/w/be+RWod23/+39L+7j/BT2rYaqG5BVs4fhsN5vB2HfUCwTRgyc+nAinMnEbNfSiOiRSk4nbDcUP3NNGcjzQXkdQEsyAuttA2pFVD7Azn86Mlf++eTPQPAvFBYugDz1jh14k3Ti65fPcex2ctOgzPC9zrtLGbKEfXffc5eoK/mLY0L4sZ9Xy7The5GwlCLMtbgbfaBm0CadMQV44UzAkVWwsSmk6UcNxz3Ji1MiVHxNU6fKXFJAsamZWWWsIMKbn9V5W1UBOedsyhka2xrHsq3ove8KB68PvecM6WaYyuatOlYGyQxOACF7GjdZFj3/PV7glfffMJn9w/5g/ffsTlpyvWP2tZfToLXy2wQ7pmXh4M+fVCeSl8bxLEh7/frt09OOJF33UdF1/tmE4jjSj9EHA7R7gwgasZdG/PlObcoqskQntmGlyhb+VRz89Z8FugHONkDvNd2EWSEqiQWo+K4MZYWQ6F+QCW21a8z046u1/Ff0uQRXDourPM+f1Q0x5WIRMTbHucd6a5Nhai+xs/eZ/3H3yLD+5/k9/woBtH88zlvL+gwTGtHG7UqonbM0PchNzvhB9i1eLVezQIqXX4/EwabBFOx1j4MhBXjlXT0j4daS6SPZtz1s+U8G5leYKD0J8GmstI+xSujh3SJIYhcOZWiCi7d5T1Jyf4nz2ep9QhTHCTUC1zYnlMOedlc+mVa0st98WL67YsrOV3Fcst+GwTrOL1UUv/oMmRkmrBOD6nHPUJ55TWG1ZbojuLZhvjvFE7Z3lDpslRCrFW/3JOUYqUBFX2nFocDTnakhyyriqWiW8ybUV8XoCS0zIWAe10IadmrbkI+cMcCrgZ2xWx57kaGlyuTehdovWRlR/ZxYCXDY2LBIn8tQcfsT1t+PFb93j80Yajn7asPtohl1t0GOye12i+16NmN5Usum6z/ezW292DI8pNljdSRbxnevOY3duJbj0yDAHdetpz02pRc3Y15+Ywk2RJwbsnQw3LlWkR2lqdZPmlCcbLnWYtVwuGfNA/iQo+9zNfS70JrXKMOrtWwXCBPe+wAu+/9R7vffR907qH8cB0EZgKxzbVsGKJync/fJ/UOv7F//Qd4gr+q3cf4cfJNJfgjBozzYk+bMNxpOBy7gh7Bi1arTMHnb+aKsXM9ZFWhN/59Xf57//4JzZcIvT3Bd8HJCqpy88/KOwGfFLcVWC83zEeOfp7ntArqw8d/SNB1jliTpSjB1dcfP2Ie2drZNfPVYZFTPwso4oOVboyP66Lzy+QzZem6cHPFyvvN629G2HvInCbBtYd6ahj97Chvw/TvYhvIz4LvCJAl04u1YXAVdkTluK0arEpGa1Ss6kvApIrXtfo0JQFz+DwOzGOvFjIe/SKjEJ7DmGnpCDEtVEYU6sQFEryJxWYxNgREVyUzEQCmbJsFmM8aIDUKLFRpEn1GQHzB6lp8GP0jN7ThQkviW1sCJIoyPWD1Zb+qyOfHh8xbtYc/6lDniW00D5jvNane917Oniz173N61/yLdvdNN3DWbOcfUcbLr7q6U52lqZx52kuhe6p4vtE7JzlSdhFq+LQGn8VmLVal3cT5TkNqd55qXSIaY6av5cc2msUM1dDfKXKSakmmiRBSkZDJzln7SwgJPfhg0fv8d7Pvmfnl8TpRePVBGNEugZETaj77NTD+pdaOP/+/4t7f/u/JHWB5CXnxNWcB9iErGaB7ftsFhWHIIY/S0zGRFCMHoTxGrunju98+CO+9+7fQb2ZZHElNJdGDdPgTYvPE0/6gTZG/K4jbjzqhPUnETd6tu96eh84XvUcNQOPv+7pHx/T/cloTsgsQHXx7sXZ+D83P26SSl8qLXfZ5n7fhKTsHX3NPrT3JRiU4D10LXq8pn/QcPWWkO5NuJAIxTJLxYlVor6y4gAzE6BSshSNgg7eavPtLIG+H5kFXzL20LixU8I21xcs2fiuUg7qsXqD08ZgLN9DszVGTdgl3GOzPMdjR2wdqbFweqNelrqEC2vSim/belwoj9PaWV6TlSOuYFonpJk1eoApCZN3DNGZ9itzde6kQlTBAUdHPdtvKM9WHcd/GgiPL2AYLfw/RjTpcxvgTe/05nZ3SGHZ7o7pltm0MLcFGN5cMz6IdMDYB3xvBRt9nzIelRN5B6G/72nPjC2g3lnZneUoVOxUyQDVHmWsQAGqVA3RTWolfAqnlwRSvkt7UISoCSwTRqZplvOWwRimITvef/M93vvkAyvtPsX92PFpQqaIumDOOTGNWiblt//we/yPX/sO33v7W/zGj/4Zm9/5xxXHqsTwKe1F3AGVg2yshogM0eCMmHNNTBM0Ycazk20iGhLaKtNaCFdiPN/yXMKsYW53+H7EX7WM99eoF1ZPJuI60LeeK9fgJXHa7Xj8lRXtJ2vk2Tll0GvcPbAXFnoTiClVetx1dn/xbV868vNqNXU4DmEZ55AmwHpFPF1x9Wagf6TIZiT4lKlaOUm+U1LGUMuyqFBBzvWcVNDR4XY5YdOlaaS+N2VCSjBDhuVUoGsNtiIxb/bBMR57dg9NiErEeL7BBPW0sVqBkoTmmWP1xCiT4SpvBMGoj25M87qNS6VJn5snkpTmwiy1uHaMR47hFOLG5rT4QkmDKXrGaR4Xlz+v4fUKTTMxvq2cdS1HPz6l+9kl0g95+cc6Bw83xS9qat4d0z3QaEQENmuu3na4ZqS/bJFRaM5sxxyPzDnkc6TJtGnwvf2O6p7AlZTJ20XQeleFFIpBAaF4cG32udGEq11g0VedYQb1+fqqSK2RluuPLYB2zSGL1o9iAyk0nvff/g7vffj9/NkiWicli55Z5UToIbMkGgty+K0/+R7vP/oWPzj9u/y25IoagoVz+hzGqdh9Qqa8lT5VYYbdcym0ksI4ES4jvje4BDWTMOYqxOFiNA3aubk0j+T/YoSrHcE5ptMOScrqcWI8cWgnXI0tXZjo3r7i6msbjq62BrEUczhrvFUAL2GEQ0jhOk34S9HKMyxMqxe0Q7laPzvEHpxD2gY2a3Zvb7h6V9B7E25h7ku+pZn+1M8Lc6Bothod2jvChdBcQNiqwXfFOioO4ZwkKXU+V85OeT0G+nsewZL/T2tz0Ml6sqdPYpirS6TokEtP6hTXJHYrx3TikRHCzspiuVxZW5KrFV3cZMLfXWWLKVM1bZ04ppU3BSPacWGrdM8cu/uO8diROkVXCULM2HJx/qmlSpVZKJd35L3CGz1nm8Bmfczmxzvk7NKUhAw1/HzTcTkn7iat74Tpis8Jvhef4T3DWxumY0V7j4yCH4T2PE8Kb3hk2EaYEm5K+G2eDJkjW65Vs4GVlmahYyZtFsLJqvbasws+LQRR6RdYiO8kxgBw1KivPc22/HSyyNfALPCjQQg0nu+/+13e+/D7lr+2DELGKN12yjkdBEJmIHijuX3nJ99Dg+Nfpe+SWuGb5z8C4Pg3/9GM4yZFRhtdiWp0tBipC91nLyTU+HQk4C96Hvytf4T76EPSOtUqFBryWDoxuhG6D9uYmxoZRtzUEFtPuIysPm64ahv8cc8QPU6Uy3eUzU+PkMfP8vDq/nVSqtmn9uZGfj+1fSkFL9x2UR0q/HtfwLxhtS1sVuze2XDxDWjv7bLnPguL3KKSX+ZyDG2hp9Ehwyxs24tULS0p6U1VKl8WVWSMxJPAuBb86HC50vV0ZBt1WickGCWx9t/ZvLESVbk467ljOlWjGoasgY4OtxN8L/PahKzk5KChxXDO1Edb3+NxLgyQLOGUG5T23NbveCTEyZO8I7aKhITzacax2XcQ2lCbIF5tBra/3BDbFSd/BPLsIgve62lld9N4P9tcvhO8sNeXYmaeHrF95FCXkCi40ehhbkhoEMIuWYWG3gRX2YGBKiSLUy1v7VQHWh6B1JlX3+9yCsOlcBbmGmJQP1/Sq+xe1NwMboj1PhXvTDrnCC3XSWnez8aIdpZqEifIbjSBGwLaNYBNap8UnVw11UCJmR/73T/7fd5/6z1+/91vMZzCb3/wT3nwN393Xq0pVVyaGC3fQ0qwXtl91fi2sh1mQrgq3Sc7uifQixHVS+7fBvJ4Za5nylZFjo8v/GE3RKa1R5Jj9elEXAX60BLaCe8SmwdbLr6+4eSqg2Gcx+xAmBRsHUAPBWwR1Ida8CvfrltYs9a7tJQPH+05HLcI3OMNl19dc/VLkc1RX+lbSydZ1dxUUMlRXIvKJc0ltBdqVMspoU4Yj7wxc6IzaKHkhE4pC7pIuPAkH8wR1pjPIXWQNhHflNhfu29SmRd9EvBKakpyKIeEnJ5PFNpIDELcCDJmeKvPePKQ+1GgBrXAp/G4YTwy6NFFq+xSChEAtuvIDGGqE7gSUuOIRwnXJMSlbA24PQZEeXcKrLqB4WuJM7fi9I8EeXwGOtoaPTDCDqf2zW1p+dxN230+seVNLT94/ScCTWB40DFlQF5GoTm39IzVUxnB9XOCmprLdhGMUMyN+vR15ZYRIHv7mbMWpTTvVlK4q656+ym7mTOKmHoxx0CYoQzEIIXUeBOQedUUs0zi4h6quMseGbPg8g661rRILzUGnpwrwqLbdNY2s7D7zk+/x/qTibCD77/5Tbb/w/+z4sclWEJ24yxwnUPbQOoCcR2sr01TNUxihG1P9ywRtuB6yWXesSKXMaGrxkrUO2//ygCrPZ9c7vC7xHhswrh7qsiVYxo942SJz/uvToxvnczvqXKdF6rdYqZKhh72Z5vbn+GvbDvs3+GCur7/h0r94ZfGUFixfXvF1S9FTk62VlsvY7fLlpKghQqWxHixW0e4cKw+haOfRVYf9YTzHrebcEMkbE24DveEq7cduzdbhgcr0to4hdoEyM4ydVjNPTIssPXE0bLvhZAqtFDurVGIU7EYLUdIGp19l7K26UCCQQHTiTKeQH8fdg+F3YPAeL8lHrXGGV8F+vuO3SOrwuJ7pTmfaJ7tCE+vCGc7/OVIuIqEK8Vf5XEJVsS1eerQK0+a5sQ/heMLBZYxB2RMHu8T0zsT57/UwXo1z0Wu3yj3358ufv78CsPdNN1Sorv8fbRm90DQYGXPw9Z2q+VTuDHhr4YqkBAoZXLsgHnBarD8tkwzR1U04TPuuwc/VKyzjDIZZ6R+L8kyhrG2CDD1tnEYnjT3wfIvLLRsmLejkuS8Dbgx8oOjv8W3z/4ncwBqtv68I3bGEnC9bQ4Sc/RZwaCd4VfatLz38Qd8MH2T/mHD73/9O3z39/4p6//8vzYmhgN3tp1xY+eQaGHSKWQNtTENuzoz1VghMrmqeKQAw6lnNVpe4tQFnMhMfctjBgr9QDjbMp4cMR572rOJcNEwek9shTEkjo93XHz1mAfP1nB2AcgCQpfZ8oF94Vt/yRvVkqL3SreX9/FQyy2fPXcQVIHbv73h4peV4+NdzbwHsAxeSHFBA5ucZb/rhXBp66t9FvHbMSMPkhWESOgnkBXDPc94LzHcB79z+L6F2JI6YxaEC3OyWRFUgwBja1nupiNPPJ4MShBFyEJVgWTc3NRiJa0SNe+CFJ0liWmbq0jq7G+iMJ4K/eCQyeF3ptmW0lepheFUgEBoc0mqISLDhB8jbghIahDMwZaaXDmmF8bjQNxkWCSHFMcoOQ91ooQvGzqZGN6duNqesPljRS8un9vsStvXdOWa3z/7HL47e6E4ULxneLgiboo2K3kgSh4EkCHht6PFRDchP8ksNA1WmOGEasqLWKADzOkVvdQsY4fF7Go1CGCZdq6EAsuYEG/pHNH8eXEwKPVems3uPQebZGEOxKMG1zs+uPd3+Pazf13LupckPePaEURswniXnXEYVSvKIrcovPfxB6Qzz/fffo/f+/p7pD/+GBX4rR9/wL2/9p/N453HTXYjrjVtd88mirYh2dhgmkg+dVoL/cM2sxhM8/U7h1zleHWX0zopMEaa88RwzxNbz+bDyJV6xvuOwds0SY9Grt5ds9nubGP0c/ho3cBSmje0lNCyScvCVH2lhe51fbu5v1UHcPvjsDxAvIdVx/Bow/kvweZ0xzCZxVECEgBiZigooNHBzuF748ZaUdWIDClzy6mKhzqfzfVgwkuobJa4SaROqhW6/jhaZZZxylGSxi9PJ2ti29Ao6EVgOlE4iiAWkFHhDWNjWiayKKjPGmYiayCY9itAMfUDEBIxh6ZPx2LrQclRmTC09jnRI8njRjJWHQ0aVLtnuMpaujONt3sC4+CYjgRtFDImnSjWlr2PovX6kLj8RiLsjmn/w4j2/f57eyG28PnM27sJ3UWpDtYr+nvWCdcLfpexmyywRJmr+VaBSzWjy8PVPLlOzHQvobK59pcUZ1t1jhVzPydlEGYzdmGilyQ3CjWoQpx9l3IS86xYmImdw4Ar9CH5Xvb2kDGSOs942tCcCx8c/y2+dfVvcqayhEvgM4siNQ7RhBujMRWSGp46Sc0hoY03vuPliMRAf9+Dg++/8S3+QfAzJ1gsqYikXB24jzZO4zib9G2bI9Rs3rvJJqWxGARZe9xknuXUNLYx+HyPYbRn1US46EnNChz4XWL92OhvEc+g4Hxi+zasP94gT87z+As192revGpSltJ/1RkHLpvmX7SWGQL1d6Am7G4bpocbLr7hWD24qs6fZUsx4/E5dN5fOfwVtOdK+2wyeK3cKmeLS4Xtgr3vaW2/N+fQnAmI5Vb0oxUL8BcDcrVjLzG/KrjAtPYMD81S7J4Iq0+EYQhMR8kCHyALP8sbbQpN1mxHC4SYC8GqOcXEBH9lzGRt2fj1WcOviqMS2+WACOM9od95wiUGma3sUrLIse8mZfUYpq0wnghxlYWvTySRRb70vGmoElYT519vefj0CD5ZhLnfzYu2aHc7524l2EviE+cYH6xIne0+fiCTrs1hpl6MRpWr1JZ+mVDLmlUZDMkvayz8ubzzOsEVoeeYTX9hLxpKMgWkTvCUENysDUJODVlMsQVQDznbl8eBCTOYOcEFv0wJGSf8laChZTwKNKrIs4i2gusT6hOinhSchewGh0NtHLzPgtzwCPE+J9+Bb539az4I32T1uESgweX7/4yjb/4XwGIDmiwaTnZp1v6hPndsTTswpkd+H6VWZ2v4nWzFEsUfB1zrCZe5HnyBG/qRcBVIrWfa+ByiDX0jJLyZi+vI1dsdR0VbtreQX/AC/lkIWYFK1Xm1tdzbtWsf4YYFK8GjJxvOfsmzefeCmFzOhbC8luboMcNJm2cu55KN+O2UAxWy70CxzXdKuAItjMWhVSyMhZJSxj3miARltri8t7wc64btWw5ORnRyTBuroLL6VBm3jvEEtFVkMBokZM1zMrPdjfa5sWYwGAJzunEwJcA05MItN1mgdY2an8UYCgSYMjdYpmJSkOEWc9KVoKLuWcKNjmljwjd1WLRaiHb/HKWnOSOW3Bu5/NqK44sVuttZNY4bhOfLZXFR727X7qbpFs2qaxmPTJhKBJlM1XdDwWGzdleyIpU+FYELszZZrgtZACv0U4YY7H5a6C9krTVGNPjFc8os1JJa7tuQnWMLjdf6ayyDqhU386ZQMo7Vq6YssL2HYELZX04MDxr6hy3v891atLI6z4JFgSEZB64CqSTSMVaCS5lz7BzfevrDvBkkPnj4Lb7/5rdxf/AMGSPffvoj1r/zj0wzXpalbwIlic7V+/8901/6Lm40vEu9abtV8MbyLDCtiqMRwmZF98TZeEzWLxkyyyRzpduzSGw905GQ1ENQhnuw6RpkGPLYLzTXQ60hQ0HFGtHy2ZewXStsDzOwlQNFkBDgaMPlVzvad65Y+YmL2DFNzjZfZ1F+ZiyYwA3PPKtPlfbJWIVpqeXHmIzX3htkJ6pWVWGJp1/bb5n7VVo5WJVp4xlP1PQghbhWBoTm3Pw0kixxvglaKJnz3ABSIAVnfoSaKJ0McUTm9a92/B6lTIFJcMkEdgomFzTa+MyRpwo+ywxRxpVDxdE+w5zjYlpve25CeTwxfm8SxfmU0S1Teoz+lti9bflF3I/755gmYhL62le7/9ndNePPFJGWjjqmNZRs824y7MXtomGvJVlLmXyHO6+wP1mdM604lwKpARMicz7cJa+uOGWUXEYnXzcmE5CZyZCCM3x1jAXuNG2y9dZHwTTRMm4lMCHGquUKNumLgHO7kXDpGY8d/YOW7skwlw5StTwKJVOZamUQ7MEqXkwwZ4qcmzRrCY73Pvw+H5z+HdJRhzae99/4Fu/9f/67LLATm+/+fXtW76ERLt//Z/zer36XaS2Vxiv5nbiBDN8IKUA8muEHBIZWUNfSnkVzdsaIDCOyaSCC306od3TPshMyZQZIp4wPOtqLRcn2Yn0s8XYnc6DLl6gdLqwbNdtlW8InqiZwu5btu2t2X5940EzsYqgRVJZEZk5Gk5LgL0zghquU/QQ5KdMwzRVHpmmPY6r53iVQpYbSL4pIljBtccJhIJF6x3DsDP+dnDEWsrNs2kgtrgomWLUlW5v5M7FNXrNAlChz1QkhJ8eZ9Svmy9VrGj6clYRRELX5mlYKTXZMTzNOrCpISEwn0Fw6wqUyrewObsyVVqIwHgsTnrSmBp7U6D4VwvHA+Tc67j9eoZdXz790PeT+XidwZw38tvP8TsERqoo0DeNpk3cWG6ywU0s8DlZuowQPOBuoas6X/LKFiaDZA770pu8tYEXmvHH2ZIXtUDBYWeixwWdtNd+uVA7WHPkWSokfqdiqOeB0/lwwLXLx3BXnzf3w2xFtWsa1M41Xv8N7P/69xaYxswpS50mtt4xn27EuCskRZZYoR21cMu3s2x9/Hz51fPDme+AcHzz8FtPaktj4f/eUFBypNUwv/cp3qoNCYtE+7JH8oBYP3+TXkWGgsgjU2cJCPK02eDAtfDcRN02N0GsuLJJwaOydpwaGY0fbBBiGeQOsQ3aA4ebJ+GURvTetnQVi9fyByy8yfzudbrj8Gjw8uSSqw+dQ1ZKxqyaaUUEH09r8qAynHj84y5E8jHC1NWplsRKyc7ImIdJiOmstTSW1W4fabX6IECB4ptOO/gFIk2oeB8haqoeYdYNSlqe0lIM4JAtpHNWiKtavlNvlGJ9aG83Nn1dYcizKgrEqkhemtTCceuImmaarzPl4nSKT0Fwo3ac73GnLcM/PqUt3VilDRZgaQZssa0QX3F4hPZqYHp3gd/0ianNhGRxouzdDDbeHGO6G6YrAumPqZG/A/M5M67huquCxVIYFXC9b5eJa0Tzb6gTB54vJAvPND5GyMExZkpAZBnuas2mBBDfXUUssNGS1yaGVVYK2oUIPs7MqC+mSQH2hqWvR2mJCJOKvJkie8cize9SSzte48x3F6UZxNuQMZKkz7brQzGQss5JsKgqkiDYe7Y4MWvj0B3zw4JuZnmwOwP5+Q2qM2G7jAMnbz+ZS8TsLSplWzhwrahPQj1pNw5TZFuogNsK4EZJvWD0W/EXeoHIgRgr2jsKVVm3aqRBbLPXlMOy/hzz9Kp6eQ5fL4n+RGfzn3uoGLvsfXfP7i1Rh8R7WHRdfa7j/5hmNSzi1ZEQlZ0CMOU0ioNHRnDna82RFTtsM1/UTXO3Qgp0vxncv65sz3L86soqWm7/X2i9XBa42gelex9U7Dj2ZCE1k7EMWZs6EakNlDmg2FTULO7DPRbN2OmUlrHDzy+ZeoORFREChilnkWbLSVDlZf6mJqE7ovKM9D2zfdAwPkm0My+g8tcrdnF3QXHpw99m+4RgbCL3QXOV133jScYYn6rDYQzVt5OLrHfc/XaFX2xu13c/TWLszeyF1wZwyReCW5BbZrHRjMg1OtfIygWyeY1zcon3GnAmrVPktgQclEflSsy3gf5ngS0wY5uMqKyLNi0gx2GPpXc/JdixsMs1BGyKzVpuhEF1QvXD2TDJEXONqrPm/+pXv8vf++PsmeH3JcJYnUYpMeZK7vrAaQs7xsNiYUjLB2Di0tUoB37r8N2ZepsT7X/lNYtdZN6IJ26o9QI6dz17tYAvAD2rvaCpZ1MDlBOipcYQMP8RV5vUOARlGfD/ZWHiIK9tk3cgcVdrAdBRozjO7ZImHl4i3ZV6L8lNfnlj6z7ddhyUcHrLQ4A9hhpwTt39zzfjVkc7FnAN2Fhglh0IqhSEvPKvHihttLq2eJsL5CDknbL1ngeR8TpZD7kNVELC5X0KyY4QQavh+KU+lbcN03LB95BjuJbxTy8GrWKTZaAwADWqKRtp/RvPZ5L5Xf47NyWLVzkwGLEd01Dnb32DU0nA17s2Rum6KYI2WlB+xfNXTaWYgFfaHN6aQz76S5vGWqdswrYXkzCLzg9I+FXrn0WODGSXnbzC2CIwPIvHhEW67e17o5jFfqgqzEC7jcrf5fPsS7NHoW9NxMFww2r3ckCveOivGKLu8Ky/LNGccsxD9a1WG8gAFo10Ku1TU0sUzpZQdZItKwCLIgWCfQ1/dPjxQzimcX1UIDvq4f2/YZy7kBORLB5DEiEwBN1hu0Wkt/Ktf+Q6//Qe/j1wNptEtNgI3KtORJfcIO4ff2j3VYVBJxJK6TxEZs7kYrFyLdo1hrVOkfTownjZMa0f2h9UWW7GJn8D1mjWPvOkkFqkrHVLKGYklKxmdPUNcBcJuqNi07ydS2zCtnGkxYgIXB+Oxp1l1sO333kdlmjBrvbWfunyhr3Z7Dss9dEgV4bs4UJwj3Tvi/Bvwzuk526mUzvFEzaVyYq5LFgXpLcKsfTaRgqN7NllwTD+YNlusrcynxXnorKJE7UMWvLKc59nhjAjatRbCLqCNY9w4hnvCcD/hV8bF1Wh4rkzFCrJ3KJr/Fs1OMKOIlXkmIzmVo+bPZhbOYSGJktaxJL+SyljCrN5WSN5hybBBsMyB4Xyi3bQGqa2yRzgkw6FXjkYw9sHllvVPYbq3yukiBa/GbFAcvfekVTSEMycMSklouomLr3Tc+7hFd7s95W3vfS832Z9D9b2bptu1TJ2bccEEYZfpKMsk5KWjC/y0UlcKqwGtwtcEMXOax3JMSjO1bBGOi2qN9KqtCJHi3S8aANaFKujdQrtNWFawJth9l8664szbE9x5EWTmgAwT0s1a8LQS/tWv/Aa//W//pdGpVm1+poSbImFr5noKAp2rEUEEAZ3me2enXakQYfiC59uPfwDO8f3wXdQJsSsTwP7ViT9pdmaYJu2mtMg3kTnUmFCPjTk+fF+YD/bMmsdQvSNclSrNUpkRYN7qtGlx2549QXqdJ+pwAn9Z2osW2bIkuuaEUG3D9u2We2+dk7KQdS7lKSi1JE3RKttnQvfMnLp+O1rgSt9TGR/ZMUzTQBPQNhBXgdTkHbd0IeUNFigBPjIVx66jvxeYVpaWMbXGUPCriDglTg7NGi5gGq5kbbb6ADJ7IRpmKtEErs+ZxSqCaDSBvXqExl7IEaKTQQrV+VzGLg+xhoNQ/WS+GfMbidX+Kxn1nLEqivWJKlxuCeOEP16THrU2TlulO0+WNjI4tDEqahG8IjA8TOjpBna759/3Aca7/+vdhe+dhG5at6RcFLfmpI1m7qh3885VcNGcHJwSLVXa0smSshqWdI5CE2ZOp7LQfCVjqlKFkQUa2MyzvLk6a6Qlk9lCG6A4z0RIbUBbB+qQNFPQak7ecbkBxCpw1TvbjGueB+Z8vWBpID9+H9kNyORNqPc5pNE50zaOG9QrfkgZigjIOJkGUxLfTJOlyGtDZg9QU1r63qr/xs40VImz9VEqT4gqLlrqyVKdwpKR2zhJ40ibOdexH7BJWgj33pn5djXityU3sZB5/KhA7HylGtX3WiL8KHNlNnlJiX0S36vZbtwbykYM7IU9Z/M+nW64ejfxqN3xtF+b4plKdGJOyyhKGjzdY4MSzBJR5OIKHaeK0ZaClNo1aOPqhq01ET9zGbOaGpRaWUUmxU32zlMr9G8qdAbSOmdUqjh5E7gxR4kV+TLZfCPN0JLkpVq13KzZFgpYKcclWSEDrdGaFA33KuJ2U3bk5jwQOTiKjBqUTHl+zPM9B3c058Eizzo17BmD2IqCppJpev2AjCMrd4/dGw3jsaN9FumeKHGdU6oCqOBztrL2aOTqnY6jpw1a4NGl3CjvfjG/84fcdS67lx8yTzYrd0PNPi+RWjhRYpq1TJ+11Jo+Mc79KlpvyRsA8y5VilFOs9lRc8gKexCBDBG3HY0VkIW/emd0Le9nTXlcUGwKxps1Vm2cTaLBJoLbjUZED7aJpFUz83gXfS2p8zQnT/ejmtDKIdApWOJzmlBL+mgX7NxxQiYryilqdc1q+aHG10KV1sd8v0WSHZkS3372o+pIdJNahv7JnGjN5WS5gtWw9vJMYMKvWBYSU65IYXS11JTVZotWxqkSzwEb57rQbBiRrGksMcMyzjInSNpLdONuP+VeqXboUSvPuPwZGrZvNdx/eLnn8DGdwSAFEUiTozl3dM/snUlS3IWFVkuOYGPVoceW4Hw6boidr4mbzE/A/mYv+9olYE7T1qo/tGeJ9qkJ/aadcDlRugIlfWNtlTBkMILLEIIbC27LLGi9VG54fd4sfC3wyOaLabg6Fw8ocMhiTOfK2NR5WJobokW8FideyVnhqFBiDd4SQWPCPbmgezwaXXLtaC8i/qrsUmRRMCeL370BtO0se5Y/l/9+znYnTXdauepAs0i0NAvDRdgqwT9vnsP8+xJugLxoi0aZf7rFAq3UGChMheIoq9zEgglPaV/Il+9DM/cjmjD253HuV4YXJCZ8SYgDM09XbbjUm7BNTda0F+adeWmzMI+LBD7jNJuK45Rx2wmJgemoYdo4/CA1H6qbTJuVsvkkS5tZxsKYDT/k/UffAhFCn82wkriarD2Mcd8hOUUqFxlB+omw9bWEkVUgVsO5d3N1ZolZS45mkrky8aPhyOlkjXsa543C+TlKcJF4XVPiucxjr2ir8F2GpJ7D85bPUbLBHa3YvqM8bPp9Ti5CzIs7JUEuAu1T87ynUrZK1YSt9+iqtWTj3gTm0rdRM9EVJ2z+WVOYKgtmT7593jzXHyeS98R3SjJwEzaaPbG6oIHZT4yVUOCEYrAWRkMRroUautgA8mPXPvsxFw7ITuEyJxWM3ePnZ3Cj+SOUAjGYsHPREvBUgbvzdGcLy7a8qxjzuhvxj89pjh4wHllumO6pMj4UXLPUVvMrvTcyPTzCX1zOUOIBZr88/rO2u2UZWygpkhe5ywltqvlf8JWKg2CTaell3SPQZwE7JSz5ykJAl2PLi8yONLtuPr+YY4UbXDaBZUsKGhf4bFoI+GxKNyEX6isTb3bOSTSnUlpZjHoK1FLpZvIzJ48WYxCoFz5I3wJV3vv0B0Zqhz0vvwyRAKg0TGvBe3NWGfm7CPoseKfJuJXeW0hysut+751vz/htkBqp53Ym3GerI49/STepZp24KeGiWMhkVk1T6/EI0o/WjylCZzxh8ZItHKwqh4O49rjz8lwLbaAsgmxhiMhMdXrFW11nZQ4u8VuZQ5urJt809G+0dKc7puSZ1LDbVH5mbUq3gdVjCyZKrSN2Qriwuakry6EROz+vtRv2qPLOAdNUi2YooBQILQtEAC+4Sdl8nLhsWqYHVra9ZAGTSkuZhWeBFaqGmwV8beU1O5sPonZsCXGXBK4qabqXZApRVFxlLGgOn1dHhjAUl0plmGId23caHRqheyx0H1/VNKiWXElnBUwV7Qe6T3eksDK2zjYhvavZ0ZaSomkmto/WnPy0QcdFgodrcP19t8XdIIY72HozNlPwQmIWYIvy5iwna25aNIYl3lq0U9UZTij/auFHnQVjeaa9QIXyWZrrh7HQrpeYjDLfp+xeCyqYlNy0yj7TIQt7GSb8eU/7bMAPdr1SzjzlckCWGHr+LK4DaRX4/jvf4YNH7+2PS8GDJ6PFuJF6HXW5gGZxFuZzShpJo+LZs3zz4kd239aRSkXhKWUesOSY9nydJsxjkisbFxpZTVNZTVM7bg7p1Fr2yEVz2BWSe3G+7U+XoiVQx78WsHxlW0kBWB76RZqOZnwaK855vObqHWHTjow5D27M+V1T5ojH6GifCN1ZInmhP3X4XpGdpT5NnWdae8tfUJaULv7lTVGdzZXyvtRJ5V6DCeNCz6r10SAnOIfVx4pc+JoLt0aRLf/F2Qov/ShJk+YPF5beQgAXUbEMqKj1/4JHV40l/g9z8ViWz5p/N+aNbR54E8qAVSX+1HH849GYM2GGE3WK9k+zQBWBiyuaS1PT3aSEKyFlBsn+u7cQd443N773Oi/2Z8P1x93Q7iB0dcZaXDEvl4yCg/svtB0pWG0xYxZJcJ7DSYrAXNb0qjvkgSkB+4K1YIuHnsdl/l5dnFOoYEUYeF8ndqlBNrMtMLNlN9KcjbUiRglQmLHufBtveBqCZbrftLz/7m/Mk2xRMFKmhBuSYVZRK4c2Nc6w4IxRS2+0saJtuN1kIcR+cT8M/6rMkOVYlM2q0OnA8kmMmU+8WNgFY5dhque6TD8rsfTF3EyNzNbMoWqW+1GCJF75vAvLxXb487AVHNF7hocdet+0o0SONltkE1MVOGtoz+x9DacWzBDOB8sxvLKcz2RNj4WBV1kKZe0V4etnp9rSlIdZGFZYQue5FXqlfSJodObBL92scz9rtjnQYbm23aCEbcpMmfledQPwxoKJq5zlLgs64qJYwbL5OWq1WI5LzbhmUfPm8EUsj+7mo4R7ejW/Nu+Nu7zQSiUEc6xhIe3FfxOusMg2tfcyWyIg90b6R+vrhe51jIbP0O6eewGqE81CWXN4bUkwvoQRwARGKWhYFnpxuB0+WCnFs3gx2jamtSXN0ILM+HFKs9NMdS4sWZgPxTRewh3LopLlPkq+r5igPdTWS1FIMMG7TYTgLPy2vGORSp0pGmBsLINZWT1udLzv3kOmZOyGKaJNyLlBYx4bra9lUTkFCj4MWXNNVt9saLO2mYd7F+eqE3UQ89iV8WXehIxaBOLtOEmmRXnva2YzglHq3GTZror5WMYuebEk6ZcLiKHcd9kHXazeV7UtYa99G3Lv+5q+MiXYrNk+EtadablelKhCTG7WFXae1VPz4A8npsZ2T6NpuauW1Pp5VPJGXpXcRWHVYvZLMbed9WkOklkcm88tx9ZEVGopI/uHZm25SSCH6lZHlh78y9NGwK412ocW1cicb2H56peOV8r35cFsYARMiyVv+lOekyUKVLLl2HpbYwP4bd6sGo823Z7cmSmngrYNqfWkTOt0g3WkuVL6neWbQAVLNpCYome9Gtg9auj+JFhgSvFLLOdGfcBya+Euc/oOQldqcorCA1TBML8iUJcLfVHVoHa28HQLNls4iBw8TDEVSoRKa5Qr+475utUxVgRWnO9dossOnDmWZrH8nb9zi75lDa/OtLDA8sq180suE81NijqLFy+ZmNxk0UUpzJdKQVAfaM6nummUPssULTgiKhIN55aSVao4uNwMK1RcNpnGEXN+UynOM+9rLgrJWamqJpoWm95SmFYcUeZ0ksXqUEWGBukyvcjNGq9p2+UdKvZl2p+kZWG4hVr2irU95eUmTeYAIlEgnq4YH0Q6UatSK0pMrjrOUrQyO2FnmmbsoHuihGdbapXe7JglLVbDcpiKQNRSyy8L5qIFwyyoFnvbjPsujMOEVd299Iyt5Dm8eCDyu80xSJo175SdZlXo53cvcdbAC6XU7woNMfNyi0+hWFsi2VmcZYZ3aFTcEg6ECimAKRZutFwvaR2I91tbY5klUZ7N1qNFWU4bmI4Svnfc+3cmF8JVpLkM9EeC85pFib0rJ8p4orDu5pzVyzlxWEBBF4N2y3Y3R1pxFjHvvgQ/Y6rLtkhas7fgRPdNjIUz61DzVe8yp05wyWfhwfMCsAijIsxVspmWjFfbNDOlzWc1NDEL7qizZuOymlG0W3Xz/ZqQNWHDa0XNAy1Tsh01J5H2w35JGnVSk3jEBpqlmR3nSYc4yyVa+iblWZUKrvqSX6L8biT4UBCcAocEy4wmKa+mKc7wSe3YrO2WftaMcCXXhapBBzHhhglJATyZalbeG7PpOGTVZrkpFpbJYTXpV6ktLLHalgJ26USpXyviHbs3PKvN1hgK6jJrwY5P0QIP/M6GJeXw7HA55QCariYvqlis5jVRhjcL2uRLBq9ZKEmZojBrpTBzdXX/PZEhAB+V5gKmU7HoM6Tm5ljmWDfYKmurkgVuxqFKwisRSJLvsxQDB/oUUCFJ9c4wXWW2UJUFBCa14IA9DxV6SK2wfSMwHcG0VvCas5wpMrps+ZU1oriQiA6mtae9Gg1iuAz0USwfw6KbU3LQJdJRh5xfvhAOu84Quk27g9DNKQizV1ImnZPLdFmoLb28ULW5ataW75ZaVJlcSnWsqVjYo6jOCcuX5lwRHoX5UChRIgdCTGYBUu5VQoRJNRVkCb+teG9wMBaNTWf4pAinrkGi0l5NVplXFWRVo9NM+0ykJlSSOIIlNY/YdUrWs/K2UzKVwrlZ8BVMK2uOGtzMZQZLYEKerDGbZ06qwLXZx8E7YdYkvKtskML9rMT2alLl6LTG5+AXKOZv0SjA+MZ+1SHTnCpT8xwoNdRm0/yzTdZfeDt09C3nXvExlL+LabxZ07+hbHyiHwPOzQ+WohVuLMyA2FhODN+Dv+ghqRUdLRzp4jPJ7IianStbltW0xwQtxWBRJTmZlRfmjbQI3iqQnV1fvdBsE8OVlT6vEMDsaqh7ffEZADkzZA6cEF1kEDNt00UsjD1rnBYdafNfEci897IpFOFaEt6Um5vAnaPTCm6cGqxO2irh2kQoScpRvFPGyRNjTv6TQ61TbxBfbAXtAhITzWUiXDpik/ZQ0ZSE0E4Mpy2rjxy6VB7Ku39uI76b5XZnTFcXqnwJF42tJwzechgU4Zo1wr2Juwx0KBN8SeNKZKGTnUC9JWqxBN5pnylRhEnBb5cYXB0UG496rmYtu1SIaAJp1cx4cakAXF5+gU7KNYsmLUJ4ujVNJX8m/YRbWSHHMomay5nGpnkMJCbT2Iszq+6kshB2ZZEUqyJvQKQaaq2lv9mxppnq7AtdxpHpYVBKX++1Kuy19rF4xisbIUMLEhMaAmnTVrza3n/RpOx3bb05lvL47WlZWD80pldT4MJzltbeXFrMg5LBS4B43KGbyJzMBiiVaclCKoE21Ejv5jJCP0DW5KqFkef1Hpa/1BTTPPXrO9MspJMxCyrf2gl7TtSFZiyqlV/rRohucV+hRjYuncTqTUt3zMcmLzU9rznD7NoWSGFr1y3ymlQtV0qScAxGKzBieR4/py7VTEu0sHeY1pDWCd9NhJAqhGPjnyyD2wQ6uXkgAZmMMhc7B+Jxgwnd6cjhuljTWporKDEcC6sQZqrnco78nBP4bphuHniLSNGFEIK0anDFaZU9upUFYKfbZ2XnKHXTCg5bNMmijWbNVOIitLdimbrvHANAZ2Fak+foAtvNKkM5L3gLA/Y5SkhykudkWcH2NOuCk2VtWnZD1nyysO5a0trArLBN+N3Eex+/PweIsBiHaXqeEgemAahhozLpntUgY+boImhrTq0Clwim1aTGouNqmaRlzoiS3P1AmFd4IVqpk5ry0ZO1f7uvduYVTm2GM9x+GGrZVLRx4DykeaLuJdYWZ0r77SfdF9+WykD5+wAmqdS3tmH3RqBd7fKhtvhjnCWRRsEPgoxkLFXNCaQKbWdCV7DKCaUPZVofMBDIUHmVvKVbatBVQmrEly6vsXRylT0kmgPMjQstNs7HzVTBLPSw46Iz/DcJBkdkYe+neS5ILkxryoBDChWjrO9QIIAcSKTk7IQRGl+FbfGDpGBMiOmInBdCSZNjTI7Q2DpMyTFNGVrMkRouqE1FAT+YBTmtTcCv+kjYKjIK0TskwwxJBSeWIJ11Z7kYbhK0IgjPV5d4WbsjvIAVjyvmRBuIXcgOtqyxBZ/TFabZrFcFF8pl5hdQvismfnGy5QeyLVVmARSwKK+FiT0LkMXfS3YE5ImWt+0sTK26Aznh+CwAZXn/ir06SrUH2eUF01iIsDZWFy01tpO6KdOs+gW5ujznUiMvpmCBQfJxFdOD+RjNYyA5qZBhFfVarp/N/r17lsRC1fEoVAfXgVYnyVILWm4HZtx9SV4vVEGdo5hmc9gWvi9mbgnCqO9cqfbwq96W7wv2hK0uV1jTMB5D4xJTZirY6TInBM9aoR/N3DZyviWzL3OwsF5KlJc5qqmme53bCUo04TKLlySDrkzDZWYWFYy1CGo3X8eSz+zzc8u1qjNvsaEWp52Qp1GTiRMlnXLuixu0Cmq8EL3HTYIbLBReM99WMxWibN6pKWtshsKM/WOQwrShJjI31E/QUZhE8d6iMFMsUt8GslQoFp81bJchhgBx5S2JzuAsyTk2j1MSC6hcJVIXDiHp/Tky/7hTu5Omm0oWeWWfklJNVJlN9ELXKj2LEWSBjVas0mUvfn7rRRgXlkHeFRGjgCAYofsQfyuadIkkKRFdKZn2BTb5guVnqKGUTuZwSp81ye2wh+Ha9WWGHgS08VZdofAkyRtRwZZh3iyWgraYkUtoJV//OewI2WcrCCgyp8d0hqdrMFzOxcPziyZdNOeFBldaMtw4ZnOuDGbBFaspKZatLGbNxI/miUep+RnUSc03UZubr1nGQIbPNll/sW2xEVUP+ix8l8VQyzFp0xJXxjbRrGHZVFXTSqMxPUjgd5nfejXaOw0hW2TMm2WWF0Uoqpe63iqzIVGTypSmAq5XqzHWGO/V93ZiXZ9kQZiFHWIQgO8NJtDMsql7clFOM55bQn7r5iAmDFUgivUzlARdCyZB2CZkKEJPqiUnxUmbNd5aBTwfN3WOuLL7xzVoqzW9ZFXFE6TBwqU1ZahjkVdBS0n7JKRG5/mtzNVWRpBkzkRN2XmnDmmT5YuGef1ds1Y/C9pwN/aCz2q/o2JRlupvMUELo6AwBUSquasle5K6arKXyKlZK8oD5a0kCUWAFw00awe19E45viRHDxm2KDDCXl5fu562wQRVcU4sNkiAmqdgqZkuk/C0DeOppY2rgi4vnr1QyZJ/oMAdkjXU8qamqZYGMi3SZU5yvlgyapmuWuMQL60DgRqdl98Hovhyn5qlrapf1AD5AuGkBF1bFwOScbqkZvaFshK1lgCXkPdJN2tbdZ57096kX2DVy4AMmLW2V7FV6+CgHeK6gDjHeBxITUkAnrHFJPhQcHpL0OJGCFdW4p5dX5kkNnbKYZLwkmuhKDNzJrtS706q0CzGYKmY7YZ5g6Y4vIsjjcxU0Nli8b2Z8FNe17nb+XmhOPIssYwJZTxVg04tNd1nmsi5Q3KuhVzgQIMjNvMzSlEgyiaQnfRutNpw09pZgEVOQ5k6o2TWUGUBCTmZecbPZcqZ3DIsgc/jWp5b8mYFxvXNebDLOBVlzoIkLPvYtAo03s+Kz3Vz4jNoD3cUuuTtz3LH+t7oUbXC7tKpVTraNhW/lSIMa+6DjNMWja5G28ic7KUIbVg4xJgFT76OOXv8TBovTrfSphzf3oZZYInM2BdZgEwzq2GvGsU4WR+7lvFeZ9UUUjanplQXiEzR+rAMufWu2mfWR3Kl4kStSFwFqFtotmWRK1Z/Ks3sjOystAnt5gXisyNyKTxKLbbncl7YZ25KtWqBH0uhzPIuXNXyU+urAyaV4D8nFcMDey4pG+siWf0M1byKWi5USbP0HeQNN+tW7JUaCp7xyIGPpCx0NQrkUuoo0HvClWmAfmeld6zo6cyhBuYkNnEex6UGXOdWMqGyvy2YEK0aZFqEbjMrAAYRlXwhMzwnklM3TsybqMNSfrhZ2ApALlI5b7L2s9DhgFqppLzkuPIVly3smOKMLTRKKTt3gGltJddTsKi2dBQhhyqrU7Mcem+BDVArXZRnSW2aB6gkjk6m7JTnCZk77HpwpwGOygs27VhdDt9ubpgqC4H7C4YXmL2pdYELcpVfYDGrc9hddZoVTZZ8Xt6Ra47dym5YOH7KgxV62PJhq5d3saNL0ZoXgr9ErxX7LGvdFUeb0p7QLbk992CLZWIcEfRoTVxbuKYflOYsJ52O0frvxLTXts1jkM0lEQhi/YM5x6j3KGmPWaDB1XVXPdDibNKwSEwC0AS+9857czmdIc2CeUkdC8zP1ASbXzHOAjy/i4LpKuDH/H0Tap5kB+ZVXrwSN2k1iQHL/dAEuz4s8GTbUF7dhDeyZ3GJcxW/1aIB5+eQPM9jC8QsiJO9G8U0JnMOCX6HOWymODtRoQq9UhxVDi0m3Wd+FHO8BiZg8wEWyhBUTL4yF+qOwXxfZebxluAalT2KWrX+EpCLkda/oWqOfqAWQy3fWaSm3bBYToVdYf6CRZRcXX/F2svOvYxNMwkEzfgsxmOPgttlB+RgfGENBkVIzIFEUjqJacNZq3aTjdF45M362MJw346VDDGkJDhnFZHFOSt7tGwL6OkLgBeo1JCSDjBsXc1lK3vefp2DCWAOQ11OBsnUlmGaj/cyC05KtNtC68vnUOubZXOv4ohZSI4L+loVzIr0E7rKichVaxSYy7Hh00mH6+N83RzNlU7WTGuTNr5PplVsB6uGi5hZE5n762zyl7SONc9vWdhTqrzkkn2pZAizn7b6qsZZgbisJkzRYAfJC1c0V4dg1vAPA1aytimyuFbWxDVvosmDQ+YNzOUE9UUTz4tHNTttdF4gVRh0WeiWMOKlo3CpLb6K7TquecG3i9YISBOy9iY1Ms/w7WLCm0BqrhS/TfM45yT8xcopOD2Snaj59RbeaxlX464zWxQHLh4LrCgwAotNejHaaT5GmI81Tq1du9TVq+/SmdY5rYTU5eNLVKpS6YL+Kj+Lp7JgSs7dUjutZCaEsnkXzdt2BSlWb3Z4ywRh55iOIDWlPwY1uMHV4AzNcIdTLFue5ufPZeGNamHYcHNmt5hWxqww57cQu0xlTAuLxbNQChfjvVTMfuHwQhnoEvS1cNAvzeEaAVY0hGKylUFd0HEkana2uIpPAouACsnmvlSBa6wBE7pWFHOBW1VHnJuFdUzV2y+qMOaggwU/UsUiVsYjh5sc7Vm0aqwxol1rFRSGtMgJmu/RtqbBVO3YBOIHx38bgufbT3/I0tkkKVk+BlcchFRvv5TFFgRJjuJkqPQ8Zx50mRLatfz+V79bceWC71VqXMXYszSoeLrOm195XyJzTl2Xzbgp2YbZhNw/u7aUxCVuoRExC14NQiJru6WKbdmI+QxqwRfdFmOy3CCWrAUB8ws0RQBVSZidXfa330FzNuZ36hHnZ19D0TTjHHBUr1Hukx1qBVYgJyXSYOPv8jyWOJcblwzjqRqjBGYNsgjBZca4ou36YV7fhckialTE5A1KdKOZ/OrB9TYOsSlaql2r8G2LZuty6agK4yWFgksrcyaz0ueoeM2Ya/EhqTCeCBqyI02tL34Hv/3Nd2u//9//y09NomUhLKMpQ+oUnBJbrJ6amOYuOam8HFBxNZdVCsX/ctiKk98mxkun1GG7e8KbotkkrEZW63C7HBWSI8RkabZ6Bz6btMHnhSoz7UtAM6fXzNTi8WdPu60akzcsrE6wMc6sAtU5327SfXyzaH8pIdse8Y501BFXVifM91oDP9wE/mowbfJohToxr3NJpNHM98A7yz9R6G6FW5MDLnThBDQqjZthk+LcKlinQDEhbYdOdaFUnBtb8N9/5z3zVDvzjPuSWWyZkQ1mMyu/u4opLpxtVatXu78rPOGS3SwnHCrUMM2acbl+Eb5TcFZFo2ykS4Ff7d8vgdCFKnjL7/tMmZxKMWtGMlLVPm3U8PcsgF0/ZZqUZSQTyONOdZDVGmPZaqm3ycqEepkDCrKGahqo29dcYdac87sstfZm59qCsZMVFZnAJSvpYxQtydM4szGKdSPYMaUmZvYTWz5dyXiupa1MwSyA5KVKGWNe+Jo7wsWCQUtVwGqmOyDHQiLRKJlxjd07GaTxX/z1d9DLOcvedz/8Ib//lW8SWyoMIRNGRcvWR/FdFGFfsGaiZMXM+L2IZtKA7Gu1RRaVloO57jKt76bpBmxCZZA9tTB1QjM5khP8Ig2gBgduUW49fy6qRnPyDtFY0zzKFNGSKq9oGuVJChSQWQBujDCSTeDEtbsRC8ddE2oopd3MBnI8CgzHNhlTMK9rs1XaJz3ERDxZocFqhAGW1Uiwfjgo+Rss/0EECbOGP8WaOtICGlIWeKYSGGUNC8QAE7CjWjBCDcYwXq4WHBzQ1pPymLlJYbIMZe5q2Mezl5znIvhL5Yilo67QiQpBPmWveMHcyzGqaDsHUCzNS8sbYOObPEgQnM8OtSHO1ktKexrjK9uWi2zZ38W4GTyVF2wRlkLFtt0o+IHq0I3rgNsFtO/zepBZgy2twAuLuVo1x+w4LpqtTAursDBWhD1hWz+rfG9mZ3V9JnBDJK4XCY/IWm/+3WcrKoWM+6Zs7So1i1jYWSIZN0bUO4bTkKtTax2nuTy7Cdfi+KsaucjimaibQrhKhLU3rq4oPuYqJjH3Ddsojn7zH+P/7c9MGWkVbROMDpnM0ThXLVbSKEzd/JBuNFoZThBJhu8WeOG6+fAcvFDG/+Xz++5hwEKdKG4oHy6+z1SuyoEteQ1EqMUdy2J2bpGTl/y7zjjs0hQr2CfAmGd65Z5KFYCzdl06Oe+ie8/hXSVKSzRzw0WMcgOkow68EJ5ZSea0bmsBzP0NQWr6PA2O5EIW0rYh/ODkbxOPWr79+Af4KWvkiO2OmZ8ogPqmsho0ly5xU6qbhWVcsxX5g3t/tz6H38U5A1tYrODlhlXGZ8nTXWLuy02uaBpOILnZB9PMUyX5vEnFOVl2WaS1LlbM76jwsYu2vz9dXq22XDCHDrUCNyTbjJbZr5YOobKK/RU0Vxm/7EwAha6Bc2aIfnnrBS3MPmBO6RhnxWVPSx2zIlLmnyubudYAlj0EvbxfN39e4TU3d8gsMttsa/Rpxu8lyRwuPOaQZgS/nXBZ6ZIp0VxK1WqthmDax5frveb8HbP2nx1U5VlisogyhZIH95uXP0TlHxu8mKmrkh2YxpIQcJor/9oGaTQ0sT53jnQ8V0c2SEjtHBVzqTi12IDLq33hu5wjFfO/PZPh1kJXhMrRzWHO+B1WbmRrJoq2wRxEZeASUCLTSuDBlJB+Im3Mwy/9mCEDyVDAnIAFyLt4Uet13rUzRlgoWDZKoKumnlcS8hTOsBbzDs1c3fxwah7msEvVSSdJcU+2ME3o6VE101JnFBgrY5JqnHvRwsdTCy0O51huhn7EifD+m98meeG7H36AG2Ku7mA0N3VZa89MCW2zhZDHUsXM0xKGu4yAKxnHaj22IkAXcMo+jlg2qdlEklxsU53gkuKvpgrxlCKC2njDncuOXjZ6V0xP2aM9adF0J+G5MkyvelssrqrHSA7/zX6KWia8HJBxy0K/ai9yuK9ztaCrOsHl65hQnG+w1PaK4K3mf3W4MW+KqbBGtL6L4pRKwZnALfmds1C4ydUe22w5LXw0qQHUBGbdgFK2rraWLCdcTOb3KCb3Iuzd7YTQOjP13WIDKVDWMqDGBoBSkWZOXZkjH3O5eb+1dI0FC67FL4PkKtY2/pWhMc3XRiBuEv1DR9hKrqbtGO9pfnYxbRfmRIbeLEuzmEuKgUUqg0PYaflCX9DuThnL0SmSvZ2pPHi0hebGaGusJGQpCzbjn5rxXBnmhDgK9l3OojVH29iCrVpAxnmLl18WL7EKk3J+5QPLrOEFh07mPY5dJqcn8zKHXZqzPQFyuYNhRE82jMcNYWv5bgsuBJCakv9WK3TiJrUCnlODn8wWk3HCDQFde37/K+/h+8R3f/Z9ZFi8OOdm6CBvuqJGldFcReJ7b30704uMQeG2YzUjl+HLUqLVMk2upoKsL1L3vbJiVV+jyxO/BqwsTinXWgZ/VDU4X6oIgvK5ltlfbjt7xV+1JsX6uq7lsjwAhd9caoIxUhUR2/RsbVgk1mRZxHL5Jlni7WPOY9z6KljVGQvFOkSFKmrCGJcnRsbMiw/Axru8m8W19OBa1YKxPptAtk67SC0XVRxhS4HtpkTszKzvLqNZgGDW1/5UqYqR6+1GU2dC0cEceZohhsr8qNGc1Cg6VTuvsCvM15E1y4ybm19j1nDdRIV8JBmmqw4k47TjqRA/dUb3XECzldusOdwbsZSRTVbUKhy3cKAdQAw37GnPtbvBC7L4mQF0DVaIsc2VY6vjqGCQleyf+7cMWCg4LVRHWcWyKkXGVQGgZZCcW2SIzw9dzKEaekx17BV8U6b5nsVpANnLOiRiKb5Yksa0Df2jld17lKrNwSzs5+TdpqVOOb1j7BxubEyT7wfcuaJhQ/I+J7IOFj2mi9R3JYNasgfQbNKn1hPbMk7geqvUa4t4MRmcy+T2xWTwiyxWeVhMq1gIAM0YYYmwK7zkQhXzjrj2sxMmb7xLLNfetQkCVxyJhQtc4KE7TbYvuC1grMNE1cD+RuVcDdGtHOWsTdVsW9P+6hM1y6Umy0lW+kn8fC1gPxtcyYORhaWS71f6VqCGfHLK2egq42FpGRbhpvndZzZKVSI05fnIjPsWmZ0d1eoa2/C3k0V2Zsqi+XCy0xWbB6nNfPgx4fO4WRHUeWMAcq09IblSFzCvr4nK5pkhECqEEFtDDahzkBpQETvNz5U3JqeZBjZr66n1xA4r6b40viIIVlVCopC8wy255kt/SJkXZf7cUqG4s9AtlRDUQ8he9vEE3GgBA5IUt51MYOzhXgdp/mBfU3IzXmo9y1pxZidUR0V2YKgT6BoqjAEVciDl6LSyK2VtUPPvadUwdfllTQbUo0aTqeVuNJGOV0wb21XDNi+MQo+Z5p2WBH5KpMYxrS0CSZIybQI+m+zEaPzfzqCB1AkSfU5Wk+rkFbLlkC0AFeH9N74FKGGbYYmi6RQhLYKoqxuYLfxou3aZDFn7lfIii0a6TLgjpunuMRyy8E/BNI6qDZWx0Pl6NcuUgtuNs7m5nIze3WV+fmFNk1q9sGVE4AsWVKVICTUXQuGs2gFaK0jXHNQxzlM+h6tLP0EXZjO7siKKBrvYjMkfLTbGUkJd1BSQ8nsxu80MN4zSWCkLDQ2qY1qGyTjnJUugLKQuAt7hWkvuVDTrYslWP0q+HrjqOFcxbdPKQinffvyDqtGC8MHDb1arLjW5BBYgWQHwvVmSaWXnSI6Ke/+Nb/I7m5JI3ZSBi+/9N4xvfxMAN2QKpFe7/yTmtxkMf46rLHRtv8nOarP4ktPMSrHJXKGlZTtkMXD7OX1roVstxZCvXEyayXJcxtYWpVedtdvFBC5OKBln3Ec0Uy0KNJA11po/N6Y8kRcvtEzE4HPIrU3Kit9CDeFVMmWs3C874gzDtEuFnRLOe+K6MRbAxc6ExXpN/6AhBfDJNNcSFLGXLLpkdHLCeOSyILZncgs+MOTsa5NFdn3vzW/he+U7n/6gQhR7XEYnvP/gWxmySDX1XdEkCryiRTOBubSPdyi+aiiy9GZXXLJsUFpNPXuevCgz3KPB1fR7vk/QOaayAeZNt0SoCaY1hYtlesni3sdSYB6tcJ88NS/+q9YOPNOVp5vncX3rkmP5i8KzlE9LRUIxIUV20JZNqLyHJmexiokU5qWoOehirhNGZiwUjJ/ZeoiYoE/L/jEHDmWBNltmbn5OBRcjcrm1kPIyN2JEloJZpDqw4sqRmga/84bnTnMuE+ufWjaxYmE6Wx9uSrz38Qfz+AXJQviHyBj54OG3cLkk/bSxNdScC2FrCkkp8rpkVfwPf/ATvvPJjypc8v7b37Q52BdrTGkujNKXGtAj6qZYuckYvBjXMG3s5RnbQcFlQsDSkVqw3Z9Da7ibI604vnPuyeJEUw/jMTmqJXvmS+KZ3MG6mGHetQvfVffnag0FXmh+NnmyIM7H2m5qzrfigCgmcfX4L49bLIa9eHfM9JEp5VBNYXi0ZjyWSo8bToRWHc3FRM2WpHOSjvHYM63zYgwwHjna8wIdCAUbcZMSFxrI733tvZzsIz+rzPQ1N6nRyKLW3Llm/uax8/N46dJJVjXUDPpTnFyphjuX91JMVCjayIwNF5wtFkcQUuvALePyFSoGiJIXY9bgy72ahunhEeORY/2sgVdR6MKcpAj2N6ksgKXg79mbX7BEy2A3a74lnNvCbKnUyVLos0QLFgfsMux3iadC2QipcMC88eo8vgUPzRtiCZKoQTfl/Nwk5e9Gs+y05Epxrmp2ssyJnSGV4Vhw0ea/9wJYFZXUmjD3/YKNpNS6Z+99+oN9qCPlPqDghW+d/YjvHb1nG1ULsS18Yo+bcmrHwqCY7BgcfP/R37XCmmryp6w/dUpzJqyemuyZ1o64EpLXGg0XroxCZsES1rcUFn4JlRpBR9F2DzMDQp0f4sy39bJ2a1eyFg2zTUibkGCxyXYVJa6phOhquuaJU3HbxU5fTeFqIlM1vL3UhY2ZuQUvriYszBjyQnhUrLK83Mp2cHZ+E6rWDVkDSdlEysnJ0/0jdg9cDv4wSKXEg6OKv+gJz7a4y5EUHMNJFriZaO17mFbZFHdCSQtYpvy0sqxLpVx1qXElWfgWKpZERXZT1eJr6sjyTLnfEtOeFrbE0OeNLmO0Sh2fuTbVYvGWS3eBae2Z1r5itdNRhkYWqf40z6KyIftB50KYZfMMnumNY4ZTnzHwz64l/MLakmFRGBvluzxn66bHvEGWUjc2H6kb0rSew6dL5i1SMh56EdxilEq8syKkWfgWTm4RnkWTLmV2Zo//YrNMOSotO8pKlFrppykeB+yAKcI4zqZzDtzZM6ULLtw2jEeeFIzp4/tEaoW4yj6DSYkrR/8gGE3sYmfQoJp1W/J31LSPeRy1rA8nvPfpDyl5hCUab3a8D8M9rJx7zmYm5LGZMkRYYgc8aKOkoLhBWD9OhKuI30aaq4QfzIKI7cz+8dtEcxmN/lrocDnBjsESC8fZYm48z1y4/Zy+E6brRpA2Go6kQnI+B0loDqXLAmFBwK4yWKRGpJkZ4kmNrxrpXtllmM2w/EAClBDXelwxYerkswrCBL/QnPMC2tuV5o5ZysJMvcp5TmPrCFtIEdwA3dMJf7GrprhlUAORkZASfmvm1XgcGHOGpL1Wbg0ZtzLBXLytzUUyxxhATPidkDpfHQhLfuVyoVXhWXC2wwmxnCiLKsZ1TMt8Wr6vPMli5xiPzDFnmcdgaouGTuVq1mQrHlyvNOejsT5KtJsT0ukRwz179+15Qks+jletHWow5fdlAdRyaN3U8oaThUX5LLZzUUVjhBTqZBG6eUP2M7e2lktfjHHK0Xx+SJWja0qHYaRLgeo0oTrDCqZ5zxpxlrXV8VYdxtkJW+GUbEoX1oaEhnh/zXAqdGcmqKajOV1j8haJKAnGtcCpZzU0c6ZA5wzbLpF12VorTt4y7lYTrQ7hrLiVnC/JoKzUmHAtTsZUEgdmC9yNwurTWesWwA0Jn5PkVCoaZL9EFrZuEZJdcPhhsjG5TqgeYP56DQ/5unanyhHNBQxvWw2hmITYaMUXNVgYYfWaMptO9nBincrCw/DVJVa7MIcLW6HiUuUaVJO3tIrlLrKW1RyvY06zuJjkYAIltsa1tcxfMife9h5JWO6FMeIu++eFWJO5wDFCPyC7AVGleyK0x2uGB13VXvfqrTmjwGiwj5ttmSQRN0y1KobibBHn8M2q6S5319KXygbRSiWqAjg/70yyzw7JMtFFauilOttUmWIOhMjQSmuLwQ+mKcQSxVMWQ6YegTkk5SpHXBXmSNvSP2wMo7tQmme757M2vSqtpLtctjzO9i6Lf0DmjRvqWJQoxepQcyXIRXE724hMeWCek/AcIwZYJJXRekyNVCTr2jk38p5GXqEm6jyo8MICrpAx2ua43IydM0hhMR5ytGb31pr+njmt3KCMJ45pNa/B1IhBjTuL6IytkFYef1kgFNtcUjBYpibU0TwnnUObXIiygbiyaDAZpc4vN9p4xE1+2uIqyEltiuvAjcLqE1NkFKEU4jRc3K7jBiUe2fNMa7dXwr3CItlipR94bv2XsX7OmfZ5C11VmsvENjqaTFtQr6am9460iYxHmbbi3T5gXyZAefFLfJd5Ys0Ul8VEz4KUhTBfCpaqwWa6TJk8SoEExATTZEUc06phXFtW+nCZX3rjrTsliMIL4ay3LGIFvlhOzmUCnzr4hgXK5ZauH42fuW7wO4u9J2uQBX6JXVYQdylHovm60QCWMazQwNqMj5fnL/ctdKO4cKI4WZQ+WghhyJsae5NozmIGYWuZxbS1aeFHZVrnpCAR8NRKAmRBXWGFPp8/jHuTM52siZ2Zas3FZEm8fw4nxBfSlousjFPZpLJZDMw5YiuflrrZWtRecaJFYwZkyMLmtdQ5XYo7FqwTWQjgA9x9KegXquv8njMEYZFcpgnXBEXMmrT04/MOs9IvgK5lerBh99Azntgz+ksTsNNa9jbbUs0itmJReGrzOK0s50pqPWnnajBSCg5HqsEb5D5+/81v5TpoLChjluRGg+GtkOdizhym3rKO1SRDPTSXRcPVKnjLeX5H9ckklP6+0FxRq2CUDUomw3yvZeAsrfD9wZsH5QXtTvBCOJ9g15DayRI1kzGWHYzHOfFEECsu1zr8drLJsnBs1U7HZIOZAyaq9nugsu/nEJhpZTXCBuzcHPNdKGXmFIuV+aJAyQkxrW3BGC6Z+5Q15bhpzam27W0Qi5Ct6l25WJktM90LDJ5gnJBhxGetw4I+CsOCKrDGY8fq8TRrOtPMva38RE2oOJal12sgSbmvYNF2an9LWYwFfsljVLzuletZzs14sZnABV4w7SU1EK6YHURFuy0/8/P4HVY/bjkh25b+fiA10F0p7qp/wYR9Bdpyc4U9TabShpb5cBfvskI1HtzWxnha56TwZ9Mc0VQ2uSwoS36kWoVlCQkVCGKhuVp9MSocMVsri3dZwoLzuzbfQt7QU94ECsTjBGSmBxIC6XTN9lFD/zB3OTuTK77M/O7nzGW2pix/LmwfecCzemJYdco+DFe03BzIocGjIQvctUGVFHzWq2m7Qi5Imcc9yx71SqkQoY0SLhzdYxvQgm3PVpmNtRu1Os3Gkyyod6Zc2HNI5Vo3l+nm/M+HioNm9fgW7W6Y7uWOcNZazHISw0AEZARVwRXtM6cjXOKzNYigOCn8zOUD9pxFlf5Sniu4vetIXOYKyFtTFdARVzS44qwjT5isGRZTsDiVanYzzSyGs6KN5Wsfcjcr/zdf3Dt7+WXTaILVautHw7FbP4f2atYUxbTd1DrC2TDDKHkiWr9LSfjCGJgXYc2sVqGWsiCKl33Rt7JR5IVeTDFZ0PTcpBY77z3xqKG/nxd6Eaz5WSs/1VPrapUcrDV/b94MdNUyHhlM0ZxPNc/DK6/pwvye3TyHaotpDpn1wEiFFNSpkfIdedMS2sd2ATmELkTqeUWA1fDiWmomd6cIamUBXTALlLjQejFt0ji8VE2ylO6Rftp7tpKEicYzPlizfeSJK9tIgZnPKpLzh8jsNBSqA7nCpJMJttRCvBKai8SPNn+Hbz37kflQEnxw/5s5tN3qoU1H5nwuiWeqwM3CVsaZNWOCxgSxaxIaHe7Ms/44h/Jn4VG45ZIdeOozvDBpViqgfUpN3l/HXOy4cDHMm3DZiA8L1y7e5W3b3YIjdj3rT5XLd6RW4JyOveVeECWuLUAgbONe/DRl/hRtK4dEVu9uvvwciqf7s7xMpmiZuKqHt2geuZre8rHlYNGUgUnNrDWYyZwTS09xzs4lsp8zs2iLRbN0Ml/XLb4PWWPwzuzLXIxTkhK7gIvJHA6xYFcwbhzhzJ5t1tTLBuGrwK8FL5NWWLEW2FykyaylVBa83OzDrg6BvdzDgHaZGlO0H7XrxMYWVCnRU1oKsBxsN0EoQSW1YoRY4U6PzY+YrHTTjVnhXrFWFtp1iyslYyMIxl8tm9DCGgDqQk/tHKgjJY/yGKEx+lit4quzcDOzGqNj+SJxySZ5WSizsCsCuL5/wQItWPSlFfxO53dkOwGFxta/fcT2DUEb6mYqiZpvVjTXPcsh46WIZck+6Pv53s2F0bzsb1OUfrT526gXYmN83PHY1kFh8SBatVrJEWTaJhvjQklkHl8A3QaaZ+Y4C7tIKaiavP2sVoBKHZ9SPqiU4ykWXR03UfxOkN0wO9GW86F89hnb3XIvqNI+7jnbtqzvb+kJjOtImjxyEdB1Mj7rk2SctcYZflsI+nGRizVrtDUksGi32UQSiuaqSJpJ/3UaLbNllf7l8ynYVaaJAZYbV2DqnGXA1wzoD1MWQAkkzCXWb3KquHkB1JaDHww2iTk3p5s3jkIFihbxJslRaFbDPWifNYQx7t8nqY3hkldLfsBM4arho1WtndfjjHvPY1S8ttWxkCeQIvhdzhcc/JyMJEMwsS1e41w9wC3uo8bwcH3c1wKcZ1obBNJsk8E/zkEb4MobH/pVay9ZWCXLmKRUOaG1oHUw7726XGtuB4gt7LgJNKVUUcaHJcV508vwxFyoMbcynEXOFuFKdo4t8yQXC6RonGWvyN8V2prhyyPzLm0Hxnsbrt7KArf4lo/M79Gem6ZY+MbdUwP44yr3PdrG2lwmW1/BrMlwZTkobEPKTI6kNZJzOjI4QYNSkr+r1/lnSBmWkzmPgscyhwHhwtE+s/uWzGi6XJrl9WU9C7WKEWhOxh5Mwx3Xkt+fmBadhOZSF0rIwsot82TPn3M7WKG0u2m6KSEXV3SPV4SHiegj2gmcebqnsPPCeII5cvqJeL9DRkuwXTSv6kXNGmLFep3WEFQpGl1lLbh6npaEF0uGxJK3uojMsQxehVGR0FVn0S5Bc1ahhDYh53FICw2AGVKoDjN3MNBZ0yl/Fw01mcDVxpsATybYfYmGA8IuMB3Z7h1Xyu6hZzM2Nbx36eDaY4DAjHs7NxPcM1xTKDmupJCsTrL9KKbZCWPP5qaU8VhIm9bI4wHLLyrgJhP+KSy0uOw1NueEmGOmyH414V1CpN1gWrQETxJvmbbuNPG+oLZ4vwKz8yql2auf80m4MYE4oykt9+EqGKmc0xTErKA+msAt83uckJWZDRrKBkqFz0zzszGUWudr1mZNQcn3Tsw0viJsheqJF/KGf2nFMRWQJpgDeL1i+6Zh727CqkJosXCwUPjJNt9pHVh9OrH+ZGQ4KeHhStgp00oYj0zjHU+ge2L9kDy2JRezGxLtuc2raTVXhdBQxs+gheZpwG9zn8bsMxLJHGjbDHyfOe3VGrUX4aYZUihwiFWLsD6VGIO9pDdO0UZxO6G5iOi47xSuc2T52WfQeO8mdFXRYWTzs8jZV1asVwPRqdEPe8X3wnSSuHy35fhPd7g+MW18NktyzrUymVwOqxMWgiAPRKmQUCOD8o9ayl1mR9K0qKhb3nDh8Zb7ZhpU/yCYyaM2sVzmPs5ZtdwMSZR48qXm46RivzgyKyLuHxNChVFowpzMPKWak7YSubMTIK4gNR6fplnALkxDYH8Tyn/PuXiXEAo5aUgWwGNaLExlKe2M+YDRh6YJ1iviKjAcO+LaNBBJhs0NwXJKACZoCp6dhNCnmXK3gA5U8oLZjpZI3jvcbnh1KWMLDXcvT4gswj/zZuVGGwP1NqaSFzZ5bIpg9DvTrtqTjb2rXZ+pkAmmCdlNOGnMqqj3Z3ZaZUyymHFa2D26LzCWzt2qdIjNM8n5CdxutGAIZisHhfHBhuGe4ZjtWS6kmceghOUSZmxXpkB3NtFcRmMBeGHcOPo37F46mpVUsNQaSVecjbkqcXOhhCtorgxuiA2k1qhc7TPF97FS55bEgLCdnYUFgoF5s6vMCplxbBVHak37jp1FvFVu9cI6wKuVArrYzRTNQ0F7HePjDsL39kJXTINDhPB0C8+OYTUgokzHibF3Fol1AuOp4VhuO8KRRTWFZJFWhaUg8zzKL0Qzj3TxUMKeE0uV6tGtFLLCUyxCaNIceZarLiRBvCNuGvoHQlqp4U85KY02WXBW72PeCpeCtpTYqRmzsmAugmZB8C4RRik480Q3liTEn+8qfc1qmglTB6DEVBLgZBNsaRYtec7l88UGVfmbUFkIe95ulRoKWkKSl0K4jDshMJ10Ocooe5Gzo3Q6hu4T2Q/9LeVPouUmJR5o1zn9YcWZFxxX8d60iFexHWgxUlKPHiwqSzDvEG9zzIIUBPEWESVRKi1x2sBwv6VNahVSyljEaGk/G08SZ4yQBb5L1lCXiMOs0bE3D2aFxs5bYrwWrh6hN16uwKxAeEd/35EaZfVU6J5F493mkj3NVaK5sBuNx2Zd+T4np8nc2tjOFMiSFiC1mmEGqRZR7WkVwlkm7BI+J6hJXmpY/N7xLIS4zIK2fi6zXLBy8rPloCI1N0x1ZDuQcfatwLyBNhfA1W4x6Psb8HWUwrs09/JDyr3yS0oJtjvWP1N2Q2Nmy3oyfCYTmuM6MR2bxheu4pwVqwziMvy0MhyywNpzYLDACVl46qmbQIEXZLIMXBVuKDfzDm0C47Enrmx3c6PQXhSBo/U4Kx9/MJjDmB1E6fk+uGw25l1Vg685gy19pGe417J71BhWmiylnN8mwgW2OEIibhLDsTPt1s/hvlWgZiFZnWM1vHhhKeTxdDHNWajUzkmtpWaM6zCHkebvypiPbx6ze2j14oo1IFPGpSN54dnErFQdr1mTnQ7wXMd0b22lrbH+aSlwWYp5voptidnVj3RvTpaoLRmj4YzespOJV7RJOJfQRjN7gbpRTZ0wHTfQNNXcBrJz2OZuEURApZCVTVSZubfLJOdzUhuqvrBc1dXnlq0ZE7hutnralmljmnp7kUhBGNcuO5uk1hOTqLTPIs1lMmfaLlYc2g/UxDtCxkubVKPqLLF46RzPPWdZ6xKpIfBa6qwVoV0YCAt5UfJ+zFFuJmX3HPKYZh1XZt2W8j6Iab0ua+UIlnM3iUVNXmeNHcIKVTmU5499Qbu10N0zvWJk9XHPdBUM3oym5bZn0DwT8Ep/z7zXMiUjzRctlaxhln6WSgMic1ar/G8Z9mq9lb1+VJMgC7mqkaQ5qxJA6jzDiVRSf9iat12DM5MrpzLUdTuX+qn3XQjhovEWAZOPU28YbhWEjasCOjUwHmHfj1M1HbuzRLgUZLRjh3uZ5jNaurySgKc4GetOXm1Has4Fgb3nrSZEPjZ2jqtHjt0Db8EreZwkZe5sjAzHFi00rSFuUuY/gtu5TOOZNYdC2YEczlxqrxXhFALjiSOtkuWuWDXEtdXF03D7KfdFtxrGudRelk6SBd7LOBkVrom4kBBvdbWcU1u8apj4tAGcMT5i5wxiqnCQGKYa476wLXSwg0235JstzKDqTBXqOSX4RvLli8CUQ/inWI/rltTNVKqaNLwWjcy5Qtb2bzxyDKee6Sjgh0T3NBJ2NkbVr+dBnFYufBGopZ7anraezytCXmUhNJNWCVUtYJmvt8/WmOlhlbWT72OFMs1x7sasLUdYPVH8qNU/AYrbWVKrPUjhJk12ecwdBO+tV4AW0zHfQC63tM8c3iVCEzPeY+nSZHIMD5T+vr0c9ZJzzfq9AdxjI+TBfOGiLJqvkilV+dhSrr3yeecdEIH+XmA8tcEJl8L6o4TrzZnAmDNoiGM8adCuZZmEncbPdcbKxbuWtGqs9tUqoF2wpMgry8HgRsuloCKWi2EF43EDSfFXA+oNa109VvxWzKG2SWzfcHtaaKHXldSV5mjMGsrerrs/hsJCi1fb3f2YJ33BBxULcd4NVg9ODMuLm3ydJIRLoXsKfmtOiNTM9xIx7a6O/9Ii8Y5xY+M1bZTLdxqmTR7DKXFbEvmfW1tq7cuwWJg34Myf7sKE90oI0fLxAr6JpBXgYbyXahTftBbSUWubty9hfdR/llNkIUglm+pZIBk0VOZEFs6Lfi3pYnOa0MwsKYyFQkP0Jg1TqZSLCWdzTGnVsMEEMFBr45kiIQzH3lIuqmm7vs/7csZhjd0gJmWqczGnKs183SXM4CbF71K9n83kLLiLNlzk47LlzWdpGVbqXcgRdJ7qdCt5dd2kpozlrGSqQnsGcn41K1mHgrcoFocFK+/AYLgDvLD4I9dD6h4rY/R4l0hBDeMJ4K8E15snM3bCeGRZuKZNzotQMveUwIhibmTtVbNArVCBWzxc/qnkgc4Yak1tmCem5FSI01FjWmRrmYdWT5RwOVIKP1IrUAj9Pcd4v5sXll/QvjKUoavGwhuD4bbaOOLKW+ketcQmJXP+eJzpacDuYdZy+rGmwmsuohG6L4wWM53AdGQwe9VwilOwPP8i4KRCMJA3mlkLqhmrclWM1ePI6mkppV42doXNiuEk4AfNZa5NmMpkaTu7Z4nQYw6SgDnXFh77WjG1qi2gXWPC2ympU4YH1Ciguxlifw6tWDmLCV9/05nrTDInjxPFScK7hMvCK/jItLKFLG0y8zVru8Np2OeAZwvG2CFuIXBnS6UKrsMOVXyd2l8pLIYsoFzhoBc4QUr/1fjpWWM2bNNV4b2sjFJyE8y+A7tnXMG4to753uZE3JjzFOx5paQnXeDTyc/Pac8xB3pUrDrLAmH5PHadyhxSKHXS6rgoC2jNNonxON8mB0WkNpcnClIrDJfItvZMLd/CTe0Grfe2yW7Ka7t9Wwq9GOmeDPRXDcEnNFh6x+nITJXVJ0bLqAlSxGgf1UQrWecrJSsL14JHLh6i4lrB1cQxRaDAYlfP15JolSNScOweOKYTxfWO7lNoz7Jm6yRH5hiNR9cd4wlcveuID0/qxNzbzeq/PBlzxJFpCBlC8cJwGujvzZQpGW2C7t7ZmCPtoq95eNunI+uPTeONXWL7SIgrX7X1ohlUs/NQapVwSlcwv8WOG7VqyK6PGbowJxBjtIixe10tkz2eYJjtKHSfmrkWG/Mq10xaJQSzJLXueE6STscN0yaZcFZon+VFCTP38VVtSwwXqPXRMp5rhyjEVIOCgk8ZXdH8D7Qx2pNzWvOSgGG7tcxNvj5g87Gaw1Qht6zSXLm6mLCpjqEl7ETGfZPlevaXI2x7dJrMgVeokXktu37C98aLHddWRLPMp8IGiK1UDdeCGJiFpKPWKSuBIeEKdHSkdSKuylrNBQAUKySZU7oWwTgL9jwcObH/rOXn+7G/KeRH3mvVosOynsWV9QmF4djoaX47bzb2eg1aaJ8O8zhdV7apzJGfA9O9cwn2erOUkMsd4dk9OAFpLBpNg6JTKc9tvF2LSLKdBpgTshwA05Y5SbJnsWT9miGDkltgmVN2WQ9KcymYIlSnI0vWAeaRXD2dcJeDVSWOtqPpFJGmob/fEteJCFx+NbDqjnNu21wAUi3xRn+vpb8nM4ifc+12T13lsMZaTM+w2NTYBrR7KDSXa/zTK/zlyHTcot7ljSCwS47pSNk9dDk1nY11TfFYoIeyaeTPrRDnYixLlN9z2pJYCsndCCKkrs3p65T+kbPM+aK4wRsRvsbcW4WNZeHOct0UsOxoZcMsnuLGME5VY4oYrq+2ab6igtfmjiwEYTYhlwuM+ZjmUtmNwZQOFSQTZVUtCcvqY8du5WhXE6MocQpIgumkpTm7nMdjgT9C1txEjc6HWTAuv9Oa7yLZPxH2IzjzxizRymax6w03LteOVpi15H1g1+N3a6ZjJa6yQpQdZGnhCFtm4QIqjzcG659ApaeZpSWE44H+XkfYmeOu5mkoc7UMq4LLQRPmkLZrotRUjyXsugaR5Lm9ZEWUOVlAl9g5xtOyPiPaCHE9Hz5tbLMpgSXhCuRyix7Ipb33fxON7A7tTuV6BPZv3g90T2B4J+BCQh20TwQ/GHgdLmB4gOXhfKI1dHIux2zXKVFXxSQGZmGr5ZUuOwFzfoYsyHPFYc2e/WnjuXrLKGL+UmifmbanTS73Php3VpyDzYrdGwJOay2l8chlU80hp6GaMv19e5bu6YQME2nTcPl2YPcwbxbRvKQuOwj9aCkvwQT05TuBk6FDrnr8BcRj8+R3T0bcFLh60+Wac572PEMg2Wlgg5Yn/IKdAOxHrZVhWkwKUZAhWuY0MWyxVM7o7wf6h1pLMbkRSmb/kDXU2NqEreGpYl57c0Lkna5ogg7ITiVWkeGeI+wcXjHNbckAeYWaFhMW9jTd8mVNeCMmWNtnkSfblnsnW3AJSY5pElwAiUJ3nthFo/qJN2pluHLElaNZr2C7w0yMydgt3lS/ouWWQpEleY31CyoVqsDNyz0hWzKujxawUqCF5bM4B6EFtaCVGj3XYpFYMNfCK7ctXNYigMuSzCG8Ps+ZEkBTQoenI4MdfZ8/L1r7EqeNReAy+4Dz/YqyVkpf7aV1LQzP5X4Y5/6Px6Y9H/84ES4nrt7tiGvTaN0Ew32z7MQrOjq6p2rY96F1e91EWTbnEIm3lsGfzZVcBF2MtOeRaXKEkHLMtMEIVm7GtNxaQy0uIAGfQfKFcC1+BaBqtJoTHc8geTZXyjnFs59xWYBp5bl60xGPFBmE7kmGFXIQhSStwgfnmE46piPjVlqkmnXBD5bO0sxoYeoMaO+eTgZNaGYcRGguoTmD1ePE6onRaaaVOdKmtcELkmxib9/qrD7Wdkc47628TVLC+cTxTyLNGfT3LS/D/rjDXk2z697yEpoRO6Zk7i/16dJRR2xtkxqP/ZxNKgmlFtZcMiYrXevZtMQxpyOs9y3OtFwpwWX6lFo0ky3qaxgpr1pbOkQO6GL1MwAR/EWPXHmiCjE5gkt4rzPFe1DCucunCa6LDKfmUIunK7tmDp6xiL4c9ScLgVJaVTZyNwrXtQidYgHBDNEVB09ZLyJICBSOcPm+uUpVYNZHz3hxqZ4Sm/n6Jc9EZSWo9avkvE0NuF6I0cFRZDgtFpdWh9cei2F5zfys5W83ata0F7vK0gFJcRjrHAhB9iMdwfpjpf10R1wHhnt2zvojW9spJ54Sn3CD0D0Z57JF17ESDtebfLa5fKcaac/dWBV/MaDbFb4b6deJ6cgTesPwSgieJKNEhd5Z/tgieEtm/Qw71JRvwTirs3Pt+QfX3CnJkSkp16SKq8DV247xvpVQbs+gPbeUiZLUvOcpsx2cPf7uDU/qEq4X3C7TZ6Jl6/fnA+Es31MEbT39g4bxyJK5xA20T2D9k23Gkg13FlXGTTDt0JuGWLIe7R5BbDec/KHCrrdJu+7QVYPfThz9LHHxlYbhFFz0NBdxEXWT9f7M1yzlYAp1rgZq5E3IDTaJUpupSsnGKlyNjMcN27et/M7qE6F/w6yKEmPvom2OblLCpVRc0rA88/ZWzlqREAttUVWMBdGD65Vp4wiFlP8qNk3zyj80J5efFaxvGGjOj9A3BSdaD4/JYLartywhfkqWIEoV4iYSt55p4/Ftg15t88ZoVo2on7NpwfWCl33tsBxTNEK3zdzyEvRTzOHcbwUkWpQmzhEuJvxuwZ3OwlyLUF9oodWomTCVbbL14geFizlPSLiCPjpCO9G/4QhXjvYsoti8LOsXZqFdI8NqjNJy7IsWu9B2y7OrrVd1QnKOaSPs3jQlqHsykdpAf994+uFK6M4mrt4MC6qYOf/lcvc8tFAd1otxXOZ98d6Cfe6QS+Ru8MI1mpVpa2v0HviQSI1n3Cy5dmZuxw1s33Ac/TQL2OzcSW3mt5ZLh0W5kTKwLHZBMh61yKxVOKzTynH1lglcFNqnwurThL8as8CNyDAuFr2Q7m3o70PBodTbri7Raim5Us0ie3rlsqdTmDYt4xGECzj6SY/sBtK9DXHl8dsJmZTpyHIruGnWIFOrpEZzBNoRx38CXG1hu8PFRFq3tht/ktg9cDk1ojfuYLIkOEbLEpLMZY5Ii9j8ou1OmtPnZTt0TGjncVOif9CyeyiLLGD2zD5vOinMjo32wianNtkaSYLzJqDqjCi/qKU9jKPHdRPtamT7liMFz7SB2HVspgTnF7edel9sWy6u5YJbtoL7DiPdU2U3edoQSXmSpmSYdlw7Y30ki1wrk3jaQLzIDrXtrgpE2Q2ES28hqyX/bNQK9RQeavL7ZoZgiosbIq4fzVexnOfFCZihEQGLTMsFKd3lju7TFheV9iwyHvtZe87a4DKz1zKNY+lAqY+oQOqgewruzJMeJKRL9A8cYSfGky0n6eI6Rb5UDbbcP/+xd8/ybvJ1ZE7kNK2F/r5Zq2Fn83Y8NQWm+9QS2agrOWIMWkiTY/NM53dR3vHhu18QCfY++4UmvFm2MinHifYMJnU4nxjXCTdkQn0OD3Sj7YzjPWU7edYfWwIcJ+Y9TSszeVxOjFOqTlTeYf6vRp0U8Fwy1abxDPc8/QOYjk3Dbc5M4IbL0XIrjNNscgngPLrpuHq7Ia3NvIqrhGQ+5OgNUnBTIJwPxE1LaoXm3OGueo5+DG5oaS8siCGdrolrqxkX14Hh1BE3ikwmmP3OdvTxWKys0WRm2O7tDd3TBnl2Cbud5QJuAyEm1ikwrV3F9ARmukzWaGeTTCoVr9SmiscrxmNvHMheoTXv33AvMJzaxOye5UmYtVgrxpdxuiFH8EiOrmoK1U9IyfK17lF8VEFzEcZoHYvR4U9Gdp2HKMSV4MYV3cfXCLP/f3vf2iQ3bmx5Eg+SVdUvtaSZ8fjuvXbc2I39//9kv2zsI2L3ru3xeGYktdRdDz4A5H5IAGSxyapqqSVLdmVER1ex+ABJIJE4mXnya5AxjJAsm3GNuYjrmrVD1xgUxkOrABigbiyIJAVYN8D2FaBsgA9aCrpWQcrEVAZ6aCXtGhgiBLtAwjPJSdiXwAeiqJQbDPI4LsiFWIJHAvuJUvggZ+sWQB93nO5DKaCwMI3ci0TKyD4EcaYlX0Wq5gAgwxwJToCW8lPJeR6sRK3sFhqq8vAvPHatxuJd6DPUBhESKQttyKXNkXxdlPNwZRWhlZRkRfLZWzFSVIvM8xCMQn0rmPLqb1JI1i0l7TmDq45gtiPC8ikFO7X6CXLcLNn5hDxd6Y5MbQ4Bdu1ROwWtGaryCI0CPUiHyyEZDJAjtFcAoLF44yW2NS6BpX4SZe8rIk5L8SVwir9N8YKKMjdnd6FQvwRCFUCOULwnLH7zMA+tKKAmsgXlsjkEaIX2tpQlfEPZCjFrcQoEKyFUbqmw+LWE2QmHqlsaYCWMYNV7h6AVmpcVKEiZ5+4SSMTOCIDeEeyaoVsplGfXktUDghAuK0JzY2HKK+hNC9q1EpytFMxWw6RY4Tj4pfCmyqVgqAuSV5/Yx6JH3F+UaK6NPL9YBCNoheZaShWpDjDbyI1axFTOIPdudox2RbkKsqvkvZHmHCqGACjLcKlGFWf7RSQ60ro3pfCsXgXAMKhW++E+X7OkATc1oOIY0OsGaFYwlwGeBWZQiuHjpGN3AbQ2QCkaS5FgiaFQAjFUJbB2/XW2OxRKSQZfjFBRTt5tZswbCA3fvQ+A68DDvjDwtJMWjmdOGC8A0hrtbSnJLGxQ3DWSJFNGDoiA7BRL4YGqBWwt7XELsWztGijuOnRXFm4l/aW8A+wHBVcGmMKhfUVQXqG8Czn8LpcnchOraBZFm6J09gqocl/IgAkSqbQUspxkneuaUb8QbPfy/wWB1gqxhKFY/oihOgWzmWEUO9Y3xpP0CfJxIWPpf1xm6Z2H7zS07sT6uWnRtgXKd0Ls0l3KshosCq67BMAai7c+xuBpyZpJfbzUOWsLXRhYdpBlRMzIcZVCdxHPXwoYXtwRFm9F4aLtpDaVD1JMMsWwFhbuZoluQbBriFVuZKY2myC52rFcjbv2WC8Jeqeht+IwM02AL/o4Q+WA9lLBLaND7UHOUb+IxR11imEUszA71Top58KQAnluWcHsCuitA212fRaRj1VZk+dfKWhjet6HzgFWgysLtzRor8VSSXnybCIL1DVJYb9AULHgZLYUImG1txBrNTlEPcNZSenVihGYhCpQQVJebYCvDGIRCekaWiw7RRzDdRihVOCqk8lkF75OKxd4DC+MfxtKjHlVHcEqj+BNNgWJONb1kmgerWSmCkFBmSBhhAYIiwKqriWUK2GFmx108qIPvfVjfufAcQU3iFDgwX7DaIUUfQGI4k146tUFdrcqWpQE3YiVlGgRdS3trL8PkkCQ5G8a5T3DLWXFVL0TzewqsTR9BVG87wHWBu4lUCxb1N8VUK1C+UFWtYkxdZjunO5j30EY25uSNmIoJWuBFNyCcmgbK+EKCZbQ3MokkQBpVgS3kpA+pWXsqWZAWD7sA1NhYkM89yP78MfDC4PGqF0Ltb0ALTpwEJjB3TpQMBKAHImK9VbFYGpGd0Eg1kIuwZI5prrINxCXONlppAi+1Hkp5YvIE1DJTEseKN8oFA+M8i4WlGQWpRUZtPIDuliiuy5jET2JsmCNyAsrDjdnpOORA6hVMA8ky3AS5dktFOwuwFuZWX0h2y//7KA2Xea3Va7A7lbYtuwmseITqncBuvYxmkLlqr9uIffsLixoYcQpsm2kqnEafEaDC5MjOYKREKTEK5GwNbMTDLC91OguxBpJhES6BTL/qgGCArjsA8iT95wVob6V4HLohMWlDinfjPVor0qYXy3IuX2sD0B41WFbGoSFx6LoUK8knK+Ywkq/Akno0+ON9Pg7M9B1oKwf4zPRHg4avgTM1qN8p7FZVLA3bY7ldYsAVykUVolB0O3yxAp2OeoAqapyVBp76egcMr9v5ukFMvSRQyKHCndQTYUWFbY/LsBW/C6Sqqxylhp5cZC1V1J8trwDEIDmZSQ4ryPu3Iml2r6wuYilagF3wXANYfkLo2kNmteE8qLF9l8t+CeN6p3v7xncU1Vyf4s97sv9dgAghi+VTF66jzgCy1hTjrH+TwpsGcXbmDfQebSXNnJyp0cqUVZwbv+9Dt/zeNuoTzwlGw34FHhhKG0HvQO0CnAqIHiZzbsL8Xrb95K9ZbZiFTa3UVmVQG0V7IOQILMicLRymSDk17GTqS7k2VxpQqDIu/kgCsZ+6KDqtuevTfSLZKSjaY1ws4JbReJlRp8WqMWjCQC+NHE2FacSeUkdLu474Y9YatQvCRRE8aY0w/JOOkVYWqjaiQNLJxIO6cSmDqB4HfLRsm/kpfqFhS8JdiOOP8S00LAqsyLkiEe5knqcLc7uphYyD9Ux0EhH3L2SIpys5bmn5y89JVrbDGjXWwjJeZJY/VHKDSgl2Vbi9Ozfv1IMt4BY3S7dG8BeTsaBJOPJKGjF0CbAF582139e4b0BdXBiyHGmQIjQQmCCVgwfGN1lyOFRi18J29KgWIh20JVDd1XA3ytoa8QDnrLfAFGY6fpeYDyaUwBxf9a6hw2S46ywAi0kzmitRUEbg+0frrH9gWE3Pbba3Aj+mdODYx/WO2D5i1QXYV3EjDjZiQLQXRh0K+onbScTfPNalkXlewY5jeaVgl512P1IYNIo78NeZM6ekk3PGNxHdFBiH5NdVIfMWRE0we5kDGx/ECdmke6NgeZlifYmzqqJbyKuxnra1sEznVrx5MgcSBLG5wwZezTTDMV72DWQyocwYjjm0sORhllL6BZinKqqY6qgjrjpSshVinshvGCSGNVupWBqhtn6WJJcvPGqCYIrhehAaJ04EJzLChZlKZ87BywXcNdVJPcWCQbwhYJuGKaVKZa1cIaaWmZK0wD6gWE2PoZaxSWOEw+0aSK80IpCDYWSiYII7bVFMITqfYjlWzxU3Qn9IzMALZODD9ma6VYEV2kUlYLeCSlIsJKnTinZomaYXcjZYartoxdCJZVVu5VMBInPVtd9/arcqQmRPB17qxGYSFWoBrhf7gJi4ZICjAmw2oOI0RTI1hUx5UFEBNBGC3H0Sjq4NQ6+/EqpHYF5K+eA1aPcvtKlZPFWDtvvC1R3AeZ9QPNCI5QCxZEOCCuP3a2GaiqYwKDtrk9BTUkYg3TU7KxJ+OygPWQtsjcfnHFdMibCUy6fh4xB/ccX2PzBQ211Xn77hRAU4YFgNhB4xIrC9RWwe2VlUudIBh5pHxGEAEdgw8RVLY60Lig0rwJYKSx+CzA1obkpEFaM9lZWhMWDKEoavAPJeOtxX+GmEBiQuE8rd5XsE4xQUyIwNr/XcEvG8q9ixAhPhMLmR0IoxO9DSvojxQniEZvcVJ9Iv3Efi/0xq7UnKN0DGj0E2F3AutPiRIiExKQCsGR0hYQtmQ3y7ATEkA4mdNcxjKYi6K1gRXYnyy+paaRhPUO1rShY6m8+OxHSckzrWLEhcuAWFlzZGDIGQJPEFDKgXOQj6HyGBKwSLJl8AN8UaC4VEASn1bWH6hjeSqC1BHgjL+vNul9el+9a+IVwMNhdgN6m8uQQOCFVP4413FTrUX7QcEtRmsEoFPcccW1k56Ji8WST6zEtgSQ02gs5v6TmAiqRtafkBNs7Q1gBoYg4HaXxG7PMAgn5e7JuUw+Iyz3SDKs9jAqidIf9jmP2kNcojcNuGVBbwsXNDkvToVUam6/Z0AWmV3NJxlYmpRWD1PUbPi+tA5rvPIp7BVJSJaFTBbQD3BWgbUB3rdDsNHRbRMKkDtxIFVpWSixWLRM1A30UBZDJ0CmlK/tYxSQdl1iyQh+vS1qh+/EG638FwAS7QSYz8pUUZMzZYw6REhGwW0ZzQ+ALQvVO7tEXJIZULIOj66i4L+Q8qpUIDiiF9oWQvi9/CVj9zOhWcRVm5DzKM6gZcIek+n8MpJp8xAwdsz1dpdBeUqSkhMCUBGx/pyVZaU3ZGg9WYfs9SZQSQ7LQBu9JefSrt4kVzt7CZxJK+GzwQjSRJrQ+s2RThY1FcbODUxq+7QP7SDP4pkOzUjD3GnYduS09QIW8rEQ+4S4AvyTYB4LZclYWzQsDujZQjjP+quoO2bOfyuQAYkFqDb5cIkQsWHWi6EKhZanbeMFKB4OIfEyf7LwQ0zhGsQbsJi6bnQSel8xwC5uXZCYyLKUy8iCAmg5USriW/ZCwZS2ZbARRtik7KxJZF+9qFHeC2/nKCFYbPbS6jqFpVmfF7hcqe7RdJYxJBERoJj5X1WeTBSM1oORmENnCRh0mrlaSEk7bSDG0DvBewRoPqz00BTAoYsGc+4LaNjAPFzC3AdeXW9xvK/gg+HylHb7SCN1epqzd8e9pm5eiiEQszrKAHMEAANWyxfoPFZY/aVR3AeUH8Z6HuKLAwqN5ZaCcRUmAaiQ5As71106YbKoobI3gQglySNjvkL1MxeVM2/WWsVZof3+D+38nsA2wd6Kg0rhTLQkRTCK6WUhkC30QpaY7CT3TbUBzbeSYGA7qK4A6wH5ATr9NFI9mDYAVuluP+5XC4lchCi8eYqn2tAKN/5TnfvkeDQsCAC1+j+ZCSbtCpC1tGW5B2H0v1AOLNyETsO9ea7Q3jFDGZ+eFbyGt5EKIIY5T4WJRphCEvXn5idbuR9kcuc8NwHm13qF8U4CvCbb0aHcpn5Hzw9Q2gF957C4M7HuF4gFIxe/S+M7xq69ktjQbAcZ11zMOhZLQXigob+Sle/HQUxAoAsEgFWqkIHSL8AF+adFeaRT3kfQlWcdW4oSTR5S8EJwzAPvQgZoOXPRVJVTroRsLJoKuA2zj+4SNwAiVBaoC5AKqX7qcfitWCHLqs5SfHwxwpXP8ra4dKOie7YmAUOjMpp+zvkjC2kLRP8MUEyzhPNzHJEZoAIAkXzFAEIWa4iA5xEQVYnBQvRUMlg6qGNdlLVgYMdZtCbvlvg4cEVC3WPzG+PB9hZfLLTa6QOcMiuVGustXjC7sSRptKU53KHEQMAsxETPBBwJjmJ0mE7C9bLD7rsLybwT7EBBeaoRGQa0NsGL4lUdzq2F20g/J6hhz2+WV3J7lit4yyxCoEqtTKg33k3/WDkaj+9017v8oLFv2TsNuINBAZJfTjcTWg8W6BYvTu7mVBJ3lX3cg56VU+/exv3VR+dXILGP2AXk1pWMAjuoA32h0K8buB0Z7JZV8i02A2UaFOKCT5BQSWkRnmZHMSYLoiIQ7kweaa4XmlmEfgOptyKu95iXglhKqCAAI8ZmkKAwSOEw5nlacI8fa2Bj+WF/wR8ELj2KEQwDqBhc/tXh7W2H5cid0cF6BOwXuCKrweWDrysF/p1AXBuV7ZEZ5rZBjSP2C4K68sNVfEuyaYHYMXTNswne1REMkMmcmipURBB6QyAKNsJCApuZGrG+9jj0qM5jF0CmjRQVqHan7YgmgVFCyFp5NtgIZ2AeXuXMJsTimC30MYecFDolhXnkO8glDVr113oSe3T+l8EKsazYxPldD8GWCpFAHAAuF+lKWYslrHAqgW0n5GJnOKTsOOCCWmCGwj8/NDabytJxTgNIMpQVCUEoghQvbotAOLigsdYuf7m/w6n3bl1RnBjuH6q8b7F5fwP77AxZFh/WuxNvdClb7mN0UsYqvUDgwaJj1NV7dDbexWFqd11iUHTwr+ER/yTGigQjmtsG6tFj+RUvWn1NYvAlorxSaW41QAOt/UajeiWLmlQWFUiJqWicKODmIuW8LpTbFSS+3Oy2DvQesRfvjNTa/V1J88g3FOmeUHa0cFZWKZPfJB0Ax3ri9BuyuhN4FbL9LVr5M7FpJqGRIi+FIgsMW4KY/l9lIEYFg5bjmFdBdqVhGJ54y0kcmPFnaIFmTUhmYc7akbhj1K4IvgdVPwq/SrTTqVwR3wUDhkTh8OZBYuRFCA6ITuFNQbW88Dl/5nmE5eP1j39pT5UnwQnKUTf7qPejuHjf/8wUe/rAEXrWwhUcwsXAfIB5tBoLXUDYAty22KwPqSEiz6xh4vWHwA6TyxAXDrwL8EjFNVaG4k8gBcpKdQ10QpiQg46VhYaVUM0nqoW4CqjtkUowMleS4OwjH7MLCLwz0zkHtYjREIYHq7mYpDFH3HexdAxgNVXcIlyW6pUa4MigefAxmh5CrlzY/o8yToPpqEAgMLjTARnBkABTJ2TORe2BQ66BSum9p4K2CL4RQp8eVgfaawWWIy6dBerUnSXMmwWyzKLGCs/MsKlitAkrjc/alUQGldii1KNebYoe/bG6w+EmD1uueKASQOND1Bjf/XeOv/BrmdzssqxaBCVdFjffL5end7u8io8lgyKuarche+aqW0ToNlIACI5Dgu6lrKQoIUBIu9S8FzFqJc6qMhsTPMsk1Lwj1SwIrDbsOCJrQvipAwcJuSpiHRgi2k3Id0qNGzJcCi9FgABgDLi3cVYlupVC9EaNFFKNMejqGZao48SZOBdUx7DpANzpXvmguFUwh5PY+iNPN7Aj2QSb8UMn45Vg1uHiHuHIUODEZHWliTxy6ucwOACoVuEHORNNtTH/2Mkm0lxSZx+R56VpIbSgwNj8YtLcMlD49EojZC4Cl78NI/2ZEBRpiPkASIpl00yqhP9FkNNnHyCc70obWLncO5pf3uNmtsPu+Qv0aCFcORSkDNcTB7lpC8AQFBV06IFZX8ADaVqN70FJv7QHQtaTNuiUQyhBnwdhBEmtZjHcNVtKPAVmWD8l1/EJD1R56E9OzxEToS+HEwGnVOABGOoFS4CpyQxDBrWKCQVnEJQmgnJEkjasIh5IGBQWzDVCO+jpnkYgc8Tpso9JlzjWsWBG4MEKrxxDM2uiIG4ol7SsjYWML8eQmYulQ9MoWgfIEl0nHSQLCEfEspXortrc600CURAgXVIxEkU7aeg3PCgTGn+5eoPq/Fhd/3oGb5vE6KwTg/QNe/DeH+rcLbH8g+FXAn3cF7F2M9/lq5cBomhhpqvXwTkNTQMsGKpGZDwJOFQlOWaxa8JLQOY2mUdC1glkDxQNj8Rv31Q5WSirxbgJ8SWivNLrVAmZX9twHAUiVtVN6eIgrLxfLJelalFb1zklVE6tiv00ZWhq710ZCKFuJn3crUcrLnwnFB4/2WsNHbl1XiqMtGKD4QBIKFgQuSIlCpmaYnXBRIxalVY2XclYR8vOFROgkkijWlOv0KYecfuzL1M+jz4KB8p38Xr0VRV7fSptDGYBoOOwZFpBnhUjjmJzFRCzGSEydzvHLNNCsE69/f/PT+/Hz+pFDALct8LbDcl1i+XOF9rbE7nWF9tajWrYwOsBoj8AKrhOHW6qmqhTDlB5ceOwuNdROlmL2AajeMdqVQvtCaA+DVlj+6iV5IAhUQIsih1eRZ/hSg6O3XixcyJdU6TPhZEAmBk+px7kysZcKw77ScKUsjerX8TyALN2BTKZcvxRFp1da2Jeia1+5NOuLcqPA8EsrAd4GILZSQC9mKpX3DK0pOxpSqeuU5CCTT3SMRSsVgcBtgkwQYQip4BBXuaBBWRnpQELBF5wa0DqSrD5idAZ5oI3/VWSVevG2g/rwHlw3/fMcg14hgDdbVP+nQfXXUmAaAqjdYWBbfIXC+/cyEaeZfwOEP6StYFRAFwTrLo1H48zgNPLeFclkp1UAF4SwIrgXhKYx0BtJQCgeQkz8ERiguHcINhaFvBTnbNCStOKWOvMgI9Jomq1gsmYnTHmp2Gl3YREsCc2pAPoZew0x9FE5oHgv/TYrTdY51ptY+h8bgBpxqgmsB9gtckXhtALlFIUQ/QIp9IuVfE88z8FquAsAAdD3QhIVYgSFCvLfl5EPpGYUTUB7rbH7jsGFz/eP5JNI+G18nSDsReMkn4RqRenuqc4xfnqS8j1dnh69MPXL0NSOXlaua6BpUKwNil8r4QK4XWD7GuArB2M8tBHLLA36lCmidICtHNSyAzNhu7Eo7hSqd4zygdFeKrRXwMO/adiHC9gNwz4IKDS0LNP7hqY+KiHfuWR2JWcIEmtZdIixUegujRD1rOR6foEc5wcAiJ0ily4BMhOXj2mJYMqAP0KkTYyOALFqEJdayHgYayCU8kWIQCScJxQMSl7v6AQgAMERuFMyk5chdyxmypy2wSuwJ1AnxDPUxXjpBqhalsSNVIHY+Z5WcxiWlzzoPpJ8jLlHhx1i8JmZga0E+3P6/i3IoaiFobQdzHqZMVwCQ1NAYBLGsahwgKh4WELMeBApoksHLgjbC4V6q6GbaMlpgi8V9M6jcAHdlSQhJBxWSp+TpLU6QG8BE6OBAInaYQjlaXchvBumVlA155JXy19idE4QQ0X5gMRsltLETYxqyPAAy4TMBJhtB7stYHZyj8FIMVjThOivYXgVeUAcwy9VzniUMcTQrUf1VlZwFCTVHgl2CIisawrlhwC7dtj+UGD7+5h5JA+2/wz0zrKh2oqxuek1Bpb8gFzJ5FE4IO3/H/x2QB8flSfBC/sXmVfCAGJZEMF60XZQmy2WbzSW/2Hhr5doboRsxq8YWEgZa2NCHNd9Z9XK4+LawV0oPLwuoO80yvfA6mcp8ewqQnNN6C4KSRyopRCjCgyqHRDJulkRYHV0jGm4ywLNjTi3JJ5VcF+QdGhXiaKV5XsfakWBYgRCfBAmYkYxwoCCDADWkU84aWPF/UhgiINi+PgGWBeTUD+mSYhMgDIBGqJIEaMM5DgSnoPsKCN4p0CdgtpJOJfdiodd73xMtfZ9YkbYV6gcv/OwA447YW7zqMeNEwmG/1O+/7egcOc82cPPw2fRdSjugTYYGApwrFBqh1AQ6s7Iqs6lpStydp+saDn3eYChbEBYAWEJhFLDvgcKSPiiaj3s2iNog1BId9INIpF4H6YVCpnE7S4q7ULoPIuHgNoouEpBq31FItmZKsMWwaqcgNMtI/1n9B2kaAUh5VdoqkKI2W3M9IycHd4SNFLZcxJOk0IUrtn6WANNiQM6NkeSGaRggMT+SsQNa0L5Xpzb9UuL3fc8yCoDgBGkkHgmE3IGgEhI5r0XaMF1Gss7ltX5lBad6auf4kQDPsmRNnHlUWhF3uwDKFlGbQu9q7F8a7AsCoRFIXyXl4T2GuALB1v6aP4LeBUYAkusavgFofnOwO0M9FZJsHQMSwmW0CmCKgm01JHcvC96B0hcHwWZjVMSgQdiyXBZRglRSczQijN9VpRA5uFkFxUuohKOS/z0eGhQO0sNwlSS4hwGaKffgMfvPniF4OOgVf0MzqnSQ23ArYTXmVqy43TtxbpPmXpDBRvCXtxnfmlTSnT4f9i4b0F5fooc8pSMXNjsPKq3Dm+3S/z+8gNap6EIKJVHVTm0XmONUlZ0QeAcpR4DLDJxcu4b9MKjuVRothp2bbB4E3HQGJddPADFB5+jZST+m+CdxKh2i1hyKjF4MaN6H0AdQ3VeMNqVieRNjG6phICJFHbfq1zvDDHkPhhRtMpJPTXdQAqpLjgbCGYjlVqClvCzXCkillg3O4k8UpHISkdnsrsYOJy9RNfoNnGjUKxGE7D7zqJ+FSNzGGKAxP+PVFL6nuJy40Qnr5AR1gbl+wHv8JSxMByMOWZ61E+eKJ+A6e5bulPte9SmeHPMLIqgbkAPhPLOoNQaKAq46wr1i1LKdl85lGWHhXVQJI4dIoJWHVTZAjdyWh8UOq+kU3slyoiBVLWCOtFnaYEHxbHWfXzYBEkUiPfEAb3yTEJRsaZxEfHPnGyQlGEmXSawE6cFK0KQGtRCaJ1mZqJYvDFiqTk1kaE1Z8cjMyN0CtQqUAxgtxvA7AJ0E6DqTqI2nBN8NQbOZ4t12KnGL+XQtH3M4puzDObO+a0p6/HgG8rwewjQ79YIv9zAXzzAqCB9FciGSmUcvJZY3qa10g9i/0v9wbuo3Qa4Y1E6oYV8AXx4ZbH4i8Hy1w7BWqEL3QmsxloJO1+MPGANtNcEkEJ153K1BV2Lw7Z5IWnDSVknZdotpbaYXzJUEwltWiBxzyZr2myFRYxtH5VAnUQ2CL0iA52Ec9WvJVxLb4UQ364lDl4c3wGIVJfgmJ3mYvJUSs8nEkjxRsFdhH7VyMhwW/AkvgvEcZ5WEfEdUCSTSMEn3issfiHQhw0eVYsY/N/LQGM+OFxOlY9UutMDZ278PVqhPrqx+CSaFma9wcWbAlyV8BcFmpsFPtwu4FcexaKD0QE+KCgKsDrAqICFkY7nWcEFBR/xMo6VDXwQhZxmRvHeixXtPWUrkgOJsk33keYVxb1+iTGvlOEC7o8jjlleckxa7ghRDKLFmxQgZauV48tM+KtzGtwqseRroNoBdisUmmoXSdkH1isz7+XlZxlUDphVdofAqcmZc3TsxNfstR9SEabrfCsQw5QcUMLctLj8k8fP313hx8sP8BCS9xzxQQxDDE2EYtFkNEkTSzo1GF3Q6LyOZe72aRwJjMvLHbZ/LAAuUN15tFca7YsSdu36Yq8x5Vs3jOKDeP83vzNCSNVx5PIA6peEUHJfKcRKv08JNWAgVMmCJXQsSlN3UkVXfBwp+w0SGeMJLVSms0wleMyDQHiq7R3LvtKxBqCOlcPFKZfihFlLnbNuJTQBfiUQJAVCosEbOsZ0WnUAKTBJxn+C/oa/AaA3BZY/1+C67kPE8PjVnog4PEmeqHRTs+fV/bFxune28SD1QvUG54DtDvqDxuoXg1VhwaWFX0rsrdJS3G+7BHwpeCvZsKfQkMgsqFeYHJQ81L0liTBfcbRI2UcHR8JcU542xYSgNJvGlXrymKbZl7vY+X3EwHVvyUpfoUwKDR8ZnTrpzKrryc5V3Qk04L08D+en8dbhwzxkYZ7yIkabaGZyHb7k4WUfXX7KwfaNKNxMlTh+1nPP2XuYXz7A/q9b/PJfL/F6uUEXNBKNSzIAVPSaA8jFLItI/aaJcWGb6IQTTaFIeIlrb9F4g6tljd1/8bh/s0BxB+lUFzKMTe0FK4sWLMcsNXAkNzKUh6+uAeUFdvOFcJ8EK76IRHokfRtgG9AtCN21xNMPfRhyc/FPM/ylh7+ErDId5TJQiRGvu1Agr2Idvtg2Le1qLyVJxBei8FF6GOslZDetYKNx0hssAr9JwAnF+NpkzEkDFThbur7TKH7TuPyPFnR3H9nb4n0Q7QcExPc/F7wyZ3wek9OU7hNs6qlxNrXP5AAdLdkQgpQyaRpgTTDvNUzMIU/ENqkGmAD/WlYdWmbuoJGrmVLsbJSKRMaSJMlxRSF2jMgRkMKlkvcWQIxlxF45EPKIM3Vc7kSvb0+2jFznCoS+QGaqipEcWimNNt13wl2Hf1Pv4dTl/Wg2nNr1kN7GWAER7W2ePG4KiviWLN3xQ5p6BoNt3HZY/WmN++oCD//Z4dI26IJoJz9g4JNTyafGSzZjoT0sSckfSx4ED0UBmgIq5eANoQkGjjV8odAst3j/3QK7ukBolSg4Z3pO2mh9ZoM59WOOhkMKMyMe3B5nWC2v3tJj8NRH7URjAglui9tyOJZmiU5SYe+1a5XgRcqQYB/BwfkRa3DvNEZSpiw0AiyOYsTInSwxBE0l0qZkRAVCaBVUY6Se4XtG+csaWG9Ft8z0SzGouOex5r59w67xMfIR8MLQSH/6cQeNtMHN722LXziEPt0UyLnoCoBKzErjv5iCu3cMpf+DBz32vAPYL2Ue72GUBSTVKAadb0pJJix771TcW63HsNNTtic50dqdUrYHI6T4dAfCpO5/tH9+Et+GnLKqCAF8v8bV/2Cs20vc/7HCd5drGARYRQhMGWrQxDDaYd2W8CrAUIuF7kTxUkCpHBQYHWu0bEBgWBVQwmGpWxTk4BcKLRtsfYFtKFB7i52z8EH6u2dC53Vu8lCJhdBHwHC0VHkAaRCJ0kZUuAD6ZboJIBNLNwHC5zGCzjhaK8wceZ0YIbbLao9SO3ij8gogFfXcf+SibH1Q6JyG9/LsVIL30qtI99RqSbpqCKqRiAu7jVzbu1YKdjbN/pgbw0QjO2GsiPd080dq3mfEdA8p4qG6md5vT8mOtwF7uEuW5I2Pnxl4PBXNWX1DKyVZbaOWPmrgqYpwfO3hxDF3zFT7DiwbDlql4zYMrNspZ+f4UvPLqeOXG297hJVl5f0NKNwps2b80Mc8rMzghzUu/rdH+eEKb/7lBdyNR7noYJQkRRQRUtDEQCEp1gvd4drs8J25R0kOFTlUxAiQ/IQAgqH+PXZQ2LFGzRYrVaBmiyZY3OsKTTBovYFnQmVc9nOkcPLAlOOEmQHG4PMAegtDWIx6o4kU97Xy4nJeqX58Ki1cy5XpsDAdVqaFIQ8V33lIkAsoxjT39+VYYesLNN6i9gbb1g78HQrBacFpPcUCuIJJ24fo99h2UhHZSagqe5/rwu0Zc4P3NXzH45Xbwf7/kau2Z8hIO2SxDNYee9vmFe/Rbcd2mlrSzh03nuXyKY7sO6VUp+SI0pxtyrhzzMjkPhPXnOtEc6v9udt/Sv869Gi+CYSBWSZ6NfMSDvVDIvBmC/OnBi9+LcGLEn5V5PIym4Kwjux6CQ77LWYZhioAmqGth9acFSERoyo63BQ1XhZr6JiEsQ0F1q7Ezlk4Vui8FqsvLuGdEyyUPcVonqgsGTkEcsgLDZYMMHCMFBv+FvcdZ3oJN3O8FwU4A7RFwMaUMIWHNS47vf0gtdwFJU7uIM7j0GioRkWHGyS7LvRtqDrhuVAuQDUuOpRFqaJzmfD9UPKNwIz7hkjejsdjam77p8hHcC/wxLbh9lOWjWNlPK+I9446pmROdDWeoqz2XsbcS5o4/wm6/ei8MV7qH5p5T+kMUyjKobbM7fcUPOspiMlXLeOHcGgFNd7uPXi7A3Y19B1BAz0EBvSwFxGyy10r2Z5qo6VLawUoi60usbYvorKLlXKjsgSAAtz7D2JllTy83KAEEBDhs3T84D5DGAzh0UuLHA97S0JFmWg9t1slwiYCyMb/gPbREU2EMvk+mAHnQL7tQx4Tm9ogeSeHP+axyNOWw9RybrjfieN2eIqxBUyEJ9dGS/LENOCP3TaUoVLO65PR8fNaZErp5W3Y/573w8xDHTy0g0oN+/sN3/UxmXrnoyukPffOf6o1ONWGQ8dNX384iob7TW07RYbnBKbf5ymT899X8oQ7lkOz0SEMJ2X8pe+pGOL4nONGDK5BiOFRh0yyAzL767HJZGrfE35PxTL7kuth/3u/Iw5hrUfbMbeqnXoPafsAUkibph7tcCw8ZWzOyTMR3kxZwUOZUq7D34bnGJ9r/5hDVuNTrKs5i3HOKpw797EXcNyq3L+hY9c7ZdvThUf/xxPjcNuhCfKQkh029JnWaZ9ZmGPA15Rymxqd/YH7n6esqzEp+nwj5NA9RTay2qYsgTkNMr6PqfYe2m9O4c9YkPk4nnbE5tMMDKjxtkeWSMLOGfvwz9RkN27HSI4ZRf22KYPk4+SZlO5TGjAefOPBnbZP7/85l6jjd3zMCDn224lXxSlK6PPd95zF+RTFOKd8p75//RZulimrdaKCRB78U16YsQU66Fz5ZxoP6P1dj+mSRweM2z918qnf5xowdex4n7FSTT9PrD6H/WW2Xx9T/mnTU5TsDAxxyJj5HONOHd/lOSQNtEOD8dTtwxn/Y9py2lN83nPzgX2Gz2b8jKae2aHrnNqmuetNtWfut/H5T2nTt2HhDuVkpTAFLQxDFUfKd2z1TRmKc6vlbPmOd5hSIENLe0oBjy98DLIYW9YDjPVpUNdc35459hTtN2Ox549jBc1TTuYpHTXR3z9BG38hpfuc00UPPxy+76EyGCuRwy/80EppWskcUkTjz2OL8JBSfA455Xrja099f472jK7/XO7gzyx7fWECXkhWblaGQ/wyKabByZIv4RA0NXamji//qF0jxTd53mPW41ApJat+SiGPFNrwb0r67XsPcrCNH+0/qXAHE9ajdzKacOas1/SOxguP6Xal78Ntn75S+8qLYZ+KFfPMvqcomMMY8uPfDl3v0DXnrP1Plal2j7d96jXnJpp/fNnTS8NY8QlFkP5nx+twRA8U71h3HTIe5qCFuWPH/qKh7Bm7Q+xiTlMfADmHh04YkOMrj+9q9H9ephCa4W/jH6YU7xTqM9/OMeT5/IbBcaU7hfl8MQtlzgpM8tQHNDVLzc2+43M9VamfqoxPkSklP3e/U+37hnDUr0xydyfai2IZy6TP6gjeOMRzx+FHY6RieLpT2jx12UfNmMKb0/epcT5owFGlPt+6iW1jg2H/JJ+Kq+5NiCP0ZNrKnTJg0vZPH0fHle6htz/n2Rz/Nt7nk+WpVuZTfz9FwX5JJXbq/R5aEQzP9ZUo4E8dTV9EohKYautoWTtrnzA/YlxjhsASM4rsMMQ100YcGaZDK3WqDxy54NwjmN/n1El/aiWZvh86Zv53uVWOn08J9Zo639DyfT5D8zR44ThYc3i/JM9mIX/uwfq1KYNT2nNqmz/jvU1ZTFMT87ckzEhMYY9uZfAs5/DXfMvDisIYKGPgBIVwcmPT2aduA6lUUPo+buuUcXWsbbJ9aiX2MTI8z5wCxKPfp9on30Vhzt1z3/Y5Gbbl+cbN82O6Q8/mcw+wQ1b01y7fksL5WGV5LDxpavs3ITLgpx4LcBh3HcMNc49y3rGz34bp1dhhjHS8vJ5zMiXI4zRbarx6OiRPeedjBX743KcNqUNWbD7TYPux031aH/48jrSh4h1+T5+HMryBQ0/wuQbr30P5fUsKFziM9c3dx3BEH1K+36KImRg/TluRQ8U8efiMsh5sHRw/9cyO4feHttGjITknpynYqe/PaQ1OTSzp/8fgvXNj7xQYY3Ch51mOfAale+pbPTR4k8x5T09pw9x+kx6Pj5Q5Z8NRD8YXks+xMphTrsPr/SMo2rHwcOBj9AzmscjHGGuvOKaJWeae3Xg7jz5PKcN+v6fhw0OZXtLP7/+ccuj5TFmuafuhZzU8Nu078TtPVF15pn79ZeJ059Zex9YxU1ZwOu4Yzjx1rjHscew8s+uwA9+n4lum2jT+PL7e3OenyKnKdu5dTD2ncSc8xXz6R5S9ZxDQlxIBpgdykkNK7COe43gyeHSuoWI55fyH2jQ+x9SE87lkrl3jNp3SjtEk9ag/jwq2PrN8+TjdQyb6+LepWWZoYUwtf4dySKF+qoPn0MsYK8y55fahteh80OPT2ngqFnvKJDg85z+joj1FeFoB8J51tf/bSed8HO8l5zj4fp9iKR46ZnC9k/fH4f735DH3xGuPr3Xs2C/Yn7+s0n0qoHTI0jxVwZ5yrTnX87E2zGHX4+2ndLDxBJP2P6bgTjn31CT1qcr8LE+TWYt0IIegr0fb+bR3P9+gqQZ83Dnm2vEUX8Dc90mZmAC+oT75hdKAP7M8xwOfWjI/FZ891fo95fc5OGT8+7jt47aesm0s35LT7x9JjsE2U33zU4yPR/vOXG/qt2PXOgUuG98vcNwJy4w84Xyj8NZXngb8hWROac1tO+YK/hydYM4KnrreFERz6B7nrnWWv7+cMpGf8v6H8hTL8pRIlEOrqGNw2ly7n7rtG5Kz0n2qHOvQn/Oac0r2lPjYs/xzyilK67lXaGc5KGel+ynypTvYFP71KXJ2iJ3lLF9c/jEw3X8meU4leVa4ZznLF5ez0j3LWc5yli8oZ6V7lrOc5SxfUOhQjfiznOUsZznL88rZ0j3LWc5yli8oZ6V7lrOc5SxfUM5K9yxnOctZvqCcle5ZznKWs3xBOSvds5zlLGf5gnJWumc5y1nO8gXl/wN408EW2TuSUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a866633d-fbf6-46e2-b739-484022559b1f",
   "metadata": {},
   "source": [
    "### Code for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1163487-48a7-4fbe-aa25-184fd6c9acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fastai\n",
    "\n",
    "## run inference on test items provided as a dataframe\n",
    "\n",
    "def get_predictions(learner:fastai.learner.Learner,test_items,device='cpu'):\n",
    "    \n",
    "    test_ds=learner.dls.valid_ds.__class__(test_items)\n",
    "    test_dl=TfmdDL(test_ds,bs=16)\n",
    "    model=learner.model.to(device)\n",
    "    model.eval()\n",
    "    inputs=[]\n",
    "    outputs=[]\n",
    "    labels=[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in test_dl:\n",
    "            xb,yb=xb.to(device),yb.to(device)\n",
    "            xb_3c=xb*torch.ones((1,3,1,1),device=device)\n",
    "            out=learner.model(xb_3c)\n",
    "            preds=out.argmax(dim=1)\n",
    "            ## true input is 3 channel,with 1 channel img being repeated 3rice\n",
    "            inputs.append(xb_3c)\n",
    "            labels.append(yb)\n",
    "            outputs.append(preds)\n",
    "    \n",
    " \n",
    "    inps,outs,lbls=[torch.cat(tensor_list) for tensor_list in [inputs,outputs,labels]]\n",
    "    return inps,outs,lbls\n",
    "\n",
    "\n",
    "\n",
    "## show inputs,predictions and labels\n",
    "def show_predictions(inputs,outputs,labels):\n",
    "    line_thickness=inputs.shape[-1]//10\n",
    "    row_list=[]\n",
    "    for img,pred_mask,lbl_mask in zip(inputs,outputs,labels):\n",
    "        \n",
    "        img=frame_image(np.transpose(img,axes=(1,2,0))/img.max())\n",
    "        pred_mask=frame_image(mask2display(pred_mask))\n",
    "        lbl_mask=frame_image(mask2display(lbl_mask))\n",
    "        row=np.concatenate((img,pred_mask,lbl_mask),axis=1)\n",
    "        row_list.append(row)\n",
    "    \n",
    "    row_array=np.concatenate(row_list,axis=0)\n",
    "    plt.figure(figsize = (20,20))\n",
    "    plt.imshow(row_array, interpolation='nearest')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mask2display(mask,codes={'background':0,'small_bowel':3,'large_bowel':2,'stomach':1},\n",
    "                 color_codes={0:'lightblue',3:'yellow',2:'green',1:'red'}):\n",
    "    coloured_masks= [np.array((mask==code).unsqueeze(2))*np.array(matplotlib.colors.to_rgb(color)).reshape((1,1,3)) for code,color in color_codes.items()]\n",
    "    mask_img=np.stack(coloured_masks,axis=0).sum(axis=0)\n",
    "    return mask_img\n",
    "    \n",
    "\n",
    "## create frame of white pixels (of 10% img width) around an image        \n",
    "def frame_image(img,width=10):\n",
    "    H,W,C=img.shape\n",
    "    framed_img=np.ones((H+2*width,W+2*width,C))\n",
    "    framed_img[width:-width,width:-width,:]=img\n",
    "    return framed_img        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f686e5-104f-4d98-bec4-ba0c11b3d1cf",
   "metadata": {},
   "source": [
    "### CUSTOM Learner equivalent to fastais learner class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5be714ec-a383-4560-8732-2767da999565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%writefile 'Pytorch_Learner.py'\n",
    "\n",
    "import pdb\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class PyTorchLearner():\n",
    "    def __init__(self,model,dls,optim_class,lr,\n",
    "                 loss_function,metrics=None,device='cuda',**kwargs):\n",
    "        self.device=device\n",
    "        self.model=model\n",
    "        self.dls=dls\n",
    "        self.lr=lr\n",
    "        self.optimizer = optim_class(self.model.parameters(),self.lr,**kwargs)\n",
    "        self.loss_function = loss_function\n",
    "        self.metrics = metrics\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def update_running_stats(running_val,current_val,num_evals):\n",
    "        running_val+=(1/(num_evals+1)*(current_val-running_val)).detach().item()\n",
    "        return running_val\n",
    "\n",
    "    \n",
    "    \n",
    "    def train_epoch(self,train_loader):\n",
    "        \"\"\"run one training epoch on train dl return average train loss \n",
    "         and optionally run callbacks\"\"\"\n",
    "        self.model.train()\n",
    "        running_trainloss=0.\n",
    "      \n",
    "        for j,(xb,yb) in enumerate(tqdm(train_loader)):\n",
    "            xb,yb=xb.to(self.device),yb.to(self.device)\n",
    "            y_pred=self.model(xb)\n",
    "            trainloss=self.loss_function(y_pred,yb)\n",
    "            running_trainloss=PyTorchLearner.update_running_stats(running_trainloss,\n",
    "                                                                     trainloss,j)\n",
    "            self.optimizer.zero_grad()\n",
    "            trainloss.backward()\n",
    "            self.optimizer.step()\n",
    "        return running_trainloss \n",
    "    \n",
    "     \n",
    "    def valid_epoch(self,eval_loader):\n",
    "        \"\"\"run one evaluation epoch on the eval loader,return valid loss\n",
    "           and metrics\"\"\"\n",
    "        self.model.eval()\n",
    "        running_evalloss=0.\n",
    "        running_metrics=defaultdict(int)\n",
    "        for k,(xb,yb) in enumerate(tqdm(eval_loader)):\n",
    "            xb,yb=xb.to(self.device),yb.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                y_pred=self.model(xb)\n",
    "                if self.metrics:\n",
    "                    for metric_name,metric in self.metrics.items():\n",
    "                        running_metrics[metric_name]=PyTorchLearner.update_running_stats(running_metrics[metric_name],\n",
    "                                                                      metric(y_pred,yb),k)\n",
    "                evalloss=self.loss_function(y_pred,yb)\n",
    "                running_evalloss=PyTorchLearner.update_running_stats(running_evalloss,\n",
    "                                                                      evalloss,k)\n",
    "            return running_evalloss,running_metrics\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit(self,n_epochs):\n",
    "        train_loader,eval_loader=self.dls\n",
    "        self.model=self.model.to(self.device)\n",
    "        \"\"\" run n_epoch training and validation epochs\"\"\"\n",
    "        log=[]\n",
    "        for i in tqdm(range(n_epochs)):\n",
    "            train_loss=self.train_epoch(train_loader)\n",
    "            eval_loss,metrics_dict=self.valid_epoch(eval_loader)\n",
    "                \n",
    "            row={'epoch':i, 'train_loss':train_loss, 'eval_loss': eval_loss}\n",
    "            row.update(metrics_dict)\n",
    "            wandb.log(row)\n",
    "            log.append(row)\n",
    "            tracking_df=pd.DataFrame(log)\n",
    "            display(tracking_df)\n",
    "        \n",
    "        ## perform cleanup\n",
    "        self.model=self.model.to('cpu')\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return tracking_df\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9f79cc-f8fc-479f-9bda-0adadf162954",
   "metadata": {},
   "source": [
    "## $\\frac{2 * |X \\cap Y|}{|X| + |Y|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d887b9-e657-4300-8a99-28a687067435",
   "metadata": {},
   "source": [
    "### Metrics and Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dd599ec-ff7a-4406-9b08-3ebb22455734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%writefile  'loss_and_metrics.py'\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def dice_coeff(pred, targ,smooth=1):\n",
    "    \"Compute dice coeff per class then average b/w predicted and target masks\"\n",
    "    classes=range(pred.shape[1])\n",
    "    ## get 1_hot pred masks\n",
    "    pred_mask=pred.argmax(dim=1)\n",
    "    pred_1hot=torch.stack([pred_mask==c for c in classes],dim=1)\n",
    "    ## get 1_hot target for each class\n",
    "    target_1hot=torch.stack([targ==c for c in classes],dim=1)\n",
    "    ## find intersection (and union) for each class,by summing slong Batch,H,W dims\n",
    "    intersect_each_class=(pred_1hot*target_1hot).sum(axis=(0,2,3))+smooth\n",
    "    set_sum_each_class=target_1hot.sum(axis=(0,2,3))+pred_1hot.sum(axis=(0,2,3))+smooth\n",
    "    ## accumalate class wise intersection/set_sum by taking average across classes\n",
    "    intersect_by_sum=(intersect_each_class/set_sum_each_class).mean()\n",
    "    \n",
    "    return 2*intersect_by_sum\n",
    "\n",
    "\n",
    "def dice_coeff_foreground(pred, targ,smooth=1):\n",
    "    \"Compute dice coeff per class (excluding background) then average b/w predicted and target masks\"\n",
    "    ## exclude backgroud class=0 from dice calculation\n",
    "    classes=range(1,pred.shape[1])\n",
    "    ## get 1_hot pred masks\n",
    "    pred_mask=pred.argmax(dim=1)\n",
    "    pred_1hot=torch.stack([pred_mask==c for c in classes],dim=1)\n",
    "    ## get 1_hot target for each class\n",
    "    target_1hot=torch.stack([targ==c for c in classes],dim=1)\n",
    "    ## find intersection (and union) for each class,by summing slong Batch,H,W dims\n",
    "    intersect_each_class=(pred_1hot*target_1hot).sum(axis=(0,2,3))+smooth\n",
    "    set_sum_each_class=target_1hot.sum(axis=(0,2,3))+pred_1hot.sum(axis=(0,2,3))+smooth\n",
    "    ## accumalate class wise intersection/set_sum by taking average across classes\n",
    "    intersect_by_sum=(intersect_each_class/set_sum_each_class).mean()\n",
    "    \n",
    "    return 2*intersect_by_sum\n",
    "\n",
    "\n",
    "\n",
    "## implementing a smoothen version of the dice coeff, tranforming it to loss =1-dice_coef (to minimize)\n",
    "def dice_loss(pred, targ,smooth=1):\n",
    "    \"Compute dice coeff b/w predicted and target masks\"\n",
    "    ## softmax instead of argmax to make it differentiable\n",
    "    classes=range(pred.shape[1])\n",
    "    pred_mask_soft=F.softmax(pred,dim=1)\n",
    "    target_1hot=torch.stack([targ==c for c in classes],dim=1)\n",
    "    ## find intersection (and union) for each class,by summing slong Batch,H,W dims\n",
    "    intersect_each_class=(pred_mask_soft*target_1hot).sum(axis=(0,2,3))+smooth\n",
    "    set_sum_each_class=target_1hot.sum(axis=(0,2,3))+pred_mask_soft.sum(axis=(0,2,3))+smooth\n",
    "    ## accumalate class wise intersection/set_sum by taking average across classes\n",
    "    intersect_by_sum=(intersect_each_class/set_sum_each_class).mean()\n",
    "    \n",
    "    return 1-2*intersect_by_sum\n",
    "\n",
    "## what pctage of actual pixels of each class are detected\n",
    "# class_accuracy_metrics={class_name:}\n",
    "\n",
    "def pixel_accuracy(pred, targ):\n",
    "    \"Compute dice coeff b/w predicted and target masks\"\n",
    "    pred_mask=pred.argmax(dim=1)\n",
    "    return (pred_mask==targ).float().mean()\n",
    "\n",
    "def pixel_accuracy_cls(pred, targ,class_num,smooth=1):\n",
    "    \"Compute dice coeff b/w predicted and target masks\"\n",
    "    pred_mask=pred.argmax(dim=1)\n",
    "    class_mask=(targ==class_num)\n",
    "    detected_pxl_count=((pred_mask==class_num)*class_mask).sum()\n",
    "    return (detected_pxl_count+smooth)/(class_mask.sum()+smooth)\n",
    "\n",
    "#def focal_loss(pred,targ,gamma=0):\n",
    " #   \"\"\"calculate the focal loss between pred and targ \"\"\"\n",
    "  #  classes=range(pred.shape[1])  \n",
    "  #  pred_probs=F.softmax(pred,dim=1)#bs x num_classes x H x W\n",
    "  #  target_1hot=torch.stack([targ==c for c in classes],dim=1)\n",
    "  #  pred_likelyhood=(target_1hot*pred_probs).sum(dim=1)           \n",
    "  #  pdb.set_trace()\n",
    "  #  loss=-(1-pred_likelyhood)**gamma*torch.log(pred_likelyhood) ## bs X H X W\n",
    "  #  return loss.mean()\n",
    "\n",
    "\n",
    "def focal_loss(pred,targ,weights={'background':1.,'small_bowel':16.,'large_bowel':16.,'stomach':16.},\n",
    "               codes={'background': 0, 'small_bowel': 3, 'large_bowel': 2, 'stomach': 1},gamma=2):\n",
    "    \"\"\"calculate the focal loss between pred and targ \"\"\"\n",
    "    if weights:\n",
    "        weights=torch.Tensor([weights[class_name] for class_name in sorted(codes,key=codes.__getitem__)]).to('cuda')\n",
    "    n_log_likelyhood=CrossEntropyLossFlat(axis=1,reduction='none',weight=weights)(pred,targ)      \n",
    "    loss=n_log_likelyhood*(1-torch.exp(-n_log_likelyhood))**gamma ## bs X H X W\n",
    "    return loss.mean()\n",
    "\n",
    "def weighted_crossentropy_flat(pred,targ,weights={'background':1.,'small_bowel':16.,'large_bowel':16.,'stomach':16.},\n",
    "               codes={'background': 0, 'small_bowel': 3, 'large_bowel': 2, 'stomach': 1}):\n",
    "    \"\"\"calculate the weighted cross_entropy between pred and targ \"\"\"\n",
    "    if weights:\n",
    "        weights=torch.Tensor([weights[class_name] for class_name in sorted(codes,key=codes.__getitem__)]).to('cuda')\n",
    "    return CrossEntropyLossFlat(axis=1,weight=weights)(pred,targ)      \n",
    "    \n",
    "   \n",
    "\n",
    "def segmentation_cross_entropy_loss(img_out,mask):\n",
    "    return F.cross_entropy(img_out.flatten(start_dim=2),mask.flatten(start_dim=1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b6d1ae4-23c3-4c2a-b5bf-917e555c0790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## deining metrics+ losses to train\n",
    "\n",
    "metrics={'dice_coeff_fg':dice_coeff_foreground,'pixel_accuracy':pixel_accuracy,'cross_entropy':CrossEntropyLossFlat(axis=1)}\n",
    "class_accus={class_name:partial(pixel_accuracy_cls,class_num=class_num) \n",
    "             for class_name,class_num in ds.codes.items()}\n",
    "metrics.update(class_accus)\n",
    "metrics_list=list(metrics.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c6ba6-bb3b-48cb-a284-91c1d483ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "'model_{}'.format(datetime.datetime.now())\n",
    "## distinguish model saves by datetime when training starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b7f5f8e-1c64-44dd-bf4c-2cf168c7bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_fastai=unet_learner(dls,resnet34,n_out=4,loss_func=focal_loss,metrics=metrics_list,lr=4.2e-4,cbs=[SaveModelCallback(monitor='dice_coeff_foreground',\n",
    "                                                                                                     fname='model_{}'.format(datetime.datetime.now())),\n",
    "                                                                                                        save_training_progress_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea63560f-1114-41c2-a6c6-96d0ae0ff2e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>dice_coeff_foreground</th>\n",
       "      <th>pixel_accuracy</th>\n",
       "      <th>None</th>\n",
       "      <th>pixel_accuracy_cls</th>\n",
       "      <th>pixel_accuracy_cls</th>\n",
       "      <th>pixel_accuracy_cls</th>\n",
       "      <th>pixel_accuracy_cls</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.819589</td>\n",
       "      <td>4.894317</td>\n",
       "      <td>0.504193</td>\n",
       "      <td>0.952858</td>\n",
       "      <td>1.353431</td>\n",
       "      <td>0.961750</td>\n",
       "      <td>0.773010</td>\n",
       "      <td>0.815116</td>\n",
       "      <td>0.558861</td>\n",
       "      <td>48:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.576029</td>\n",
       "      <td>3.183226</td>\n",
       "      <td>0.607838</td>\n",
       "      <td>0.971856</td>\n",
       "      <td>0.402510</td>\n",
       "      <td>0.982330</td>\n",
       "      <td>0.631747</td>\n",
       "      <td>0.895428</td>\n",
       "      <td>0.545349</td>\n",
       "      <td>34:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.020074</td>\n",
       "      <td>1.894007</td>\n",
       "      <td>0.554371</td>\n",
       "      <td>0.961971</td>\n",
       "      <td>0.483733</td>\n",
       "      <td>0.969807</td>\n",
       "      <td>0.640989</td>\n",
       "      <td>0.888280</td>\n",
       "      <td>0.741508</td>\n",
       "      <td>35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.496395</td>\n",
       "      <td>1.504364</td>\n",
       "      <td>0.542197</td>\n",
       "      <td>0.946287</td>\n",
       "      <td>0.768665</td>\n",
       "      <td>0.950902</td>\n",
       "      <td>0.909317</td>\n",
       "      <td>0.784151</td>\n",
       "      <td>0.794152</td>\n",
       "      <td>34:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.975801</td>\n",
       "      <td>0.587341</td>\n",
       "      <td>0.691812</td>\n",
       "      <td>0.976410</td>\n",
       "      <td>0.148860</td>\n",
       "      <td>0.981822</td>\n",
       "      <td>0.874810</td>\n",
       "      <td>0.893949</td>\n",
       "      <td>0.716199</td>\n",
       "      <td>35:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.766816</td>\n",
       "      <td>0.932444</td>\n",
       "      <td>0.683506</td>\n",
       "      <td>0.974513</td>\n",
       "      <td>0.154632</td>\n",
       "      <td>0.979766</td>\n",
       "      <td>0.886605</td>\n",
       "      <td>0.921734</td>\n",
       "      <td>0.667883</td>\n",
       "      <td>35:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.639469</td>\n",
       "      <td>1.028086</td>\n",
       "      <td>0.736477</td>\n",
       "      <td>0.980787</td>\n",
       "      <td>0.139808</td>\n",
       "      <td>0.986502</td>\n",
       "      <td>0.960923</td>\n",
       "      <td>0.840300</td>\n",
       "      <td>0.676582</td>\n",
       "      <td>37:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\fastai2022\\lib\\site-packages\\fastai\\callback\\core.py:69: UserWarning: You are shadowing an attribute (model) that exists in the learner. Use `self.learn.model` to avoid this\n",
      "  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Better model found at epoch 0 with dice_coeff_foreground value: 0.5041932463645935.\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Better model found at epoch 1 with dice_coeff_foreground value: 0.6078378558158875.\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\fastai2022\\lib\\site-packages\\ipykernel_launcher.py:68: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Better model found at epoch 4 with dice_coeff_foreground value: 0.69181227684021.\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Better model found at epoch 6 with dice_coeff_foreground value: 0.7364771366119385.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_fastai.fit(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1a24dd-39e4-44b9-9f8b-3d3f5afdaf61",
   "metadata": {},
   "source": [
    "### Save Model and Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7f68ab16-5517-4305-8b59-37362f44445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def save_learner(learner,learner_filename='learner',save_pytorch_model=True):\n",
    "    \"\"\"save Fatsai learner,optionally with model in pytorch format with state dict\"\"\"\n",
    "    ## root folder for all model wts/learner object saves (fastai creates this by default)\n",
    "   \n",
    "    ## save in subfolders indexed by savetime\n",
    "    date,time='{}'.format(datetime.datetime.now()).split(' ')\n",
    "    ## swap : with _\n",
    "    time='_'.join(time.split(':'))\n",
    "    date_time='_'.join([date,time])\n",
    "    subfolder=Path('models')/Path(date_time)\n",
    "    \n",
    "    \n",
    "   \n",
    "    subfolder.mkdir(exist_ok=True)\n",
    "    \n",
    "    \n",
    "    ## give a descriptive learner_filename. Ideally with train config (wandb.config) used to train\n",
    "    \n",
    "    model_filename=Path('_'.join([learner_filename,'model.pt']))\n",
    "    learner_filename=Path(learner_filename)\n",
    "    learner_path,model_path=[Path(date_time)/filename for filename in [learner_filename,model_filename]]\n",
    "    \n",
    "    ## saving learner for inference\n",
    "    learner.save(file= learner_path)\n",
    "    ## saving model (Ws and bs) the state dict with ley variable names and values tensors (params)\n",
    "    if save_pytorch_model:\n",
    "        torch.save(learner.model.state_dict(),Path('models')/model_path)\n",
    "        \n",
    "    return Path('models')/learner_path,Path('models')/model_path\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "281dd784-dabc-4fde-8497-640c7fc1024b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Path('models/2022-09-11_14_19_16.157819/learner'),\n",
       " Path('models/2022-09-11_14_19_16.157819/learner_model.pt'))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_learner(learn_fastai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8ecaee-0d44-43d0-9aa4-ef44e41a86cc",
   "metadata": {},
   "source": [
    "### USING CUSTOM LEARNER CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91b96fd-a37f-4be0-8092-66c920bcdacf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_metric(self):\n",
    "    if(self.iter%50==0):\n",
    "        dice=dice_coeff_foreground(self.model(self.xb),self.yb)\n",
    "        wandb.log(dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "409e8703-fe56-4571-874c-23b771c156eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=create_unet_model(resnet34,n_out=4,n_in=1,img_size=(224,224))\n",
    "learn=PyTorchLearner(model=model,dls=dls,optim_class=Adam,lr=4e-4,loss_function=focal_loss,device='cuda',\n",
    "                     metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f971cdd-673e-468c-a1b6-a679a5cf0b45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133ad9a8f0fc484e87cec63503d402e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41eb7871d3414449a1b5c691c4db06ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63ed6fd3c66432c8d1dcd1c2fd78cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>dice_coeff</th>\n",
       "      <th>pixel_accuracy</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>background</th>\n",
       "      <th>small_bowel</th>\n",
       "      <th>large_bowel</th>\n",
       "      <th>stomach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.373728</td>\n",
       "      <td>0.393545</td>\n",
       "      <td>0.295359</td>\n",
       "      <td>0.964124</td>\n",
       "      <td>0.458556</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.025914</td>\n",
       "      <td>0.033049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  eval_loss  dice_coeff  pixel_accuracy  cross_entropy  \\\n",
       "0      0    7.373728   0.393545    0.295359        0.964124       0.458556   \n",
       "\n",
       "   background  small_bowel  large_bowel   stomach  \n",
       "0      0.9971       0.0625     0.025914  0.033049  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9650495efc84dc18ea1fb1fb56bde16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a3d23267fa4bae82e1178602db59c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>dice_coeff</th>\n",
       "      <th>pixel_accuracy</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>background</th>\n",
       "      <th>small_bowel</th>\n",
       "      <th>large_bowel</th>\n",
       "      <th>stomach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.373728</td>\n",
       "      <td>0.393545</td>\n",
       "      <td>0.295359</td>\n",
       "      <td>0.964124</td>\n",
       "      <td>0.458556</td>\n",
       "      <td>0.997100</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.025914</td>\n",
       "      <td>0.033049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.272448</td>\n",
       "      <td>0.365715</td>\n",
       "      <td>0.347332</td>\n",
       "      <td>0.949216</td>\n",
       "      <td>0.431368</td>\n",
       "      <td>0.975157</td>\n",
       "      <td>0.220414</td>\n",
       "      <td>0.444955</td>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  eval_loss  dice_coeff  pixel_accuracy  cross_entropy  \\\n",
       "0      0    7.373728   0.393545    0.295359        0.964124       0.458556   \n",
       "1      1    0.272448   0.365715    0.347332        0.949216       0.431368   \n",
       "\n",
       "   background  small_bowel  large_bowel   stomach  \n",
       "0    0.997100     0.062500     0.025914  0.033049  \n",
       "1    0.975157     0.220414     0.444955  0.000178  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb29c80dff864f5d8d7d5a9c32af7109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1de54ac7b2c41629bd907e5db5ddc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>dice_coeff</th>\n",
       "      <th>pixel_accuracy</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>background</th>\n",
       "      <th>small_bowel</th>\n",
       "      <th>large_bowel</th>\n",
       "      <th>stomach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.373728</td>\n",
       "      <td>0.393545</td>\n",
       "      <td>0.295359</td>\n",
       "      <td>0.964124</td>\n",
       "      <td>0.458556</td>\n",
       "      <td>0.997100</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.025914</td>\n",
       "      <td>0.033049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.272448</td>\n",
       "      <td>0.365715</td>\n",
       "      <td>0.347332</td>\n",
       "      <td>0.949216</td>\n",
       "      <td>0.431368</td>\n",
       "      <td>0.975157</td>\n",
       "      <td>0.220414</td>\n",
       "      <td>0.444955</td>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.321527</td>\n",
       "      <td>0.246099</td>\n",
       "      <td>0.403714</td>\n",
       "      <td>0.968648</td>\n",
       "      <td>0.290623</td>\n",
       "      <td>0.996517</td>\n",
       "      <td>0.376479</td>\n",
       "      <td>0.278258</td>\n",
       "      <td>0.001066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  eval_loss  dice_coeff  pixel_accuracy  cross_entropy  \\\n",
       "0      0    7.373728   0.393545    0.295359        0.964124       0.458556   \n",
       "1      1    0.272448   0.365715    0.347332        0.949216       0.431368   \n",
       "2      2    0.321527   0.246099    0.403714        0.968648       0.290623   \n",
       "\n",
       "   background  small_bowel  large_bowel   stomach  \n",
       "0    0.997100     0.062500     0.025914  0.033049  \n",
       "1    0.975157     0.220414     0.444955  0.000178  \n",
       "2    0.996517     0.376479     0.278258  0.001066  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a9bca822374fb388a2b189f40933aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d278286d2434a39b2c5cf41c3f9eb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>dice_coeff</th>\n",
       "      <th>pixel_accuracy</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>background</th>\n",
       "      <th>small_bowel</th>\n",
       "      <th>large_bowel</th>\n",
       "      <th>stomach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.373728</td>\n",
       "      <td>0.393545</td>\n",
       "      <td>0.295359</td>\n",
       "      <td>0.964124</td>\n",
       "      <td>0.458556</td>\n",
       "      <td>0.997100</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.025914</td>\n",
       "      <td>0.033049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.272448</td>\n",
       "      <td>0.365715</td>\n",
       "      <td>0.347332</td>\n",
       "      <td>0.949216</td>\n",
       "      <td>0.431368</td>\n",
       "      <td>0.975157</td>\n",
       "      <td>0.220414</td>\n",
       "      <td>0.444955</td>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.321527</td>\n",
       "      <td>0.246099</td>\n",
       "      <td>0.403714</td>\n",
       "      <td>0.968648</td>\n",
       "      <td>0.290623</td>\n",
       "      <td>0.996517</td>\n",
       "      <td>0.376479</td>\n",
       "      <td>0.278258</td>\n",
       "      <td>0.001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.161435</td>\n",
       "      <td>0.142907</td>\n",
       "      <td>0.451696</td>\n",
       "      <td>0.965970</td>\n",
       "      <td>0.182525</td>\n",
       "      <td>0.991311</td>\n",
       "      <td>0.389053</td>\n",
       "      <td>0.225878</td>\n",
       "      <td>0.213220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  eval_loss  dice_coeff  pixel_accuracy  cross_entropy  \\\n",
       "0      0    7.373728   0.393545    0.295359        0.964124       0.458556   \n",
       "1      1    0.272448   0.365715    0.347332        0.949216       0.431368   \n",
       "2      2    0.321527   0.246099    0.403714        0.968648       0.290623   \n",
       "3      3    0.161435   0.142907    0.451696        0.965970       0.182525   \n",
       "\n",
       "   background  small_bowel  large_bowel   stomach  \n",
       "0    0.997100     0.062500     0.025914  0.033049  \n",
       "1    0.975157     0.220414     0.444955  0.000178  \n",
       "2    0.996517     0.376479     0.278258  0.001066  \n",
       "3    0.991311     0.389053     0.225878  0.213220  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802bd2cf1e644dceba345c461d8ae8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0878865d54e45349d87b0613fca3ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>dice_coeff</th>\n",
       "      <th>pixel_accuracy</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>background</th>\n",
       "      <th>small_bowel</th>\n",
       "      <th>large_bowel</th>\n",
       "      <th>stomach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.373728</td>\n",
       "      <td>0.393545</td>\n",
       "      <td>0.295359</td>\n",
       "      <td>0.964124</td>\n",
       "      <td>0.458556</td>\n",
       "      <td>0.997100</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.025914</td>\n",
       "      <td>0.033049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.272448</td>\n",
       "      <td>0.365715</td>\n",
       "      <td>0.347332</td>\n",
       "      <td>0.949216</td>\n",
       "      <td>0.431368</td>\n",
       "      <td>0.975157</td>\n",
       "      <td>0.220414</td>\n",
       "      <td>0.444955</td>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.321527</td>\n",
       "      <td>0.246099</td>\n",
       "      <td>0.403714</td>\n",
       "      <td>0.968648</td>\n",
       "      <td>0.290623</td>\n",
       "      <td>0.996517</td>\n",
       "      <td>0.376479</td>\n",
       "      <td>0.278258</td>\n",
       "      <td>0.001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.161435</td>\n",
       "      <td>0.142907</td>\n",
       "      <td>0.451696</td>\n",
       "      <td>0.965970</td>\n",
       "      <td>0.182525</td>\n",
       "      <td>0.991311</td>\n",
       "      <td>0.389053</td>\n",
       "      <td>0.225878</td>\n",
       "      <td>0.213220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.139929</td>\n",
       "      <td>0.073146</td>\n",
       "      <td>0.495830</td>\n",
       "      <td>0.972352</td>\n",
       "      <td>0.122635</td>\n",
       "      <td>0.994196</td>\n",
       "      <td>0.331731</td>\n",
       "      <td>0.630950</td>\n",
       "      <td>0.105721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  eval_loss  dice_coeff  pixel_accuracy  cross_entropy  \\\n",
       "0      0    7.373728   0.393545    0.295359        0.964124       0.458556   \n",
       "1      1    0.272448   0.365715    0.347332        0.949216       0.431368   \n",
       "2      2    0.321527   0.246099    0.403714        0.968648       0.290623   \n",
       "3      3    0.161435   0.142907    0.451696        0.965970       0.182525   \n",
       "4      4    0.139929   0.073146    0.495830        0.972352       0.122635   \n",
       "\n",
       "   background  small_bowel  large_bowel   stomach  \n",
       "0    0.997100     0.062500     0.025914  0.033049  \n",
       "1    0.975157     0.220414     0.444955  0.000178  \n",
       "2    0.996517     0.376479     0.278258  0.001066  \n",
       "3    0.991311     0.389053     0.225878  0.213220  \n",
       "4    0.994196     0.331731     0.630950  0.105721  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>dice_coeff</th>\n",
       "      <th>pixel_accuracy</th>\n",
       "      <th>cross_entropy</th>\n",
       "      <th>background</th>\n",
       "      <th>small_bowel</th>\n",
       "      <th>large_bowel</th>\n",
       "      <th>stomach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.373728</td>\n",
       "      <td>0.393545</td>\n",
       "      <td>0.295359</td>\n",
       "      <td>0.964124</td>\n",
       "      <td>0.458556</td>\n",
       "      <td>0.997100</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.025914</td>\n",
       "      <td>0.033049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.272448</td>\n",
       "      <td>0.365715</td>\n",
       "      <td>0.347332</td>\n",
       "      <td>0.949216</td>\n",
       "      <td>0.431368</td>\n",
       "      <td>0.975157</td>\n",
       "      <td>0.220414</td>\n",
       "      <td>0.444955</td>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.321527</td>\n",
       "      <td>0.246099</td>\n",
       "      <td>0.403714</td>\n",
       "      <td>0.968648</td>\n",
       "      <td>0.290623</td>\n",
       "      <td>0.996517</td>\n",
       "      <td>0.376479</td>\n",
       "      <td>0.278258</td>\n",
       "      <td>0.001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.161435</td>\n",
       "      <td>0.142907</td>\n",
       "      <td>0.451696</td>\n",
       "      <td>0.965970</td>\n",
       "      <td>0.182525</td>\n",
       "      <td>0.991311</td>\n",
       "      <td>0.389053</td>\n",
       "      <td>0.225878</td>\n",
       "      <td>0.213220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.139929</td>\n",
       "      <td>0.073146</td>\n",
       "      <td>0.495830</td>\n",
       "      <td>0.972352</td>\n",
       "      <td>0.122635</td>\n",
       "      <td>0.994196</td>\n",
       "      <td>0.331731</td>\n",
       "      <td>0.630950</td>\n",
       "      <td>0.105721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  eval_loss  dice_coeff  pixel_accuracy  cross_entropy  \\\n",
       "0      0    7.373728   0.393545    0.295359        0.964124       0.458556   \n",
       "1      1    0.272448   0.365715    0.347332        0.949216       0.431368   \n",
       "2      2    0.321527   0.246099    0.403714        0.968648       0.290623   \n",
       "3      3    0.161435   0.142907    0.451696        0.965970       0.182525   \n",
       "4      4    0.139929   0.073146    0.495830        0.972352       0.122635   \n",
       "\n",
       "   background  small_bowel  large_bowel   stomach  \n",
       "0    0.997100     0.062500     0.025914  0.033049  \n",
       "1    0.975157     0.220414     0.444955  0.000178  \n",
       "2    0.996517     0.376479     0.278258  0.001066  \n",
       "3    0.991311     0.389053     0.225878  0.213220  \n",
       "4    0.994196     0.331731     0.630950  0.105721  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c1c67e-a220-4856-9750-110c541a8c06",
   "metadata": {},
   "source": [
    "#### WANDB HYPERPARAM SEARCH n LOGGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1270aacc-e0ea-4f91-a880-7941b400e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyperparameters = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 10,\n",
    "  \"batch_size\": 16,\n",
    "  'loss_fn': focal_loss ,\n",
    "  'arch':resnet34 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6701713e-836d-4147-8095-345f48505dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=RLE_SegmentationDataset(all_imgs_df[:1000])\n",
    "ds_fg=ds.foreground_only()\n",
    "ds_fg.img_paths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82f00e6f-adc7-4883-8200-75de62c5412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics={'dice_coeff':dice_coeff,'pixel_accuracy':pixel_accuracy,'cross_entropy':CrossEntropyLossFlat(axis=1)}\n",
    "class_accus={class_name:partial(pixel_accuracy_cls,class_num=class_num) \n",
    "             for class_name,class_num in ds.codes.items()}\n",
    "metrics.update(class_accus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c7a22f4-6f2b-4d1e-a894-a3a4396eec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_frm_config(hyperparameters,learner,dset, metrics):\n",
    "    \n",
    "    with wandb.init(project=\"test-project\", entity=\"ai_in_pathology\",config=hyperparameters):\n",
    "        config=hyperparameters\n",
    "        ds_train,ds_test=dset.train_test_split()\n",
    "\n",
    "        dls=SegmentationDataLoaders.from_dsets(ds_train,ds_test,\n",
    "                                       codes=np.array(list(ds_train.codes.keys())),bs=config['batch_size'],device='cuda')\n",
    "        \n",
    "    \n",
    "        model=create_unet_model(config['arch'],n_out=4,n_in=1,img_size=(224,224))\n",
    "        wandb.watch(model,criterion=config['loss_fn'],log_freq=10)\n",
    "        learn=learner(model=model,dls=dls,optim_class=Adam,lr=config['learning_rate'],loss_function=config['loss_fn'],device='cuda',\n",
    "                     metrics=metrics)\n",
    "    \n",
    "        learn.fit(config['epochs'])\n",
    "    return learn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164c2213-f237-4f67-9aff-23ba7ce7c204",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Setting up Sweep for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27eb8ba1-de08-4c82-952c-bcbcf53d65f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing wandb_sweep_config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 'wandb_sweep_config.py'\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'bayes'\n",
    "    }\n",
    "metric = {\n",
    "    'name': 'dice_coeff',\n",
    "    'goal': 'maximize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "\n",
    "parameters_dict={}\n",
    "\n",
    "model_args_dict={ 'arch': {\n",
    "        'values': ['resnet18','resnet34','resnet50','resnet101','resnet152']},\n",
    "        'self_attention':{'values':[True,False]}\n",
    "}\n",
    "\n",
    "loss_args_dict={\n",
    "    \n",
    "     'loss_fn': {\n",
    "        'values': ['focal_loss','wted_crossentropy']},\n",
    "    \n",
    "    'small_bowel_wt': {\n",
    "        'distribution': 'q_log_uniform_values',\n",
    "        'q': 10,\n",
    "        'min': 10,\n",
    "        'max': 1000\n",
    "      },\n",
    "    \n",
    "    'stomach_wt': {\n",
    "        'distribution': 'q_log_uniform_values',\n",
    "        'q': 10,\n",
    "        'min': 10,\n",
    "        'max': 1000\n",
    "      },\n",
    "    'large_bowel_wt': {\n",
    "        'distribution': 'q_log_uniform_values',\n",
    "        'q': 10,\n",
    "        'min': 10,\n",
    "        'max': 1000\n",
    "      },\n",
    "    'background_wt':{'values':[1.]}\n",
    "    }\n",
    "\n",
    "    \n",
    "optimizer_args_dict={ 'learning_rate': {\n",
    "        'distribution': 'q_log_uniform_values',\n",
    "        'q': 10,\n",
    "        'min': 1e-4,\n",
    "        'max': 100\n",
    "      }\n",
    "         }\n",
    "\n",
    "dataloader_args_dict={\n",
    "    'batch_size': {\n",
    "        # integers between 32 and 256\n",
    "        # with evenly-distributed logarithms \n",
    "        'distribution': 'q_log_uniform_values',\n",
    "        'q': 2,\n",
    "        'min': 8,\n",
    "        'max': 32,\n",
    "      }\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "epochs_dict={'epochs': {\n",
    "        'values': [5,10,20]}}    \n",
    "    \n",
    "    \n",
    "parameters_dict.update(model_args_dict)\n",
    "parameters_dict.update(loss_args_dict)\n",
    "parameters_dict.update(optimizer_args_dict)\n",
    "parameters_dict.update(epochs_dict)\n",
    "parameters_dict.update(dataloader_args_dict)\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "sweep_id=wandb.sweep(sweep_config)\n",
    "\n",
    "\n",
    "arch_dict={'resnet18':resnet18,'resnet34':resnet34,'resnet50':resnet50,'resnet101':resnet101,'resnet152':resnet152}\n",
    "loss_fns_dict={'focal_loss':focal_loss,'wted_crossentropy':weighted_crossentropy_flat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "507ee7d1-8b7c-4495-addb-f30e778481c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train,ds_test=ds_fg.train_test_split()\n",
    "\n",
    "\n",
    "def run_sweep(learner=PyTorchLearner,ds_train=ds_train,ds_test=ds_test, metrics=metrics):\n",
    "    \n",
    "    with wandb.init(project=\"test-project\", entity=\"ai_in_pathology\"):\n",
    "        config=wandb.config\n",
    "        dls=SegmentationDataLoaders.from_dsets(ds_train,ds_test,\n",
    "                                       codes=np.array(list(ds_train.codes.keys())),bs=config['batch_size'],device='cuda')\n",
    "        \n",
    "        ## setting up model from config\n",
    "        model=create_unet_model(arch=arch_dict[config['arch']],n_out=4,n_in=1,img_size=(224,224),\n",
    "                                self_attention=config['self_attention'])\n",
    "        \n",
    "        wandb.watch(model,criterion=config['loss_fn'],log_freq=10)\n",
    "        \n",
    "        ## setting up loss function from config,including class weights\n",
    "        class_loss_weights={class_name:config['_'.join((class_name,'wt'))] for class_name in ds_train.codes}\n",
    "        loss_fn=loss_fns_dict[config['loss_fn']]\n",
    "        wted_loss_fn=partial(loss_fn,weights=class_loss_weights)\n",
    "        \n",
    "        learn=learner(model=model,dls=dls,optim_class=Adam,lr=config['learning_rate'],loss_function=wted_loss_fn,device='cuda',\n",
    "                     metrics=metrics)\n",
    "    \n",
    "        learn.fit(config['epochs'])\n",
    "    return learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee764fb9-89fe-4390-9cc5-abc631220d09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5zlxorw9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tarch: resnet101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbackground_wt: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlarge_bowel_wt: 110\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_fn: wted_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tself_attention: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsmall_bowel_wt: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tstomach_wt: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\kaggle_gi_tract_seg\\wandb\\run-20220902_153056-5zlxorw9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ai_in_pathology/uncategorized/runs/5zlxorw9\" target=\"_blank\">vague-sweep-2</a></strong> to <a href=\"https://wandb.ai/ai_in_pathology/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/ai_in_pathology/uncategorized/sweeps/jaqzjyem\" target=\"_blank\">https://wandb.ai/ai_in_pathology/uncategorized/sweeps/jaqzjyem</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6fa1325fbd42d7a7be9be442c54581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1a45616f6a4e79aadf8ce5ddad1342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/155 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vague-sweep-2</strong>: <a href=\"https://wandb.ai/ai_in_pathology/uncategorized/runs/5zlxorw9\" target=\"_blank\">https://wandb.ai/ai_in_pathology/uncategorized/runs/5zlxorw9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220902_153056-5zlxorw9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 5zlxorw9 errored: RuntimeError('CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 6.00 GiB total capacity; 4.95 GiB already allocated; 0 bytes free; 5.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 5zlxorw9 errored: RuntimeError('CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 6.00 GiB total capacity; 4.95 GiB already allocated; 0 bytes free; 5.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF')\n"
     ]
    }
   ],
   "source": [
    "count = 1 # number of runs to execute\n",
    "wandb.agent(sweep_id, function=run_sweep, count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "243edc45-ae08-414e-8f70-d8fbf17616f3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\kaggle_gi_tract_seg\\wandb\\run-20220901_000109-3erfuzcn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ai_in_pathology/test-project/runs/3erfuzcn\" target=\"_blank\">feasible-dragon-9</a></strong> to <a href=\"https://wandb.ai/ai_in_pathology/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\fastai2022\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "D:\\Anaconda3\\envs\\fastai2022\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c36a70942cf45b193e860ddfa940eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb752d718a94d01852e7558b127a56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">feasible-dragon-9</strong>: <a href=\"https://wandb.ai/ai_in_pathology/test-project/runs/3erfuzcn\" target=\"_blank\">https://wandb.ai/ai_in_pathology/test-project/runs/3erfuzcn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220901_000109-3erfuzcn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 298.00 MiB (GPU 0; 6.00 GiB total capacity; 4.51 GiB already allocated; 0 bytes free; 5.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12668\\1693131013.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrun_frm_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPyTorchLearner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_fg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12668\\721991184.py\u001b[0m in \u001b[0;36mrun_frm_config\u001b[1;34m(hyperparameters, learner, dset, metrics)\u001b[0m\n\u001b[0;32m     14\u001b[0m                      metrics=metrics)\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12668\\935448792.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, n_epochs)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0mtrain_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[0meval_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12668\\935448792.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(self, train_loader)\u001b[0m\n\u001b[0;32m     37\u001b[0m                                                                      trainloss,j)\n\u001b[0;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mtrainloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrunning_trainloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\fastai2022\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    393\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m                 inputs=inputs)\n\u001b[0m\u001b[0;32m    396\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\fastai2022\\lib\\site-packages\\torch\\overrides.py\u001b[0m in \u001b[0;36mhandle_torch_function\u001b[1;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         \u001b[1;31m# Use `public_api` instead of `implementation` so __torch_function__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         \u001b[1;31m# implementations can do equality/identity comparisons.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1498\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch_func_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpublic_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\fastai2022\\lib\\site-packages\\fastai\\torch_core.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'__str__'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'__repr__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_torch_handled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mifnone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[0mdict_objs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_find_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0m_find_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTensorBase\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdict_objs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_meta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_objs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mas_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\fastai2022\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDisableTorchFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_default_nowrap_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\fastai2022\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\fastai2022\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m def grad(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 298.00 MiB (GPU 0; 6.00 GiB total capacity; 4.51 GiB already allocated; 0 bytes free; 5.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "learn=run_frm_config(hyperparameters=hyperparameters,learner=PyTorchLearner,dset=ds_fg,metrics=metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
